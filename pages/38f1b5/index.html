<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GMM - Gaussian Mixed Models | Emma&#39;s Blog</title>
    <meta name="generator" content="VuePress 1.9.9">
    <link rel="icon" href="/blog/img/favicon.ico">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
    <meta name="description" content="blog">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/blog/assets/css/0.styles.f2b65211.css" as="style"><link rel="preload" href="/blog/assets/js/app.fa6bfa40.js" as="script"><link rel="preload" href="/blog/assets/js/2.7ce49225.js" as="script"><link rel="preload" href="/blog/assets/js/451.c6fed955.js" as="script"><link rel="prefetch" href="/blog/assets/js/10.9b4fdd47.js"><link rel="prefetch" href="/blog/assets/js/100.e7eefa33.js"><link rel="prefetch" href="/blog/assets/js/101.229b595f.js"><link rel="prefetch" href="/blog/assets/js/102.0869e27b.js"><link rel="prefetch" href="/blog/assets/js/103.67051ee3.js"><link rel="prefetch" href="/blog/assets/js/104.5e9ec206.js"><link rel="prefetch" href="/blog/assets/js/105.812b7b15.js"><link rel="prefetch" href="/blog/assets/js/106.d2afd06e.js"><link rel="prefetch" href="/blog/assets/js/107.0e992a28.js"><link rel="prefetch" href="/blog/assets/js/108.d7af612a.js"><link rel="prefetch" href="/blog/assets/js/109.0511ab99.js"><link rel="prefetch" href="/blog/assets/js/11.2658286a.js"><link rel="prefetch" href="/blog/assets/js/110.66eb4fe8.js"><link rel="prefetch" href="/blog/assets/js/111.c4a3506e.js"><link rel="prefetch" href="/blog/assets/js/112.96ad5e97.js"><link rel="prefetch" href="/blog/assets/js/113.d898d02f.js"><link rel="prefetch" href="/blog/assets/js/114.d26fe027.js"><link rel="prefetch" href="/blog/assets/js/115.adbc8f5f.js"><link rel="prefetch" href="/blog/assets/js/116.1932a92b.js"><link rel="prefetch" href="/blog/assets/js/117.969e94f6.js"><link rel="prefetch" href="/blog/assets/js/118.8a40c4b7.js"><link rel="prefetch" href="/blog/assets/js/119.4d5ac55d.js"><link rel="prefetch" href="/blog/assets/js/12.e397a550.js"><link rel="prefetch" href="/blog/assets/js/120.1ea31920.js"><link rel="prefetch" href="/blog/assets/js/121.0f8bbe64.js"><link rel="prefetch" href="/blog/assets/js/122.62cb2b98.js"><link rel="prefetch" href="/blog/assets/js/123.36fb89d8.js"><link rel="prefetch" href="/blog/assets/js/124.51e9f053.js"><link rel="prefetch" href="/blog/assets/js/125.707afbcb.js"><link rel="prefetch" href="/blog/assets/js/126.3f936437.js"><link rel="prefetch" href="/blog/assets/js/127.63ddddea.js"><link rel="prefetch" href="/blog/assets/js/128.45eedbf7.js"><link rel="prefetch" href="/blog/assets/js/129.309b8006.js"><link rel="prefetch" href="/blog/assets/js/13.19ccc9bf.js"><link rel="prefetch" href="/blog/assets/js/130.341188a0.js"><link rel="prefetch" href="/blog/assets/js/131.e6979d87.js"><link rel="prefetch" href="/blog/assets/js/132.162f434b.js"><link rel="prefetch" href="/blog/assets/js/133.3dbe6586.js"><link rel="prefetch" href="/blog/assets/js/134.020e2147.js"><link rel="prefetch" href="/blog/assets/js/135.c830889a.js"><link rel="prefetch" href="/blog/assets/js/136.1f295f91.js"><link rel="prefetch" href="/blog/assets/js/137.e7ff1cf2.js"><link rel="prefetch" href="/blog/assets/js/138.926cd296.js"><link rel="prefetch" href="/blog/assets/js/139.d8973f4f.js"><link rel="prefetch" href="/blog/assets/js/14.3973f32e.js"><link rel="prefetch" href="/blog/assets/js/140.3f410d2a.js"><link rel="prefetch" href="/blog/assets/js/141.29a6ec98.js"><link rel="prefetch" href="/blog/assets/js/142.76cee5a1.js"><link rel="prefetch" href="/blog/assets/js/143.1e68adfd.js"><link rel="prefetch" href="/blog/assets/js/144.0e90fa28.js"><link rel="prefetch" href="/blog/assets/js/145.b461e3eb.js"><link rel="prefetch" href="/blog/assets/js/146.0efa1a6d.js"><link rel="prefetch" href="/blog/assets/js/147.6cb2ae59.js"><link rel="prefetch" href="/blog/assets/js/148.7f9717b8.js"><link rel="prefetch" href="/blog/assets/js/149.b70d37e3.js"><link rel="prefetch" href="/blog/assets/js/15.60c21287.js"><link rel="prefetch" href="/blog/assets/js/150.ef9c5330.js"><link rel="prefetch" href="/blog/assets/js/151.495f2fe3.js"><link rel="prefetch" href="/blog/assets/js/152.399484c7.js"><link rel="prefetch" href="/blog/assets/js/153.b3f76d44.js"><link rel="prefetch" href="/blog/assets/js/154.9b4bcee9.js"><link rel="prefetch" href="/blog/assets/js/155.86d30484.js"><link rel="prefetch" href="/blog/assets/js/156.69309282.js"><link rel="prefetch" href="/blog/assets/js/157.50628274.js"><link rel="prefetch" href="/blog/assets/js/158.6201075e.js"><link rel="prefetch" href="/blog/assets/js/159.6b236af8.js"><link rel="prefetch" href="/blog/assets/js/16.f60df41a.js"><link rel="prefetch" href="/blog/assets/js/160.7cef879a.js"><link rel="prefetch" href="/blog/assets/js/161.e069cc00.js"><link rel="prefetch" href="/blog/assets/js/162.c840bba7.js"><link rel="prefetch" href="/blog/assets/js/163.d92fc034.js"><link rel="prefetch" href="/blog/assets/js/164.1654d287.js"><link rel="prefetch" href="/blog/assets/js/165.488a29ef.js"><link rel="prefetch" href="/blog/assets/js/166.f45211e9.js"><link rel="prefetch" href="/blog/assets/js/167.7c7dab06.js"><link rel="prefetch" href="/blog/assets/js/168.5487e398.js"><link rel="prefetch" href="/blog/assets/js/169.d33859fc.js"><link rel="prefetch" href="/blog/assets/js/17.e4f94e71.js"><link rel="prefetch" href="/blog/assets/js/170.8138d2a9.js"><link rel="prefetch" href="/blog/assets/js/171.f9803ede.js"><link rel="prefetch" href="/blog/assets/js/172.d083e11e.js"><link rel="prefetch" href="/blog/assets/js/173.8bc9a3da.js"><link rel="prefetch" href="/blog/assets/js/174.7bdf84df.js"><link rel="prefetch" href="/blog/assets/js/175.662c4a7d.js"><link rel="prefetch" href="/blog/assets/js/176.7501abe7.js"><link rel="prefetch" href="/blog/assets/js/177.27a6ea08.js"><link rel="prefetch" href="/blog/assets/js/178.542a2e15.js"><link rel="prefetch" href="/blog/assets/js/179.bd90a759.js"><link rel="prefetch" href="/blog/assets/js/18.ce8d611d.js"><link rel="prefetch" href="/blog/assets/js/180.bad5b48f.js"><link rel="prefetch" href="/blog/assets/js/181.75204ef2.js"><link rel="prefetch" href="/blog/assets/js/182.07c3b582.js"><link rel="prefetch" href="/blog/assets/js/183.684e4590.js"><link rel="prefetch" href="/blog/assets/js/184.1ddc109c.js"><link rel="prefetch" href="/blog/assets/js/185.23eefeba.js"><link rel="prefetch" href="/blog/assets/js/186.5023b10a.js"><link rel="prefetch" href="/blog/assets/js/187.82cdd79b.js"><link rel="prefetch" href="/blog/assets/js/188.dfbce339.js"><link rel="prefetch" href="/blog/assets/js/189.3c758dee.js"><link rel="prefetch" href="/blog/assets/js/19.98c0abc0.js"><link rel="prefetch" href="/blog/assets/js/190.b1eff947.js"><link rel="prefetch" href="/blog/assets/js/191.c88913b2.js"><link rel="prefetch" href="/blog/assets/js/192.54f0647d.js"><link rel="prefetch" href="/blog/assets/js/193.54d6343e.js"><link rel="prefetch" href="/blog/assets/js/194.abe54e8a.js"><link rel="prefetch" href="/blog/assets/js/195.099dd0e8.js"><link rel="prefetch" href="/blog/assets/js/196.ab3cc2bc.js"><link rel="prefetch" href="/blog/assets/js/197.a895813f.js"><link rel="prefetch" href="/blog/assets/js/198.94d4bf63.js"><link rel="prefetch" href="/blog/assets/js/199.22ba978c.js"><link rel="prefetch" href="/blog/assets/js/20.1bac6a12.js"><link rel="prefetch" href="/blog/assets/js/200.e0c0c5db.js"><link rel="prefetch" href="/blog/assets/js/201.3decc849.js"><link rel="prefetch" href="/blog/assets/js/202.ddbf28b3.js"><link rel="prefetch" href="/blog/assets/js/203.2397895a.js"><link rel="prefetch" href="/blog/assets/js/204.5f519032.js"><link rel="prefetch" href="/blog/assets/js/205.0f9caae2.js"><link rel="prefetch" href="/blog/assets/js/206.1f6339b7.js"><link rel="prefetch" href="/blog/assets/js/207.3757cf50.js"><link rel="prefetch" href="/blog/assets/js/208.a7f08e37.js"><link rel="prefetch" href="/blog/assets/js/209.c5597e2f.js"><link rel="prefetch" href="/blog/assets/js/21.5d7ecf97.js"><link rel="prefetch" href="/blog/assets/js/210.cba479b0.js"><link rel="prefetch" href="/blog/assets/js/211.0e468dce.js"><link rel="prefetch" href="/blog/assets/js/212.1276f952.js"><link rel="prefetch" href="/blog/assets/js/213.0ab1cbd2.js"><link rel="prefetch" href="/blog/assets/js/214.beab31e6.js"><link rel="prefetch" href="/blog/assets/js/215.85ce8952.js"><link rel="prefetch" href="/blog/assets/js/216.7ae13582.js"><link rel="prefetch" href="/blog/assets/js/217.21c5c4ae.js"><link rel="prefetch" href="/blog/assets/js/218.459846f9.js"><link rel="prefetch" href="/blog/assets/js/219.3ec1a6f1.js"><link rel="prefetch" href="/blog/assets/js/22.2bdcb11a.js"><link rel="prefetch" href="/blog/assets/js/220.0efee18a.js"><link rel="prefetch" href="/blog/assets/js/221.ecd509c6.js"><link rel="prefetch" href="/blog/assets/js/222.068be0e3.js"><link rel="prefetch" href="/blog/assets/js/223.0d7a3417.js"><link rel="prefetch" href="/blog/assets/js/224.e45bfd31.js"><link rel="prefetch" href="/blog/assets/js/225.c94c8651.js"><link rel="prefetch" href="/blog/assets/js/226.2dfa74fd.js"><link rel="prefetch" href="/blog/assets/js/227.38105785.js"><link rel="prefetch" href="/blog/assets/js/228.76ceed84.js"><link rel="prefetch" href="/blog/assets/js/229.54907291.js"><link rel="prefetch" href="/blog/assets/js/23.9bdaa3ab.js"><link rel="prefetch" href="/blog/assets/js/230.bab07940.js"><link rel="prefetch" href="/blog/assets/js/231.15ca6ff3.js"><link rel="prefetch" href="/blog/assets/js/232.22e17e11.js"><link rel="prefetch" href="/blog/assets/js/233.562e078c.js"><link rel="prefetch" href="/blog/assets/js/234.dba05df0.js"><link rel="prefetch" href="/blog/assets/js/235.3e377078.js"><link rel="prefetch" href="/blog/assets/js/236.ee8ef4f7.js"><link rel="prefetch" href="/blog/assets/js/237.342d5a94.js"><link rel="prefetch" href="/blog/assets/js/238.d9a5194f.js"><link rel="prefetch" href="/blog/assets/js/239.3f0ef554.js"><link rel="prefetch" href="/blog/assets/js/24.a091ba45.js"><link rel="prefetch" href="/blog/assets/js/240.73553fb4.js"><link rel="prefetch" href="/blog/assets/js/241.dc725e0b.js"><link rel="prefetch" href="/blog/assets/js/242.a19631f5.js"><link rel="prefetch" href="/blog/assets/js/243.8dad3f92.js"><link rel="prefetch" href="/blog/assets/js/244.1e7085b7.js"><link rel="prefetch" href="/blog/assets/js/245.e32e5959.js"><link rel="prefetch" href="/blog/assets/js/246.abb8f6fc.js"><link rel="prefetch" href="/blog/assets/js/247.40778e7b.js"><link rel="prefetch" href="/blog/assets/js/248.f3129994.js"><link rel="prefetch" href="/blog/assets/js/249.284fbd88.js"><link rel="prefetch" href="/blog/assets/js/25.01fddff0.js"><link rel="prefetch" href="/blog/assets/js/250.e5604caf.js"><link rel="prefetch" href="/blog/assets/js/251.4db1b5d4.js"><link rel="prefetch" href="/blog/assets/js/252.8ee09136.js"><link rel="prefetch" href="/blog/assets/js/253.886ea653.js"><link rel="prefetch" href="/blog/assets/js/254.9570cd86.js"><link rel="prefetch" href="/blog/assets/js/255.3f45535c.js"><link rel="prefetch" href="/blog/assets/js/256.5e65a4d3.js"><link rel="prefetch" href="/blog/assets/js/257.d73448be.js"><link rel="prefetch" href="/blog/assets/js/258.fd2f8dac.js"><link rel="prefetch" href="/blog/assets/js/259.41805386.js"><link rel="prefetch" href="/blog/assets/js/26.ab34c3b9.js"><link rel="prefetch" href="/blog/assets/js/260.940745e5.js"><link rel="prefetch" href="/blog/assets/js/261.4e120cbf.js"><link rel="prefetch" href="/blog/assets/js/262.387220ac.js"><link rel="prefetch" href="/blog/assets/js/263.2ce8ccb8.js"><link rel="prefetch" href="/blog/assets/js/264.f6306429.js"><link rel="prefetch" href="/blog/assets/js/265.f42b5960.js"><link rel="prefetch" href="/blog/assets/js/266.fe571a04.js"><link rel="prefetch" href="/blog/assets/js/267.cdceab63.js"><link rel="prefetch" href="/blog/assets/js/268.e76d12d5.js"><link rel="prefetch" href="/blog/assets/js/269.325b654d.js"><link rel="prefetch" href="/blog/assets/js/27.211e008f.js"><link rel="prefetch" href="/blog/assets/js/270.c5a09ebc.js"><link rel="prefetch" href="/blog/assets/js/271.8582d9ef.js"><link rel="prefetch" href="/blog/assets/js/272.25a996e7.js"><link rel="prefetch" href="/blog/assets/js/273.3cea407a.js"><link rel="prefetch" href="/blog/assets/js/274.e8037b9f.js"><link rel="prefetch" href="/blog/assets/js/275.c24fadc6.js"><link rel="prefetch" href="/blog/assets/js/276.15f6846b.js"><link rel="prefetch" href="/blog/assets/js/277.312bdd0d.js"><link rel="prefetch" href="/blog/assets/js/278.9a3d8365.js"><link rel="prefetch" href="/blog/assets/js/279.f033b4f8.js"><link rel="prefetch" href="/blog/assets/js/28.66852ae6.js"><link rel="prefetch" href="/blog/assets/js/280.35226986.js"><link rel="prefetch" href="/blog/assets/js/281.24522fa7.js"><link rel="prefetch" href="/blog/assets/js/282.2f2bf22d.js"><link rel="prefetch" href="/blog/assets/js/283.7a318e26.js"><link rel="prefetch" href="/blog/assets/js/284.dc2ed524.js"><link rel="prefetch" href="/blog/assets/js/285.0740fa3d.js"><link rel="prefetch" href="/blog/assets/js/286.d800de15.js"><link rel="prefetch" href="/blog/assets/js/287.37d62b42.js"><link rel="prefetch" href="/blog/assets/js/288.9aef5358.js"><link rel="prefetch" href="/blog/assets/js/289.2bf079d7.js"><link rel="prefetch" href="/blog/assets/js/29.141730bc.js"><link rel="prefetch" href="/blog/assets/js/290.23861619.js"><link rel="prefetch" href="/blog/assets/js/291.b90053de.js"><link rel="prefetch" href="/blog/assets/js/292.1ecc1810.js"><link rel="prefetch" href="/blog/assets/js/293.162a2bfd.js"><link rel="prefetch" href="/blog/assets/js/294.7e872ddf.js"><link rel="prefetch" href="/blog/assets/js/295.a67c9dc4.js"><link rel="prefetch" href="/blog/assets/js/296.cd5f1739.js"><link rel="prefetch" href="/blog/assets/js/297.5fba221f.js"><link rel="prefetch" href="/blog/assets/js/298.2698065d.js"><link rel="prefetch" href="/blog/assets/js/299.9ad4582c.js"><link rel="prefetch" href="/blog/assets/js/3.fb6b6218.js"><link rel="prefetch" href="/blog/assets/js/30.057cc531.js"><link rel="prefetch" href="/blog/assets/js/300.52c1803f.js"><link rel="prefetch" href="/blog/assets/js/301.b03a706d.js"><link rel="prefetch" href="/blog/assets/js/302.8ea88eb9.js"><link rel="prefetch" href="/blog/assets/js/303.1502ae39.js"><link rel="prefetch" href="/blog/assets/js/304.f20513d3.js"><link rel="prefetch" href="/blog/assets/js/305.aa35fcf1.js"><link rel="prefetch" href="/blog/assets/js/306.1897421f.js"><link rel="prefetch" href="/blog/assets/js/307.c3d97536.js"><link rel="prefetch" href="/blog/assets/js/308.4f22d76b.js"><link rel="prefetch" href="/blog/assets/js/309.7e7f7c52.js"><link rel="prefetch" href="/blog/assets/js/31.0a0b4625.js"><link rel="prefetch" href="/blog/assets/js/310.2e22d9e1.js"><link rel="prefetch" href="/blog/assets/js/311.974bbf97.js"><link rel="prefetch" href="/blog/assets/js/312.f28c61dc.js"><link rel="prefetch" href="/blog/assets/js/313.3c51e0fa.js"><link rel="prefetch" href="/blog/assets/js/314.d998ea43.js"><link rel="prefetch" href="/blog/assets/js/315.3e9a511f.js"><link rel="prefetch" href="/blog/assets/js/316.5969895b.js"><link rel="prefetch" href="/blog/assets/js/317.fc61c649.js"><link rel="prefetch" href="/blog/assets/js/318.0e38281f.js"><link rel="prefetch" href="/blog/assets/js/319.3c721d92.js"><link rel="prefetch" href="/blog/assets/js/32.ea991562.js"><link rel="prefetch" href="/blog/assets/js/320.b4ab4b4f.js"><link rel="prefetch" href="/blog/assets/js/321.56f69d1a.js"><link rel="prefetch" href="/blog/assets/js/322.20ab832b.js"><link rel="prefetch" href="/blog/assets/js/323.4b2d7ea3.js"><link rel="prefetch" href="/blog/assets/js/324.d81f5847.js"><link rel="prefetch" href="/blog/assets/js/325.7edfab8f.js"><link rel="prefetch" href="/blog/assets/js/326.45f4da77.js"><link rel="prefetch" href="/blog/assets/js/327.ba458f2c.js"><link rel="prefetch" href="/blog/assets/js/328.d86d670d.js"><link rel="prefetch" href="/blog/assets/js/329.f7eac607.js"><link rel="prefetch" href="/blog/assets/js/33.59727a1a.js"><link rel="prefetch" href="/blog/assets/js/330.10d24789.js"><link rel="prefetch" href="/blog/assets/js/331.60d73f78.js"><link rel="prefetch" href="/blog/assets/js/332.6c5b6b35.js"><link rel="prefetch" href="/blog/assets/js/333.7b1b290d.js"><link rel="prefetch" href="/blog/assets/js/334.285526b7.js"><link rel="prefetch" href="/blog/assets/js/335.4780d81e.js"><link rel="prefetch" href="/blog/assets/js/336.5ecc836e.js"><link rel="prefetch" href="/blog/assets/js/337.6fba51e2.js"><link rel="prefetch" href="/blog/assets/js/338.d646ffe0.js"><link rel="prefetch" href="/blog/assets/js/339.45c11835.js"><link rel="prefetch" href="/blog/assets/js/34.e0063628.js"><link rel="prefetch" href="/blog/assets/js/340.f3ae78d4.js"><link rel="prefetch" href="/blog/assets/js/341.0e5e0af1.js"><link rel="prefetch" href="/blog/assets/js/342.5e9536e2.js"><link rel="prefetch" href="/blog/assets/js/343.d2f5b148.js"><link rel="prefetch" href="/blog/assets/js/344.b076b331.js"><link rel="prefetch" href="/blog/assets/js/345.ccb92f9a.js"><link rel="prefetch" href="/blog/assets/js/346.c1d7088c.js"><link rel="prefetch" href="/blog/assets/js/347.76e6b595.js"><link rel="prefetch" href="/blog/assets/js/348.d08fd4eb.js"><link rel="prefetch" href="/blog/assets/js/349.b0633c03.js"><link rel="prefetch" href="/blog/assets/js/35.d02fcd5b.js"><link rel="prefetch" href="/blog/assets/js/350.58bd91c8.js"><link rel="prefetch" href="/blog/assets/js/351.4eeb8781.js"><link rel="prefetch" href="/blog/assets/js/352.92e0273b.js"><link rel="prefetch" href="/blog/assets/js/353.4316b720.js"><link rel="prefetch" href="/blog/assets/js/354.8b1ec3de.js"><link rel="prefetch" href="/blog/assets/js/355.d09b94bf.js"><link rel="prefetch" href="/blog/assets/js/356.5b548a21.js"><link rel="prefetch" href="/blog/assets/js/357.deef470d.js"><link rel="prefetch" href="/blog/assets/js/358.1b8619f3.js"><link rel="prefetch" href="/blog/assets/js/359.62109421.js"><link rel="prefetch" href="/blog/assets/js/36.9a2bf2cb.js"><link rel="prefetch" href="/blog/assets/js/360.b0fbc8bc.js"><link rel="prefetch" href="/blog/assets/js/361.9f4082fe.js"><link rel="prefetch" href="/blog/assets/js/362.998cb7ce.js"><link rel="prefetch" href="/blog/assets/js/363.59416eb7.js"><link rel="prefetch" href="/blog/assets/js/364.673a993e.js"><link rel="prefetch" href="/blog/assets/js/365.2ce18574.js"><link rel="prefetch" href="/blog/assets/js/366.06fb2db3.js"><link rel="prefetch" href="/blog/assets/js/367.82a80c1b.js"><link rel="prefetch" href="/blog/assets/js/368.c6eded31.js"><link rel="prefetch" href="/blog/assets/js/369.cf8dcc59.js"><link rel="prefetch" href="/blog/assets/js/37.14ce705f.js"><link rel="prefetch" href="/blog/assets/js/370.cc5c5295.js"><link rel="prefetch" href="/blog/assets/js/371.03d01383.js"><link rel="prefetch" href="/blog/assets/js/372.84d458d3.js"><link rel="prefetch" href="/blog/assets/js/373.69e36286.js"><link rel="prefetch" href="/blog/assets/js/374.325318a2.js"><link rel="prefetch" href="/blog/assets/js/375.0faf9354.js"><link rel="prefetch" href="/blog/assets/js/376.e383d5f8.js"><link rel="prefetch" href="/blog/assets/js/377.a45039dd.js"><link rel="prefetch" href="/blog/assets/js/378.e6bf1f8a.js"><link rel="prefetch" href="/blog/assets/js/379.ab3908c4.js"><link rel="prefetch" href="/blog/assets/js/38.d8358ff1.js"><link rel="prefetch" href="/blog/assets/js/380.9155ba09.js"><link rel="prefetch" href="/blog/assets/js/381.964c9828.js"><link rel="prefetch" href="/blog/assets/js/382.b2c17375.js"><link rel="prefetch" href="/blog/assets/js/383.f74bb63d.js"><link rel="prefetch" href="/blog/assets/js/384.f46a5f9f.js"><link rel="prefetch" href="/blog/assets/js/385.2b0fad5e.js"><link rel="prefetch" href="/blog/assets/js/386.b7fd30fd.js"><link rel="prefetch" href="/blog/assets/js/387.e387b6d2.js"><link rel="prefetch" href="/blog/assets/js/388.66733dc7.js"><link rel="prefetch" href="/blog/assets/js/389.3b9dc956.js"><link rel="prefetch" href="/blog/assets/js/39.52d6d224.js"><link rel="prefetch" href="/blog/assets/js/390.aa1a3f13.js"><link rel="prefetch" href="/blog/assets/js/391.b98a3f89.js"><link rel="prefetch" href="/blog/assets/js/392.51947d62.js"><link rel="prefetch" href="/blog/assets/js/393.4e8ca73f.js"><link rel="prefetch" href="/blog/assets/js/394.4eae3c2a.js"><link rel="prefetch" href="/blog/assets/js/395.b41e57dd.js"><link rel="prefetch" href="/blog/assets/js/396.f19229fd.js"><link rel="prefetch" href="/blog/assets/js/397.8caf94d9.js"><link rel="prefetch" href="/blog/assets/js/398.a79fa068.js"><link rel="prefetch" href="/blog/assets/js/399.1f8f72a8.js"><link rel="prefetch" href="/blog/assets/js/4.72adf461.js"><link rel="prefetch" href="/blog/assets/js/40.42598248.js"><link rel="prefetch" href="/blog/assets/js/400.31d2590c.js"><link rel="prefetch" href="/blog/assets/js/401.430ee10a.js"><link rel="prefetch" href="/blog/assets/js/402.0969de14.js"><link rel="prefetch" href="/blog/assets/js/403.22305621.js"><link rel="prefetch" href="/blog/assets/js/404.c24c1ea8.js"><link rel="prefetch" href="/blog/assets/js/405.a7531e74.js"><link rel="prefetch" href="/blog/assets/js/406.44308bfa.js"><link rel="prefetch" href="/blog/assets/js/407.5bea8380.js"><link rel="prefetch" href="/blog/assets/js/408.47124f69.js"><link rel="prefetch" href="/blog/assets/js/409.f2eb55a4.js"><link rel="prefetch" href="/blog/assets/js/41.78de33b5.js"><link rel="prefetch" href="/blog/assets/js/410.75f37834.js"><link rel="prefetch" href="/blog/assets/js/411.af5a1d9f.js"><link rel="prefetch" href="/blog/assets/js/412.70ce0662.js"><link rel="prefetch" href="/blog/assets/js/413.4773178b.js"><link rel="prefetch" href="/blog/assets/js/414.b91b3c53.js"><link rel="prefetch" href="/blog/assets/js/415.93254e87.js"><link rel="prefetch" href="/blog/assets/js/416.30e849d5.js"><link rel="prefetch" href="/blog/assets/js/417.1d626e6d.js"><link rel="prefetch" href="/blog/assets/js/418.c2830038.js"><link rel="prefetch" href="/blog/assets/js/419.de704363.js"><link rel="prefetch" href="/blog/assets/js/42.f02bfe3b.js"><link rel="prefetch" href="/blog/assets/js/420.934cfa49.js"><link rel="prefetch" href="/blog/assets/js/421.9a9fcf9c.js"><link rel="prefetch" href="/blog/assets/js/422.716d7de1.js"><link rel="prefetch" href="/blog/assets/js/423.5502a762.js"><link rel="prefetch" href="/blog/assets/js/424.9362a268.js"><link rel="prefetch" href="/blog/assets/js/425.40010459.js"><link rel="prefetch" href="/blog/assets/js/426.9012302f.js"><link rel="prefetch" href="/blog/assets/js/427.2f4f8329.js"><link rel="prefetch" href="/blog/assets/js/428.48911c6b.js"><link rel="prefetch" href="/blog/assets/js/429.6beb6f8a.js"><link rel="prefetch" href="/blog/assets/js/43.027dffdd.js"><link rel="prefetch" href="/blog/assets/js/430.20547f3b.js"><link rel="prefetch" href="/blog/assets/js/431.f7d8b272.js"><link rel="prefetch" href="/blog/assets/js/432.29f6c6c5.js"><link rel="prefetch" href="/blog/assets/js/433.053472dd.js"><link rel="prefetch" href="/blog/assets/js/434.fe7a6b42.js"><link rel="prefetch" href="/blog/assets/js/435.7b095c52.js"><link rel="prefetch" href="/blog/assets/js/436.8e65b85b.js"><link rel="prefetch" href="/blog/assets/js/437.6f2be763.js"><link rel="prefetch" href="/blog/assets/js/438.696a4a24.js"><link rel="prefetch" href="/blog/assets/js/439.8e0ffda2.js"><link rel="prefetch" href="/blog/assets/js/44.60d7bff7.js"><link rel="prefetch" href="/blog/assets/js/440.0f9d7601.js"><link rel="prefetch" href="/blog/assets/js/441.9293a0c0.js"><link rel="prefetch" href="/blog/assets/js/442.3ab911fb.js"><link rel="prefetch" href="/blog/assets/js/443.84e874a2.js"><link rel="prefetch" href="/blog/assets/js/444.a5560886.js"><link rel="prefetch" href="/blog/assets/js/445.ee43400f.js"><link rel="prefetch" href="/blog/assets/js/446.e451b4a7.js"><link rel="prefetch" href="/blog/assets/js/447.af57b4dd.js"><link rel="prefetch" href="/blog/assets/js/448.8369a48d.js"><link rel="prefetch" href="/blog/assets/js/449.81a81117.js"><link rel="prefetch" href="/blog/assets/js/45.54197661.js"><link rel="prefetch" href="/blog/assets/js/450.ed1865ae.js"><link rel="prefetch" href="/blog/assets/js/452.c490fd3f.js"><link rel="prefetch" href="/blog/assets/js/453.ce54e414.js"><link rel="prefetch" href="/blog/assets/js/454.0fcc3b33.js"><link rel="prefetch" href="/blog/assets/js/455.49b6deb2.js"><link rel="prefetch" href="/blog/assets/js/456.cea18d70.js"><link rel="prefetch" href="/blog/assets/js/457.eeb4e4ea.js"><link rel="prefetch" href="/blog/assets/js/458.6536f79d.js"><link rel="prefetch" href="/blog/assets/js/459.08049472.js"><link rel="prefetch" href="/blog/assets/js/46.2ea156c5.js"><link rel="prefetch" href="/blog/assets/js/460.ce2134bf.js"><link rel="prefetch" href="/blog/assets/js/461.4ef74cbc.js"><link rel="prefetch" href="/blog/assets/js/462.0135ab05.js"><link rel="prefetch" href="/blog/assets/js/463.75c97bc9.js"><link rel="prefetch" href="/blog/assets/js/464.0731e3a8.js"><link rel="prefetch" href="/blog/assets/js/465.58716aaa.js"><link rel="prefetch" href="/blog/assets/js/466.5d1c9632.js"><link rel="prefetch" href="/blog/assets/js/467.4a0cc264.js"><link rel="prefetch" href="/blog/assets/js/468.4d62ec95.js"><link rel="prefetch" href="/blog/assets/js/469.371bf824.js"><link rel="prefetch" href="/blog/assets/js/47.9c2846f6.js"><link rel="prefetch" href="/blog/assets/js/470.20c9b1d0.js"><link rel="prefetch" href="/blog/assets/js/471.b55b7293.js"><link rel="prefetch" href="/blog/assets/js/472.af9bed94.js"><link rel="prefetch" href="/blog/assets/js/473.763ed78b.js"><link rel="prefetch" href="/blog/assets/js/474.0c984479.js"><link rel="prefetch" href="/blog/assets/js/475.64086e43.js"><link rel="prefetch" href="/blog/assets/js/476.87a9a0cc.js"><link rel="prefetch" href="/blog/assets/js/477.bf829a5b.js"><link rel="prefetch" href="/blog/assets/js/478.e4b446ce.js"><link rel="prefetch" href="/blog/assets/js/479.2b9f77a6.js"><link rel="prefetch" href="/blog/assets/js/48.9a1455cf.js"><link rel="prefetch" href="/blog/assets/js/480.17cc6a47.js"><link rel="prefetch" href="/blog/assets/js/481.fa5b561f.js"><link rel="prefetch" href="/blog/assets/js/482.03b3eb32.js"><link rel="prefetch" href="/blog/assets/js/483.31191665.js"><link rel="prefetch" href="/blog/assets/js/484.d8a4c9bc.js"><link rel="prefetch" href="/blog/assets/js/485.e249dec7.js"><link rel="prefetch" href="/blog/assets/js/486.0fc0098f.js"><link rel="prefetch" href="/blog/assets/js/487.324062ec.js"><link rel="prefetch" href="/blog/assets/js/488.8ca4dee4.js"><link rel="prefetch" href="/blog/assets/js/489.efc83e4a.js"><link rel="prefetch" href="/blog/assets/js/49.697a7a9f.js"><link rel="prefetch" href="/blog/assets/js/490.45710d33.js"><link rel="prefetch" href="/blog/assets/js/491.8642a532.js"><link rel="prefetch" href="/blog/assets/js/492.6fd7cdf1.js"><link rel="prefetch" href="/blog/assets/js/493.e66269d0.js"><link rel="prefetch" href="/blog/assets/js/494.8617e18f.js"><link rel="prefetch" href="/blog/assets/js/495.a701486e.js"><link rel="prefetch" href="/blog/assets/js/496.6c880390.js"><link rel="prefetch" href="/blog/assets/js/497.d270d556.js"><link rel="prefetch" href="/blog/assets/js/498.88cbb5cd.js"><link rel="prefetch" href="/blog/assets/js/499.9e5d240e.js"><link rel="prefetch" href="/blog/assets/js/5.15a5c21b.js"><link rel="prefetch" href="/blog/assets/js/50.c6827336.js"><link rel="prefetch" href="/blog/assets/js/500.75b98d7e.js"><link rel="prefetch" href="/blog/assets/js/501.56835982.js"><link rel="prefetch" href="/blog/assets/js/502.6b40298b.js"><link rel="prefetch" href="/blog/assets/js/503.c1d698cc.js"><link rel="prefetch" href="/blog/assets/js/504.ccad05c2.js"><link rel="prefetch" href="/blog/assets/js/505.6f0caa3b.js"><link rel="prefetch" href="/blog/assets/js/506.aebe2376.js"><link rel="prefetch" href="/blog/assets/js/507.211ef741.js"><link rel="prefetch" href="/blog/assets/js/508.fa181cc2.js"><link rel="prefetch" href="/blog/assets/js/509.3d4bb4eb.js"><link rel="prefetch" href="/blog/assets/js/51.e12228d3.js"><link rel="prefetch" href="/blog/assets/js/510.7bc8cf92.js"><link rel="prefetch" href="/blog/assets/js/511.11fdfdc1.js"><link rel="prefetch" href="/blog/assets/js/512.ecc52d98.js"><link rel="prefetch" href="/blog/assets/js/513.7297573b.js"><link rel="prefetch" href="/blog/assets/js/514.7b747cce.js"><link rel="prefetch" href="/blog/assets/js/515.026fed32.js"><link rel="prefetch" href="/blog/assets/js/516.ed28c764.js"><link rel="prefetch" href="/blog/assets/js/517.2f57e972.js"><link rel="prefetch" href="/blog/assets/js/518.f88b52b4.js"><link rel="prefetch" href="/blog/assets/js/519.7c75386a.js"><link rel="prefetch" href="/blog/assets/js/52.c2faa40b.js"><link rel="prefetch" href="/blog/assets/js/520.75a48154.js"><link rel="prefetch" href="/blog/assets/js/521.895157dd.js"><link rel="prefetch" href="/blog/assets/js/522.7d0e847a.js"><link rel="prefetch" href="/blog/assets/js/523.01484cdc.js"><link rel="prefetch" href="/blog/assets/js/524.4d90ab64.js"><link rel="prefetch" href="/blog/assets/js/525.d1549e6c.js"><link rel="prefetch" href="/blog/assets/js/526.05483b68.js"><link rel="prefetch" href="/blog/assets/js/527.c3429fe2.js"><link rel="prefetch" href="/blog/assets/js/528.6203d42b.js"><link rel="prefetch" href="/blog/assets/js/529.5d865bd5.js"><link rel="prefetch" href="/blog/assets/js/53.5709a523.js"><link rel="prefetch" href="/blog/assets/js/530.a70a1acb.js"><link rel="prefetch" href="/blog/assets/js/531.66905b3e.js"><link rel="prefetch" href="/blog/assets/js/532.9f948fd2.js"><link rel="prefetch" href="/blog/assets/js/533.9c3dcf3c.js"><link rel="prefetch" href="/blog/assets/js/534.bcecc9a9.js"><link rel="prefetch" href="/blog/assets/js/535.01da0e85.js"><link rel="prefetch" href="/blog/assets/js/536.18503588.js"><link rel="prefetch" href="/blog/assets/js/537.3b07f2d9.js"><link rel="prefetch" href="/blog/assets/js/538.5435ae36.js"><link rel="prefetch" href="/blog/assets/js/539.bb504961.js"><link rel="prefetch" href="/blog/assets/js/54.07a4a582.js"><link rel="prefetch" href="/blog/assets/js/540.dc306ab2.js"><link rel="prefetch" href="/blog/assets/js/541.3a27f51c.js"><link rel="prefetch" href="/blog/assets/js/542.5760d344.js"><link rel="prefetch" href="/blog/assets/js/543.c2b318db.js"><link rel="prefetch" href="/blog/assets/js/544.3e7dfe68.js"><link rel="prefetch" href="/blog/assets/js/545.b9d38be9.js"><link rel="prefetch" href="/blog/assets/js/546.57f76a93.js"><link rel="prefetch" href="/blog/assets/js/547.a24678cb.js"><link rel="prefetch" href="/blog/assets/js/548.92a9e320.js"><link rel="prefetch" href="/blog/assets/js/549.ba3f7475.js"><link rel="prefetch" href="/blog/assets/js/55.f0ff0d7c.js"><link rel="prefetch" href="/blog/assets/js/550.85bf139d.js"><link rel="prefetch" href="/blog/assets/js/551.36783254.js"><link rel="prefetch" href="/blog/assets/js/552.e5e86f31.js"><link rel="prefetch" href="/blog/assets/js/553.7be649df.js"><link rel="prefetch" href="/blog/assets/js/554.8be323b3.js"><link rel="prefetch" href="/blog/assets/js/555.97049205.js"><link rel="prefetch" href="/blog/assets/js/556.a85939ec.js"><link rel="prefetch" href="/blog/assets/js/557.f0ea5bef.js"><link rel="prefetch" href="/blog/assets/js/558.f8d4d2d7.js"><link rel="prefetch" href="/blog/assets/js/559.2ef926c7.js"><link rel="prefetch" href="/blog/assets/js/56.c0cbcd65.js"><link rel="prefetch" href="/blog/assets/js/560.56eb82c5.js"><link rel="prefetch" href="/blog/assets/js/561.03a320f1.js"><link rel="prefetch" href="/blog/assets/js/562.649a7599.js"><link rel="prefetch" href="/blog/assets/js/563.8721466c.js"><link rel="prefetch" href="/blog/assets/js/564.3baad1bf.js"><link rel="prefetch" href="/blog/assets/js/565.e5e5c627.js"><link rel="prefetch" href="/blog/assets/js/566.315c4528.js"><link rel="prefetch" href="/blog/assets/js/567.b12e27ea.js"><link rel="prefetch" href="/blog/assets/js/568.225226ec.js"><link rel="prefetch" href="/blog/assets/js/569.da29d7d5.js"><link rel="prefetch" href="/blog/assets/js/57.19d05b74.js"><link rel="prefetch" href="/blog/assets/js/570.acc63d86.js"><link rel="prefetch" href="/blog/assets/js/571.a1637cdc.js"><link rel="prefetch" href="/blog/assets/js/572.bb88c6a3.js"><link rel="prefetch" href="/blog/assets/js/573.3fdb3549.js"><link rel="prefetch" href="/blog/assets/js/574.e83e19eb.js"><link rel="prefetch" href="/blog/assets/js/575.4314526d.js"><link rel="prefetch" href="/blog/assets/js/576.45816383.js"><link rel="prefetch" href="/blog/assets/js/577.27b63977.js"><link rel="prefetch" href="/blog/assets/js/578.20d32e8a.js"><link rel="prefetch" href="/blog/assets/js/579.55cf4824.js"><link rel="prefetch" href="/blog/assets/js/58.6e93d3bf.js"><link rel="prefetch" href="/blog/assets/js/580.d531b052.js"><link rel="prefetch" href="/blog/assets/js/581.f627031b.js"><link rel="prefetch" href="/blog/assets/js/582.7a256d37.js"><link rel="prefetch" href="/blog/assets/js/583.7e6734b3.js"><link rel="prefetch" href="/blog/assets/js/584.dfb3a9cb.js"><link rel="prefetch" href="/blog/assets/js/585.a71b9e6e.js"><link rel="prefetch" href="/blog/assets/js/586.5137eb0c.js"><link rel="prefetch" href="/blog/assets/js/587.5b00ff50.js"><link rel="prefetch" href="/blog/assets/js/588.6683a53f.js"><link rel="prefetch" href="/blog/assets/js/589.c2bb0000.js"><link rel="prefetch" href="/blog/assets/js/59.74303d32.js"><link rel="prefetch" href="/blog/assets/js/590.ac1e550c.js"><link rel="prefetch" href="/blog/assets/js/591.124f0d02.js"><link rel="prefetch" href="/blog/assets/js/592.c930684a.js"><link rel="prefetch" href="/blog/assets/js/593.5010d3e0.js"><link rel="prefetch" href="/blog/assets/js/594.26376a7e.js"><link rel="prefetch" href="/blog/assets/js/595.b0a30b26.js"><link rel="prefetch" href="/blog/assets/js/596.b3f21662.js"><link rel="prefetch" href="/blog/assets/js/597.c26a075e.js"><link rel="prefetch" href="/blog/assets/js/598.baaa2008.js"><link rel="prefetch" href="/blog/assets/js/599.76aefe16.js"><link rel="prefetch" href="/blog/assets/js/6.c39ed483.js"><link rel="prefetch" href="/blog/assets/js/60.ef364511.js"><link rel="prefetch" href="/blog/assets/js/600.adf240b2.js"><link rel="prefetch" href="/blog/assets/js/601.e5c38ddf.js"><link rel="prefetch" href="/blog/assets/js/602.c9ffa321.js"><link rel="prefetch" href="/blog/assets/js/603.36192b41.js"><link rel="prefetch" href="/blog/assets/js/604.5c4f5034.js"><link rel="prefetch" href="/blog/assets/js/605.51fbb0a4.js"><link rel="prefetch" href="/blog/assets/js/606.88fe8276.js"><link rel="prefetch" href="/blog/assets/js/607.7dc7d0b1.js"><link rel="prefetch" href="/blog/assets/js/608.0b5d9f52.js"><link rel="prefetch" href="/blog/assets/js/609.a7830f0c.js"><link rel="prefetch" href="/blog/assets/js/61.436e46a1.js"><link rel="prefetch" href="/blog/assets/js/610.031fa893.js"><link rel="prefetch" href="/blog/assets/js/611.90e0e4d3.js"><link rel="prefetch" href="/blog/assets/js/612.2b9a79d8.js"><link rel="prefetch" href="/blog/assets/js/613.d38f2851.js"><link rel="prefetch" href="/blog/assets/js/614.6cfef72e.js"><link rel="prefetch" href="/blog/assets/js/615.73222425.js"><link rel="prefetch" href="/blog/assets/js/616.771db440.js"><link rel="prefetch" href="/blog/assets/js/617.a4729ad6.js"><link rel="prefetch" href="/blog/assets/js/618.5ea9e128.js"><link rel="prefetch" href="/blog/assets/js/619.10f5472f.js"><link rel="prefetch" href="/blog/assets/js/62.9490960b.js"><link rel="prefetch" href="/blog/assets/js/620.d0069dce.js"><link rel="prefetch" href="/blog/assets/js/621.d19ea508.js"><link rel="prefetch" href="/blog/assets/js/622.9e5920b2.js"><link rel="prefetch" href="/blog/assets/js/623.78d93448.js"><link rel="prefetch" href="/blog/assets/js/624.d37d7fce.js"><link rel="prefetch" href="/blog/assets/js/625.447be412.js"><link rel="prefetch" href="/blog/assets/js/626.e59af340.js"><link rel="prefetch" href="/blog/assets/js/627.7e6d7c95.js"><link rel="prefetch" href="/blog/assets/js/628.d135b01b.js"><link rel="prefetch" href="/blog/assets/js/629.8886d8ea.js"><link rel="prefetch" href="/blog/assets/js/63.6cc1bcab.js"><link rel="prefetch" href="/blog/assets/js/630.22d4ced4.js"><link rel="prefetch" href="/blog/assets/js/631.9e7843f6.js"><link rel="prefetch" href="/blog/assets/js/632.4803808d.js"><link rel="prefetch" href="/blog/assets/js/633.50e4112f.js"><link rel="prefetch" href="/blog/assets/js/634.bb993c38.js"><link rel="prefetch" href="/blog/assets/js/635.5d6b9e6f.js"><link rel="prefetch" href="/blog/assets/js/636.9b48556d.js"><link rel="prefetch" href="/blog/assets/js/637.c42758ba.js"><link rel="prefetch" href="/blog/assets/js/638.68cc6fae.js"><link rel="prefetch" href="/blog/assets/js/639.169fa156.js"><link rel="prefetch" href="/blog/assets/js/64.abdee43a.js"><link rel="prefetch" href="/blog/assets/js/640.fbe8a02e.js"><link rel="prefetch" href="/blog/assets/js/641.ec22012c.js"><link rel="prefetch" href="/blog/assets/js/642.d4d1938f.js"><link rel="prefetch" href="/blog/assets/js/643.10235c62.js"><link rel="prefetch" href="/blog/assets/js/644.c1fadb2f.js"><link rel="prefetch" href="/blog/assets/js/645.c149df88.js"><link rel="prefetch" href="/blog/assets/js/646.c6c3f8e0.js"><link rel="prefetch" href="/blog/assets/js/647.6958847b.js"><link rel="prefetch" href="/blog/assets/js/648.5c76d596.js"><link rel="prefetch" href="/blog/assets/js/649.d6beec02.js"><link rel="prefetch" href="/blog/assets/js/65.68211d02.js"><link rel="prefetch" href="/blog/assets/js/650.89cbe447.js"><link rel="prefetch" href="/blog/assets/js/651.92467f48.js"><link rel="prefetch" href="/blog/assets/js/652.4845f96a.js"><link rel="prefetch" href="/blog/assets/js/653.a47fdb3b.js"><link rel="prefetch" href="/blog/assets/js/654.fcea3f5b.js"><link rel="prefetch" href="/blog/assets/js/655.4e38720d.js"><link rel="prefetch" href="/blog/assets/js/656.a397f16b.js"><link rel="prefetch" href="/blog/assets/js/657.dde34611.js"><link rel="prefetch" href="/blog/assets/js/658.0039ce51.js"><link rel="prefetch" href="/blog/assets/js/659.a0c401bc.js"><link rel="prefetch" href="/blog/assets/js/66.82efb6b8.js"><link rel="prefetch" href="/blog/assets/js/660.23dd5e68.js"><link rel="prefetch" href="/blog/assets/js/661.bc079b94.js"><link rel="prefetch" href="/blog/assets/js/662.f43d86c6.js"><link rel="prefetch" href="/blog/assets/js/663.a612b987.js"><link rel="prefetch" href="/blog/assets/js/664.f19257f7.js"><link rel="prefetch" href="/blog/assets/js/665.0cbf6fc1.js"><link rel="prefetch" href="/blog/assets/js/666.7a7c5b50.js"><link rel="prefetch" href="/blog/assets/js/667.70bcb46c.js"><link rel="prefetch" href="/blog/assets/js/668.c1c81ab6.js"><link rel="prefetch" href="/blog/assets/js/669.75638ed7.js"><link rel="prefetch" href="/blog/assets/js/67.9f6abed5.js"><link rel="prefetch" href="/blog/assets/js/670.2f90459b.js"><link rel="prefetch" href="/blog/assets/js/671.2ab85c06.js"><link rel="prefetch" href="/blog/assets/js/672.6975af2f.js"><link rel="prefetch" href="/blog/assets/js/673.4a5e0d55.js"><link rel="prefetch" href="/blog/assets/js/674.4b1db2e3.js"><link rel="prefetch" href="/blog/assets/js/675.162422a7.js"><link rel="prefetch" href="/blog/assets/js/676.5712b341.js"><link rel="prefetch" href="/blog/assets/js/677.f0d472cb.js"><link rel="prefetch" href="/blog/assets/js/678.a25199d2.js"><link rel="prefetch" href="/blog/assets/js/679.eebf998e.js"><link rel="prefetch" href="/blog/assets/js/68.b54c5d39.js"><link rel="prefetch" href="/blog/assets/js/680.9b45dc26.js"><link rel="prefetch" href="/blog/assets/js/681.d998bda3.js"><link rel="prefetch" href="/blog/assets/js/682.26a6b3b8.js"><link rel="prefetch" href="/blog/assets/js/683.3d3255b3.js"><link rel="prefetch" href="/blog/assets/js/684.01350009.js"><link rel="prefetch" href="/blog/assets/js/685.d94d2d49.js"><link rel="prefetch" href="/blog/assets/js/686.14b9a854.js"><link rel="prefetch" href="/blog/assets/js/687.6801763c.js"><link rel="prefetch" href="/blog/assets/js/688.c869d83c.js"><link rel="prefetch" href="/blog/assets/js/689.721c5842.js"><link rel="prefetch" href="/blog/assets/js/69.96961d17.js"><link rel="prefetch" href="/blog/assets/js/690.c58e3111.js"><link rel="prefetch" href="/blog/assets/js/691.a3ba298b.js"><link rel="prefetch" href="/blog/assets/js/692.976c9961.js"><link rel="prefetch" href="/blog/assets/js/693.dfa1dc96.js"><link rel="prefetch" href="/blog/assets/js/694.d5095ad8.js"><link rel="prefetch" href="/blog/assets/js/695.75a9299f.js"><link rel="prefetch" href="/blog/assets/js/696.47cd8b93.js"><link rel="prefetch" href="/blog/assets/js/697.f7bd7f56.js"><link rel="prefetch" href="/blog/assets/js/698.bfe02dd1.js"><link rel="prefetch" href="/blog/assets/js/699.5b6fee9c.js"><link rel="prefetch" href="/blog/assets/js/7.8763782e.js"><link rel="prefetch" href="/blog/assets/js/70.1c7c67c2.js"><link rel="prefetch" href="/blog/assets/js/700.49ecc111.js"><link rel="prefetch" href="/blog/assets/js/701.b19efefd.js"><link rel="prefetch" href="/blog/assets/js/702.d89fba61.js"><link rel="prefetch" href="/blog/assets/js/703.cbbe6ab7.js"><link rel="prefetch" href="/blog/assets/js/704.f221501a.js"><link rel="prefetch" href="/blog/assets/js/705.9b1567f8.js"><link rel="prefetch" href="/blog/assets/js/706.83b5a9bc.js"><link rel="prefetch" href="/blog/assets/js/707.38bfe6a4.js"><link rel="prefetch" href="/blog/assets/js/708.c4a02d49.js"><link rel="prefetch" href="/blog/assets/js/709.c37c1d0b.js"><link rel="prefetch" href="/blog/assets/js/71.136106d8.js"><link rel="prefetch" href="/blog/assets/js/710.b6daefb8.js"><link rel="prefetch" href="/blog/assets/js/711.60a8d807.js"><link rel="prefetch" href="/blog/assets/js/712.f1600b25.js"><link rel="prefetch" href="/blog/assets/js/713.9b84fe0f.js"><link rel="prefetch" href="/blog/assets/js/714.85f8dfd7.js"><link rel="prefetch" href="/blog/assets/js/715.2e7ac623.js"><link rel="prefetch" href="/blog/assets/js/716.d4016dae.js"><link rel="prefetch" href="/blog/assets/js/72.d1192ec4.js"><link rel="prefetch" href="/blog/assets/js/73.cefbd395.js"><link rel="prefetch" href="/blog/assets/js/74.f7652c2d.js"><link rel="prefetch" href="/blog/assets/js/75.93794018.js"><link rel="prefetch" href="/blog/assets/js/76.ea74a9e5.js"><link rel="prefetch" href="/blog/assets/js/77.5ab8d933.js"><link rel="prefetch" href="/blog/assets/js/78.d99be8f9.js"><link rel="prefetch" href="/blog/assets/js/79.514e7b92.js"><link rel="prefetch" href="/blog/assets/js/8.4f413a3f.js"><link rel="prefetch" href="/blog/assets/js/80.311c1c3d.js"><link rel="prefetch" href="/blog/assets/js/81.20e611a2.js"><link rel="prefetch" href="/blog/assets/js/82.33311f3c.js"><link rel="prefetch" href="/blog/assets/js/83.d0445fd9.js"><link rel="prefetch" href="/blog/assets/js/84.cdf6237f.js"><link rel="prefetch" href="/blog/assets/js/85.39e8a5b1.js"><link rel="prefetch" href="/blog/assets/js/86.5c32af0a.js"><link rel="prefetch" href="/blog/assets/js/87.66683f39.js"><link rel="prefetch" href="/blog/assets/js/88.7ad0a079.js"><link rel="prefetch" href="/blog/assets/js/89.2d677ef4.js"><link rel="prefetch" href="/blog/assets/js/9.4a0f256f.js"><link rel="prefetch" href="/blog/assets/js/90.322cff52.js"><link rel="prefetch" href="/blog/assets/js/91.5f07c279.js"><link rel="prefetch" href="/blog/assets/js/92.d6c06cd2.js"><link rel="prefetch" href="/blog/assets/js/93.6ba1a145.js"><link rel="prefetch" href="/blog/assets/js/94.b917fb97.js"><link rel="prefetch" href="/blog/assets/js/95.05ebd8ca.js"><link rel="prefetch" href="/blog/assets/js/96.649aca28.js"><link rel="prefetch" href="/blog/assets/js/97.6cfc54b2.js"><link rel="prefetch" href="/blog/assets/js/98.754036a7.js"><link rel="prefetch" href="/blog/assets/js/99.c0a4fe5b.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.f2b65211.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blog/" class="home-link router-link-active"><img src="/blog/img/logo.png" alt="Emma's Blog" class="logo"> <span class="site-name can-hide">Emma's Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/" class="nav-link">首页</a></div><div class="nav-item"><a href="/blog/bytag/" class="nav-link">By Tag</a></div><div class="nav-item"><a href="/blog/google/" class="nav-link">Google</a></div><div class="nav-item"><a href="/blog/ml/" class="nav-link">机器学习</a></div><div class="nav-item"><a href="/blog/bq/" class="nav-link">BQ</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Companies" class="dropdown-title"><!----> <span class="title" style="display:;">Companies</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/ls/" class="nav-link">Facebook</a></li><li class="dropdown-item"><!----> <a href="/blog/design/" class="nav-link">System Design</a></li><li class="dropdown-item"><!----> <a href="/blog/twosigma/" class="nav-link">标准差</a></li><li class="dropdown-item"><!----> <a href="/blog/leetcode/" class="nav-link">其它</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/blog/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/blog/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/blog/archives/" class="nav-link">归档</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://raw.githubusercontent.com/emmableu/image/master/202204101726398.png"> <div class="blogger-info"><h3>emmableu</h3> <span></span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/blog/" class="nav-link">首页</a></div><div class="nav-item"><a href="/blog/bytag/" class="nav-link">By Tag</a></div><div class="nav-item"><a href="/blog/google/" class="nav-link">Google</a></div><div class="nav-item"><a href="/blog/ml/" class="nav-link">机器学习</a></div><div class="nav-item"><a href="/blog/bq/" class="nav-link">BQ</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Companies" class="dropdown-title"><!----> <span class="title" style="display:;">Companies</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/ls/" class="nav-link">Facebook</a></li><li class="dropdown-item"><!----> <a href="/blog/design/" class="nav-link">System Design</a></li><li class="dropdown-item"><!----> <a href="/blog/twosigma/" class="nav-link">标准差</a></li><li class="dropdown-item"><!----> <a href="/blog/leetcode/" class="nav-link">其它</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/blog/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/blog/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/blog/archives/" class="nav-link">归档</a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Zero To Hero</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Machine Learning General</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/blog/pages/9a3c9d/" class="sidebar-link">ML资源</a></li><li><a href="/blog/pages/72d34b/" class="sidebar-link">Likelihood Basics</a></li><li><a href="/blog/pages/8b9f86/" class="sidebar-link">Bias and Variance</a></li><li><a href="/blog/pages/4bbcb8/" class="sidebar-link">Classification Metric</a></li><li><a href="/blog/pages/f2a083/" class="sidebar-link">Feature Selection</a></li><li><a href="/blog/pages/576fa4/" class="sidebar-link">Regularization</a></li><li><a href="/blog/pages/54c03d/" class="sidebar-link">Distributions</a></li><li><a href="/blog/pages/d812ab/" class="sidebar-link">Mutual Information</a></li><li><a href="/blog/pages/963e9f/" class="sidebar-link">Linear Regression</a></li><li><a href="/blog/pages/1eb164/" class="sidebar-link">Logistic Regression</a></li><li><a href="/blog/pages/05b850/" class="sidebar-link">Decision Tree</a></li><li><a href="/blog/pages/63f233/" class="sidebar-link">Ensemble Learning</a></li><li><a href="/blog/pages/ee42b0/" class="sidebar-link">Naive Bayes and Generative Model</a></li><li><a href="/blog/pages/00efa1/" class="sidebar-link">Linear Discrimitive Analysis (LDA)</a></li><li><a href="/blog/pages/12e393/" class="sidebar-link">Support Vector Machine (SVM)</a></li><li><a href="/blog/pages/4d184b/" class="sidebar-link">Hierarchical Clustering</a></li><li><a href="/blog/pages/3f9e2c/" class="sidebar-link">EM (Expectation Maximization) Algorithm</a></li><li><a href="/blog/pages/2a8f38/" class="sidebar-link">KNN - K Nearest Neighbor</a></li><li><a href="/blog/pages/710eb0/" class="sidebar-link">SoftMax and Cross-Entropy Loss Function</a></li><li><a href="/blog/pages/0d8e27/" class="sidebar-link">Principle Component Analysis - PCA</a></li><li><a href="/blog/pages/2cc3f6/" class="sidebar-link">Learning to Rank</a></li><li><a href="/blog/pages/38f1b5/" aria-current="page" class="active sidebar-link">GMM - Gaussian Mixed Models</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/blog/pages/38f1b5/#gaussian-mixture-model" class="sidebar-link">Gaussian Mixture Model</a></li><li class="sidebar-sub-header level2"><a href="/blog/pages/38f1b5/#gaussian-distribution" class="sidebar-link">Gaussian Distribution</a></li><li class="sidebar-sub-header level2"><a href="/blog/pages/38f1b5/#parameter-estimation" class="sidebar-link">Parameter Estimation</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/blog/pages/38f1b5/#e-step" class="sidebar-link">E Step</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/38f1b5/#m-step" class="sidebar-link">M Step</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/blog/pages/38f1b5/#assessing-convergence" class="sidebar-link">Assessing Convergence</a></li><li class="sidebar-sub-header level2"><a href="/blog/pages/38f1b5/#implementing-the-em-algorithm" class="sidebar-link">Implementing the EM algorithm</a></li><li class="sidebar-sub-header level2"><a href="/blog/pages/38f1b5/#how-many-gaussians" class="sidebar-link">How many Gaussians?</a></li></ul></li><li><a href="/blog/pages/049472/" class="sidebar-link">Gradient Boost 细节</a></li><li><a href="/blog/pages/7e9a4a/" class="sidebar-link">T-SNE or tSNE or tsne</a></li><li><a href="/blog/pages/b63956/" class="sidebar-link">Convexity, local, global minima</a></li><li><a href="/blog/pages/6332f2/" class="sidebar-link">Neural Network Intro</a></li><li><a href="/blog/pages/1f2a0f/" class="sidebar-link">Gradient Descent (Best Explanation)</a></li><li><a href="/blog/pages/2a7490/" class="sidebar-link">Backpropagation</a></li><li><a href="/blog/pages/aca2cb/" class="sidebar-link">Multiple Inputs and Outputs</a></li><li><a href="/blog/pages/3511f1/" class="sidebar-link">Loss Functions</a></li><li><a href="/blog/pages/f405d4/" class="sidebar-link">Batch Normalization</a></li><li><a href="/blog/pages/9e1504/" class="sidebar-link">Dropout</a></li><li><a href="/blog/pages/f75af9/" class="sidebar-link">PyTorch - Convolutional Neural Network (CNN)</a></li><li><a href="/blog/pages/f3f754/" class="sidebar-link">Recurrent Neural Network - RNN</a></li><li><a href="/blog/pages/a573a5/" class="sidebar-link">LSTM</a></li><li><a href="/blog/pages/7fd658/" class="sidebar-link">Transformer</a></li><li><a href="/blog/pages/eefe97/" class="sidebar-link">BERT</a></li><li><a href="/blog/pages/e03de8/" class="sidebar-link">GAN</a></li><li><a href="/blog/pages/c48750/" class="sidebar-link">ResNet 残差网络</a></li><li><a href="/blog/pages/fb613d/" class="sidebar-link">Encoder-Decoder 编码器-解码器</a></li><li><a href="/blog/pages/f449c4/" class="sidebar-link">Attention Mechanism</a></li><li><a href="/blog/pages/e1bf02/" class="sidebar-link">百面 答案 Bai Mian Baimian Solution</a></li><li><a href="/blog/pages/1792d7/" class="sidebar-link">Definition Glossary</a></li><li><a href="/blog/pages/6b4f6c/" class="sidebar-link">评价模型 Model Review</a></li><li><a href="/blog/pages/2bb689/" class="sidebar-link">Model Compare 比较模型好坏</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Machine Learning Concepts</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Reinforcement Learning</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>PyTorch</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span> Complete ML Projects</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-1"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/blog/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/blog/ml/#机器学习八股文" data-v-06225672>机器学习八股文</a></li><li data-v-06225672><a href="/blog/ml/#Machine Learning General" data-v-06225672>Machine Learning General</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="javascript:;" data-v-06225672>Emma</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2022-10-01</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><!---->GMM - Gaussian Mixed Models<!----></h1>  <div class="theme-vdoing-content content__default"><p><a href="https://github.com/ethen8181/machine-learning/blob/master/clustering/GMM/GMM.ipynb" target="_blank" rel="noopener noreferrer">source<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># code for loading the format for the notebook</span>
<span class="token keyword">import</span> os

<span class="token comment"># path : store the current path to convert back to it later</span>
path <span class="token operator">=</span> os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span>
os<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'notebook_format'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> formats <span class="token keyword">import</span> load_style
load_style<span class="token punctuation">(</span>plot_style <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>

os<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>path<span class="token punctuation">)</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>mixture <span class="token keyword">import</span> GaussianMixture
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> norm<span class="token punctuation">,</span> multivariate_normal
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><h2 id="gaussian-mixture-model"><a href="#gaussian-mixture-model" class="header-anchor">#</a> Gaussian Mixture Model</h2> <p>definition:</p> <ul><li>A clustering algorithm that clusters samples by iteratively:
<ul><li>assign the probablilities each sample belong to each cluster, and</li> <li>iteratively determine the best miu, and covariance big sigma for each of the clusters</li></ul></li> <li>keep iterating until it reaches convergence.</li></ul> <p>Clustering methods such as <strong>K-means</strong> have hard boundaries, meaning a data point either belongs to that cluster or it doesn't. On the other hand, clustering methods such as <strong>Gaussian Mixture Models (GMM)</strong> have soft boundaries, where data points can belong to multiple cluster at the same time but with different degrees of belief. e.g. a data point can have a 60% of belonging to cluster 1, 40% of belonging to cluster 2.</p> <p>Apart from using it in the context of clustering, one other thing that <strong>GMM</strong> can be useful for is outlier detection: Due to the fact that we can compute the likelihood of each point being in each cluster, the points with a &quot;relatively&quot; low likelihood (where &quot;relatively&quot; is a threshold that we just determine ourselves) can be labeled as outliers. But here we'll focus on the clustering application.</p> <p><img src="https://raw.githubusercontent.com/emmableu/image/master/202210012218925.png" alt=""></p> <h2 id="gaussian-distribution"><a href="#gaussian-distribution" class="header-anchor">#</a> Gaussian Distribution</h2> <p>In <strong>GMM</strong>, each cluster corresponds to a probability distribution, in this case the Gaussian distribution. What we want to do is to learn the parameters of these distributions, which is the Gaussian's mean $\mu$ (mu), and the variance $\sigma^2$ (sigma).</p> <p>The mathematical form of the Gaussian distribution in 1-dimension (univariate Gaussian) can be written as:</p> <p>$$N(x \mid \mu, \sigma) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\dfrac{(x-\mu)^2}{2\sigma^2}}$$</p> <ul><li>This is also referred to as the probability density function (pdf).</li> <li>Gaussian distribution is commonly referred to as the Normal distribution, hence that's where the $N$ comes from.</li> <li>$x$ refers to the random observation over which this distribution is placed.</li> <li>The mean $\mu$, controls the Gaussian's &quot;center position&quot; and the variance $\sigma^2$, controls its &quot;shape&quot;. To be precise, it is actually the standard deviation $\sigma$, i.e. the square root of the variance that controls the distribution's shape.</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># change default figure and font size</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.figsize'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6</span> 
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.size'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">12</span>

<span class="token comment"># gaussian distribution with different values of the mean and variance</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> stop <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> num <span class="token operator">=</span> <span class="token number">200</span><span class="token punctuation">)</span>
mean_opt <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>
var_opt <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> m<span class="token punctuation">,</span> v <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>mean_opt<span class="token punctuation">,</span> var_opt<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y <span class="token operator">=</span> norm<span class="token punctuation">(</span>m<span class="token punctuation">,</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>pdf<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'$\mu$ = {}, $\sigma^2$ = {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p><img src="https://raw.githubusercontent.com/emmableu/image/master/202210012144006.png" alt=""></p> <p>But that was in one dimesion, what about two, three, four ... It turns out the univariate (one-dimensional) gaussian can be extended to the multivariate (multi-dimensional) case. The form of a d-dimensional gaussian:</p> <p>$$N(x \mid \mu,\Sigma) = \frac{1}{(2\pi)^{d/2}\sqrt{|\Sigma|}}exp(-\dfrac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu))$$</p> <p>In higher dimensions, a Gaussian is fully specified by a mean vector $\boldsymbol{\mu}$ and a d-by-d covariance matrix, $\boldsymbol{\Sigma}$ (do not confused this symbol with $\sum$, which is used for denoting summing a bunch of stuff). $|\Sigma|$ refers to the determinant of the covariance matrix e.g. In two dimension, the Gaussian's parameters might look like this:</p> <p>$$N
\begin{bmatrix}
\begin{pmatrix}
\mu_1\
\mu_2
\end{pmatrix}, ,
\begin{pmatrix}
\sigma^2_1 &amp; \sigma_{12} \
\sigma_{21} &amp; \sigma^2_2
\end{pmatrix}
\end{bmatrix}
$$</p> <p>The mean vector, containing elements $\mu_1$ and $\mu_1$ centers the distribution along every dimension. On the other hand, the covariance matrix specifies the spread and orientation of the distribution. Along the diagonal of this covariance matrix we have the variance terms $\sigma^2_1$ and $\sigma^2_2$ representing the shape (spread) along each of the dimensions. But then we also have the off-diagonal terms, $\sigma_{12}$ and $\sigma_{21}$ (these two thing actually take the same value because this a symmetric matrix) that specify the correlation structure of the distribution.</p> <p>Let's look at a few examples of covariance structures that we could specify.</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># revised from</span>
<span class="token comment"># http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.multivariate_normal.html</span>
x<span class="token punctuation">,</span> y <span class="token operator">=</span> np<span class="token punctuation">.</span>mgrid<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token number">.01</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token number">.01</span><span class="token punctuation">]</span>
position <span class="token operator">=</span> np<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
position<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> x
position<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> y

<span class="token comment"># different values for the covariance matrix</span>
covariances <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">]</span>
titles <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'spherical'</span><span class="token punctuation">,</span> <span class="token string">'diag'</span><span class="token punctuation">,</span> <span class="token string">'full'</span><span class="token punctuation">]</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    z <span class="token operator">=</span> multivariate_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> covariances<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>pdf<span class="token punctuation">(</span>position<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>contour<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'{}, {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>titles<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> covariances<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><p><img src="https://raw.githubusercontent.com/emmableu/image/master/202210012147594.png" alt=""></p> <p>One way to view a Gaussian distribution in two dimensions is what's called a contour plot. The coloring represents the region's intensity, or how high it was in probability. So in the plot above, the center area that has dark red color is the region of highest probability, while the blue area corresponds to a low probability.</p> <p>The first plot is refered to as a <strong>Spherical Gaussian</strong>, since the probability distribution has spherical (circular) symmetry. The covariance matrix is a diagonal covariance with equal elements along the diagonal. By specifying a diagonal covariance, what we're seeing is that there's no correlation between our two random variables, because the off-diagonal correlations takes the value of 0. Furthermore, by having equal values of the variances along the diagonal, we end up with a circular shape to the distribution because we are saying that the spread along each one of these two dimensions is exactly the same.</p> <p>In contrast, the middle plot's covariance matrix is also a diagonal one, but we can see that if we were to specify different variances along the diagonal, then the spread in each of these dimensions is different and so what we end up with are these axis-aligned ellipses. This is refered to as a <strong>Diagonal Gaussian</strong>.</p> <p>Finally, we have the <strong>Full Gaussian</strong>. A full covariance matrix allows for correlation between our two random variables (non zero off diagonal value) we can provide these non-axis aligned ellipses. So in this example that we're showing here, these two variables are negatively correlated, meaning if one variable is high, it's more likely that the other value is low.</p> <h2 id="parameter-estimation"><a href="#parameter-estimation" class="header-anchor">#</a> Parameter Estimation</h2> <p>Now that that's covered, we'll start introducing the algorithm using a 1-dimension data. Suppose we have a bunch of data points and we know that these data points come from two separate Gaussian sources. Given these data, can we infer back what were the Gaussian sources that generated the data? Or to paraphrase the question. The Guassian distribution has two parameters the mean and the variance, can we estimate them from our data?</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># generate some random data to work with</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
x1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> size <span class="token operator">=</span> <span class="token number">2000</span><span class="token punctuation">)</span>
x2 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> size <span class="token operator">=</span> <span class="token number">2000</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> <span class="token punctuation">[</span>x1<span class="token punctuation">,</span> x2<span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">plot_hist</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> x <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>x<span class="token punctuation">,</span> bins <span class="token operator">=</span> <span class="token number">80</span><span class="token punctuation">,</span> normed <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> alpha <span class="token operator">=</span> <span class="token number">0.6</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>

plot_hist<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p><img src="https://raw.githubusercontent.com/emmableu/image/master/202210012154318.png" alt=""></p> <p>Well, since we know which data came from which Gaussian distribution, all we need to do is to compute the mean and the variance for both groups and lo and behold we get our estimates for the two Gaussian.</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># estimate the mean and variance of the data</span>
x1_mean<span class="token punctuation">,</span> x1_var <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x1<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>var<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
x2_mean<span class="token punctuation">,</span> x2_var <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x2<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>var<span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
x_mean <span class="token operator">=</span> <span class="token punctuation">[</span>x1_mean<span class="token punctuation">,</span> x2_mean<span class="token punctuation">]</span>
x_var <span class="token operator">=</span> <span class="token punctuation">[</span>x1_var<span class="token punctuation">,</span> x2_var<span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">plot_gaussian</span><span class="token punctuation">(</span>x_mean<span class="token punctuation">,</span> x_var<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    note that scipy's normal distribution requires the
    standard deviation (square root of variance) 
    instead of the variance
    &quot;&quot;&quot;</span>
    x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> stop <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span> num <span class="token operator">=</span> <span class="token number">200</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> m<span class="token punctuation">,</span> v <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>x_mean<span class="token punctuation">,</span> x_var<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y <span class="token operator">=</span> norm<span class="token punctuation">(</span>m<span class="token punctuation">,</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>pdf<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

plot_hist<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
plot_gaussian<span class="token punctuation">(</span>x_mean<span class="token punctuation">,</span> x_var<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><p><img src="https://raw.githubusercontent.com/emmableu/image/master/202210012156379.png" alt=""></p> <p>That's great!! But this is all based on knowing which points came from which distribution. Now, what if we have just a bunch of data points, we don't know which one came from which source. Can we trace back these guassian sources? Hmm ..., a bit trickier isn't it?</p> <ul><li>If someone told us which point came from which source, we can easily estimate the means and variance.</li> <li>Or if someone told us the mean and the variance for the Gaussians then we can figure out the probability of each point coming from each Gaussians.<br>
Unfortunately, we have neither .....</li></ul> <p>This is the exact situation we're in when doing <strong>GMM</strong>. We have a bunch of data points, we suspect that they came from $K$ different gaussians, but we have no clue which data points came from which gaussian. To solve this problem, we use the <strong>EM algorithm</strong>. The way it works is that it will start by placing guassians randomly (generate random mean and variance for the guassian). Then it will iterate over these two steps until it converges.</p> <ul><li><strong>E step:</strong> With the current means and variances, it's going to figure out the probability of each data point $x_i$ coming from each guassian.</li> <li><strong>M step:</strong> Once it computed these probability assignments it will use these numbers to re-estimate the guassians' mean and variance to better fit the data points.</li></ul> <h3 id="e-step"><a href="#e-step" class="header-anchor">#</a> E Step</h3> <p>We'll now formalize this. Recall that <strong>GMM</strong>'s goal is to output a set of soft assignments per data point (allocating the probability of that data point belonging to each one of the clusters). To begin with, let's just assume we actually know the parameters $\pi_k$, $\mu_k$ and $\Sigma_k$ (from some random initialization) and we need a formula to compute the soft assignments having fixed the values of all the other parameters.</p> <p>$$r_{ik} = \frac{ \pi_k N(x_i \mid \mu_k,\Sigma_k) }{ \sum_{j=1}^K \pi_j N(x_i \mid \mu_j,\Sigma_j) }$$</p> <p>Let's break this down piece by piece. The soft assignments are quantified by the responsibility vector $r$. For each observation $i$, we form a responsibility vector with elements $r_{i1}$, $r_{i2}$, all the way up to $r_{iK}$. Where $K$ is the total number of clusters, or often referred to as the number of components. The cluster responsibilities for a single data point $i$ should sum to 1.</p> <p>The name Mixture of Gaussians comes from the notion that, in order to model more complex data distribution, we can use a linear combination of several Gaussians instead of using just one. To compute the mixture of Gaussians, we introduce a set of cluster weights, $\pi_k$, one for each cluster $k$. Where $\sum_{k=1}^K \pi_k = 1$ and $0 \leq \pi_k \leq 1$ (meaning that the sum must add up to one and each of them is between 0 and 1). This parameter tells us what's the prior probability that the data point in our data set $x$ comes from the $k_{th}$ cluster. We can think it as controlling each cluster's size.</p> <p>The next part of the equation, $N(x_i \mid \mu_k,\Sigma_k)$ tells us: Given that we knew that the observation comes from the $k_{th}$ cluster, what is the likelihood of observing our data point $x_i$ coming from this cluster. To compute this part, the scipy package provides a convenient function <code>multivariate_normal.pdf</code> that computes the likelihood of seeing a data point in a multivariate Gaussian distribution.</p> <p>After multiplying the prior and the likelihood, we need to normalize over all possible cluster assignments so that the responsibility vector becomes a valid probability. And this is essentially the computation that's done for the E step.</p> <h3 id="m-step"><a href="#m-step" class="header-anchor">#</a> M Step</h3> <p>After computing the responsibility vector for the current iteration, we then use it to update <strong>GMM</strong>'s parameter.</p> <p>$$
\begin{align*}
N_k^{soft} &amp;= \sum_{i=1}^N r_{ik} \ \nonumber
\pi_k &amp;= \frac{N_k^{soft}}{N_k} \ \nonumber
\hat{\mu}<em>k &amp;= \frac{1}{N_k^{soft}} \sum</em>{i=1}^N r_{ik} x_i \ \nonumber
\hat{\Sigma}<em>k &amp;= \frac{1}{N_k^{soft}} \sum</em>{i=1}^N r_{ik} (x_i-\hat{\mu}_k)(x_i - \hat{\mu}_k)^T \nonumber
\end{align*}
$$</p> <p>First, the cluster weights $\pi_k$, show us how much each cluster is represented over all data points (each cluster's relative size). This weight is given by the ratio of the soft count $N^{\text{soft}}_{k}$ over the total number of data points $N$.</p> <p>When updating our parameters' estimates for each cluster $k$, we need to account for the associated weights $r_{ik}$ for every one of our observation. So every time we're touching a data point $x_i$ it's going to be multiplied by $r_{ik}$.</p> <p>Another thing that's worth noticing is that, when we're updating the parameter $\hat{\mu}_k$ and $\hat{\Sigma}_k$, instead of dividing the summation with the raw count of the total number of data points in that cluster $N_k$, we will use the effective number of observations in that cluster (the sum of the responsibilities in that cluster) as the denominator. This is denoted as $N_k^{soft}$.</p> <h2 id="assessing-convergence"><a href="#assessing-convergence" class="header-anchor">#</a> Assessing Convergence</h2> <p>Apart from training the model, we also want a way to monitor the convergence of the algorithm. We do so by computing the log likelihood of the data given the current estimates of our model parameters and responsibilities.</p> <p>Recall that during the E step of the algorithm, we used the formula:</p> <p>$$\sum_{j=1}^K \pi_j N(x_i \mid \mu_j,\Sigma_j)$$</p> <p>To compute the weighted probability of our data point $x_i$ coming from each cluster $j$ and summed up all the weighted probability. If we were to assume the observed data points were generated independently, the likelihood of the data can be written as:</p> <p>$$p(X \mid \pi, \mu,\Sigma)=\prod_{n=1}^{N} \sum_{j=1}^K \pi_j N(x_i \mid \mu_j,\Sigma_j)$$</p> <p>This basically means that we multiply all the probability for every data point together to obtain a single number that estimates the likelihood of the data fitted under the model's parameter. We can take the log of this likelihood so that the product becomes a sum and it makes the computation a bit easier:</p> <p>$$
ln \left( p(X \mid \pi,\mu,\Sigma) \right) = \sum^N_{i=1} ln{\sum^K_{j=1}\pi_j
N (x_i \mid \mu_j,\Sigma_j)}
$$</p> <p>Given this formula, we can use it and say: If the log likelihood of the data occuring under the current model's parameter does not improve by a tolerance value that we've pre-specified, then the algorithm is deemed converged.</p> <h2 id="implementing-the-em-algorithm"><a href="#implementing-the-em-algorithm" class="header-anchor">#</a> Implementing the EM algorithm</h2> <p>To help us develop and test our implementation, we first generate some observations from a mixture of Gaussians.</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">generate_data</span><span class="token punctuation">(</span>n_data<span class="token punctuation">,</span> means<span class="token punctuation">,</span> covariances<span class="token punctuation">,</span> weights<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;creates a list of data points&quot;&quot;&quot;</span>
    n_clusters<span class="token punctuation">,</span> n_features <span class="token operator">=</span> means<span class="token punctuation">.</span>shape
    
    data <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>n_data<span class="token punctuation">,</span> n_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># pick a cluster id and create data from this cluster</span>
        k <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>n_clusters<span class="token punctuation">,</span> size <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> p <span class="token operator">=</span> weights<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>multivariate_normal<span class="token punctuation">(</span>means<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">,</span> covariances<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span>
        data<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> x
   
    <span class="token keyword">return</span> data
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">generate_data</span><span class="token punctuation">(</span>n_data<span class="token punctuation">,</span> means<span class="token punctuation">,</span> covariances<span class="token punctuation">,</span> weights<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;creates a list of data points&quot;&quot;&quot;</span>
    n_clusters<span class="token punctuation">,</span> n_features <span class="token operator">=</span> means<span class="token punctuation">.</span>shape
    
    data <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>n_data<span class="token punctuation">,</span> n_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># pick a cluster id and create data from this cluster</span>
        k <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>n_clusters<span class="token punctuation">,</span> size <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> p <span class="token operator">=</span> weights<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>multivariate_normal<span class="token punctuation">(</span>means<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">,</span> covariances<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span>
        data<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> x
   
    <span class="token keyword">return</span> data
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p><img src="https://raw.githubusercontent.com/emmableu/image/master/202210012205415.png" alt=""></p> <p>Just like with K-means, it is important to ask how we obtain an initial configuration of mixing weights and component parameters. In this simple case, the implementation below take three random points to be the initial cluster means, use the empirical covariance of the data to be the initial covariance in each cluster (a clear overestimate), and set the initial mixing weights to be uniform across clusters. On the other hand, a better way to initial the GMM parameters is to use K-means as a first step and use its mean/cov of those clusters to initialize EM.</p> <p><strong>Note</strong>. Like K-means, EM is prone to converging to a local optimum if the initial set of parameters are sub-par. In practice, we may want to run EM multiple times with different random initialization.</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">GMM</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Full covariance Gaussian Mixture Model,
    trained using Expectation Maximization.

    Parameters
    ----------
    n_components : int
        Number of clusters/mixture components in which the data will be
        partitioned into.

    n_iters : int
        Maximum number of iterations to run the algorithm.

    tol : float
        Tolerance. If the log-likelihood between two iterations is smaller than
        the specified tolerance level, the algorithm will stop performing the
        EM optimization.

    seed : int
        Seed / random state used to initialize the parameters.
    &quot;&quot;&quot;</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_components<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> n_iters<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> tol<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span> seed<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>n_components <span class="token operator">=</span> n_components
        self<span class="token punctuation">.</span>n_iters <span class="token operator">=</span> n_iters
        self<span class="token punctuation">.</span>tol <span class="token operator">=</span> tol
        self<span class="token punctuation">.</span>seed <span class="token operator">=</span> seed

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># data's dimensionality and responsibility vector</span>
        n_row<span class="token punctuation">,</span> n_col <span class="token operator">=</span> X<span class="token punctuation">.</span>shape     
        self<span class="token punctuation">.</span>resp <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>n_row<span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_components<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># initialize parameters</span>
        np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>self<span class="token punctuation">.</span>seed<span class="token punctuation">)</span>
        chosen <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>n_row<span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_components<span class="token punctuation">,</span> replace <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>means <span class="token operator">=</span> X<span class="token punctuation">[</span>chosen<span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> np<span class="token punctuation">.</span>full<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_components<span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>n_components<span class="token punctuation">)</span>
        
        <span class="token comment"># for np.cov, rowvar = False, </span>
        <span class="token comment"># indicates that the rows represents obervation</span>
        shape <span class="token operator">=</span> self<span class="token punctuation">.</span>n_components<span class="token punctuation">,</span> n_col<span class="token punctuation">,</span> n_col
        self<span class="token punctuation">.</span>covs <span class="token operator">=</span> np<span class="token punctuation">.</span>full<span class="token punctuation">(</span>shape<span class="token punctuation">,</span> np<span class="token punctuation">.</span>cov<span class="token punctuation">(</span>X<span class="token punctuation">,</span> rowvar <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        log_likelihood <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>converged <span class="token operator">=</span> <span class="token boolean">False</span>
        self<span class="token punctuation">.</span>log_likelihood_trace <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>      

        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_iters<span class="token punctuation">)</span><span class="token punctuation">:</span>
            log_likelihood_new <span class="token operator">=</span> self<span class="token punctuation">.</span>_do_estep<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>_do_mstep<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

            <span class="token keyword">if</span> <span class="token builtin">abs</span><span class="token punctuation">(</span>log_likelihood_new <span class="token operator">-</span> log_likelihood<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>tol<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>converged <span class="token operator">=</span> <span class="token boolean">True</span>
                <span class="token keyword">break</span>
  
            log_likelihood <span class="token operator">=</span> log_likelihood_new
            self<span class="token punctuation">.</span>log_likelihood_trace<span class="token punctuation">.</span>append<span class="token punctuation">(</span>log_likelihood<span class="token punctuation">)</span>

        <span class="token keyword">return</span> self

    <span class="token keyword">def</span> <span class="token function">_do_estep</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        E-step: compute responsibilities,
        update resp matrix so that resp[j, k] is the responsibility of cluster k for data point j,
        to compute likelihood of seeing data point j given cluster k, use multivariate_normal.pdf
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>_compute_log_likelihood<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        log_likelihood <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>resp<span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># normalize over all possible cluster assignments</span>
        self<span class="token punctuation">.</span>resp <span class="token operator">=</span> self<span class="token punctuation">.</span>resp <span class="token operator">/</span> self<span class="token punctuation">.</span>resp<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> keepdims <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> log_likelihood

    <span class="token keyword">def</span> <span class="token function">_compute_log_likelihood</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_components<span class="token punctuation">)</span><span class="token punctuation">:</span>
            prior <span class="token operator">=</span> self<span class="token punctuation">.</span>weights<span class="token punctuation">[</span>k<span class="token punctuation">]</span>
            likelihood <span class="token operator">=</span> multivariate_normal<span class="token punctuation">(</span>self<span class="token punctuation">.</span>means<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>covs<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>pdf<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>resp<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> k<span class="token punctuation">]</span> <span class="token operator">=</span> prior <span class="token operator">*</span> likelihood

        <span class="token keyword">return</span> self

    <span class="token keyword">def</span> <span class="token function">_do_mstep</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;M-step, update parameters&quot;&quot;&quot;</span>

        <span class="token comment"># total responsibility assigned to each cluster, N^{soft}</span>
        resp_weights <span class="token operator">=</span> self<span class="token punctuation">.</span>resp<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
        
        <span class="token comment"># weights</span>
        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> resp_weights <span class="token operator">/</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token comment"># means</span>
        weighted_sum <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>resp<span class="token punctuation">.</span>T<span class="token punctuation">,</span> X<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>means <span class="token operator">=</span> weighted_sum <span class="token operator">/</span> resp_weights<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># covariance</span>
        <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_components<span class="token punctuation">)</span><span class="token punctuation">:</span>
            diff <span class="token operator">=</span> <span class="token punctuation">(</span>X <span class="token operator">-</span> self<span class="token punctuation">.</span>means<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
            weighted_sum <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>resp<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> k<span class="token punctuation">]</span> <span class="token operator">*</span> diff<span class="token punctuation">,</span> diff<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>covs<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> weighted_sum <span class="token operator">/</span> resp_weights<span class="token punctuation">[</span>k<span class="token punctuation">]</span>
            
        <span class="token keyword">return</span> self
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br></div></div><p>Next, we will run our EM algorithm to discover the mixture components and visualize its output. When working with low-dimensional data, one useful way of testing our implementation is to visualize the gaussian components over the data at different points in the algorithm's execution:</p> <ul><li>At initialization</li> <li>After running the algorithm to completion (convergence)</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">plot_contours</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> means<span class="token punctuation">,</span> covs<span class="token punctuation">,</span> title<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;visualize the gaussian components over the data&quot;&quot;&quot;</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'ko'</span><span class="token punctuation">)</span>

    delta <span class="token operator">=</span> <span class="token number">0.025</span>
    k <span class="token operator">=</span> means<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">7.0</span><span class="token punctuation">,</span> delta<span class="token punctuation">)</span>
    y <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">7.0</span><span class="token punctuation">,</span> delta<span class="token punctuation">)</span>
    x_grid<span class="token punctuation">,</span> y_grid <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
    coordinates <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>x_grid<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_grid<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T

    col <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'green'</span><span class="token punctuation">,</span> <span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'indigo'</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>
        mean <span class="token operator">=</span> means<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        cov <span class="token operator">=</span> covs<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        z_grid <span class="token operator">=</span> multivariate_normal<span class="token punctuation">(</span>mean<span class="token punctuation">,</span> cov<span class="token punctuation">)</span><span class="token punctuation">.</span>pdf<span class="token punctuation">(</span>coordinates<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x_grid<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>contour<span class="token punctuation">(</span>x_grid<span class="token punctuation">,</span> y_grid<span class="token punctuation">,</span> z_grid<span class="token punctuation">,</span> colors <span class="token operator">=</span> col<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>title<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># use our implementation of the EM algorithm </span>
<span class="token comment"># and fit a mixture of Gaussians to the simulated data</span>
gmm <span class="token operator">=</span> GMM<span class="token punctuation">(</span>n_components <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> n_iters <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> tol <span class="token operator">=</span> <span class="token number">1e-4</span><span class="token punctuation">,</span> seed <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">)</span>
gmm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

plot_contours<span class="token punctuation">(</span>X<span class="token punctuation">,</span> gmm<span class="token punctuation">.</span>means<span class="token punctuation">,</span> gmm<span class="token punctuation">.</span>covs<span class="token punctuation">,</span> <span class="token string">'Initial clusters'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p><img src="https://raw.githubusercontent.com/emmableu/image/master/202210012206752.png" alt=""></p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>gmm <span class="token operator">=</span> GMM<span class="token punctuation">(</span>n_components <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> n_iters <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">,</span> tol <span class="token operator">=</span> <span class="token number">1e-4</span><span class="token punctuation">,</span> seed <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">)</span>
gmm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'converged iteration:'</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>gmm<span class="token punctuation">.</span>log_likelihood_trace<span class="token punctuation">)</span><span class="token punctuation">)</span>
plot_contours<span class="token punctuation">(</span>X<span class="token punctuation">,</span> gmm<span class="token punctuation">.</span>means<span class="token punctuation">,</span> gmm<span class="token punctuation">.</span>covs<span class="token punctuation">,</span> <span class="token string">'Final clusters'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p><img src="https://raw.githubusercontent.com/emmableu/image/master/202210012207641.png" alt=""></p> <p>From the plot of different iterations in the EM algorithms, one can see that the Gaussian model is incrementally updated and refined to fit the data and the algorithm converged before it reached the maximum iteration that we've specified.</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># use library to confirm results</span>
gmm <span class="token operator">=</span> GaussianMixture<span class="token punctuation">(</span>n_components <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> covariance_type <span class="token operator">=</span> <span class="token string">'full'</span><span class="token punctuation">,</span> 
                      max_iter <span class="token operator">=</span> <span class="token number">600</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>
gmm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'converged or not: '</span><span class="token punctuation">,</span> gmm<span class="token punctuation">.</span>converged_<span class="token punctuation">)</span>
plot_contours<span class="token punctuation">(</span>X<span class="token punctuation">,</span> gmm<span class="token punctuation">.</span>means_<span class="token punctuation">,</span> gmm<span class="token punctuation">.</span>covariances_<span class="token punctuation">,</span> <span class="token string">'Final clusters'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p><img src="https://raw.githubusercontent.com/emmableu/image/master/202210012208818.png" alt=""></p> <h2 id="how-many-gaussians"><a href="#how-many-gaussians" class="header-anchor">#</a> How many Gaussians?</h2> <p>Similar to K-means, <strong>GMM</strong> requires the user to specify the number of components (clusters) before training the model. Here, we can use the <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion" target="_blank" rel="noopener noreferrer"><strong>Aikaki Information Criterion (AIC)</strong><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> or the <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion" target="_blank" rel="noopener noreferrer"><strong>Bayesian Information Criterion (BIC)</strong><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> to aid us in this decision. Let $L$ be the maximum value of the likelihood function for the model, $p$ be the number of estimated parameters in the model and $N$ be the total number of data points.</p> <p>Then the AIC value of the model is the following:</p> <p>$$ \mathrm {AIC} =2  \cdot p - 2  \cdot \ln(L) $$</p> <p>And the BIC value is denoted as:</p> <p>$$ \mathrm{BIC} = {-2 \cdot \ln(L) + p \cdot \ln(N)}$$</p> <p>For both evaluation criteron, the lower the better.</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>n_components <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
clfs <span class="token operator">=</span> <span class="token punctuation">[</span>GaussianMixture<span class="token punctuation">(</span>n<span class="token punctuation">,</span> max_iter <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token keyword">for</span> n <span class="token keyword">in</span> n_components<span class="token punctuation">]</span>
bics <span class="token operator">=</span> <span class="token punctuation">[</span>clf<span class="token punctuation">.</span>bic<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token keyword">for</span> clf <span class="token keyword">in</span> clfs<span class="token punctuation">]</span>
aics <span class="token operator">=</span> <span class="token punctuation">[</span>clf<span class="token punctuation">.</span>aic<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token keyword">for</span> clf <span class="token keyword">in</span> clfs<span class="token punctuation">]</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>n_components<span class="token punctuation">,</span> bics<span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'BIC'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>n_components<span class="token punctuation">,</span> aics<span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token string">'AIC'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'n_components'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p><img src="https://raw.githubusercontent.com/emmableu/image/master/202210012209087.png" alt="">
It appears that for both the AIC and BIC, 3 components is preferred.</p> <blockquote><p>Advice taken from <a href="https://methodology.psu.edu/node/504" target="_blank" rel="noopener noreferrer">Notes: AIC vs. BIC<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>In general, it might be best to use AIC and BIC together in model selection. Most of the times they will agree on the preferred model. The main differences between the two is that BIC penalizes model complexity more heavily. Thus if they do disagree. e.g. If BIC points to a three-class model and AIC points to a five-class model, it makes sense to select from models with 3, 4 and 5 latent classes and see which one leads to a more suitable result.</p></blockquote> <p>Another thing to bear in mind when looking at AIC/BIC evaluation metric is that all that matters is the difference between the AIC/BIC values. The actual value of the AIC/BIC and whether it is positive or negative, means nothing. So the bottom line is only pay attention to the difference.</p> <p><strong>Things to Note:</strong></p> <p>One drawback of <strong>GMM</strong> is that there are lots of parameters to learn, therefore may require lots of data and iterations to get good results. An unconstrained model with $K$-mixtures (or simply $K$ clusters) and $D$-dimensional data involves fitting $D \times D \times K + D \times K + K$ parameters ($K$ covariance matrices each of size $D \times D$, plus $K$ mean vectors of length $D$, plus a weight vector of length $K$). That could be a problem for datasets with large number of dimensions (e.g. text data), because with the number of parameters growing roughly as the square of the dimension, it may quickly become impossible to find a sufficient amount of data to make good inferences. So it is common to impose restrictions and assumption to simplify the problem (think of it as introducing regularization to avoid overfitting problems).</p> <p>One common way to avoid this problem is to fix the covariance matrix of each component to be diagonal (off-diagonal value will be 0 and will not be updated). To achieve this, we can change the <code>covariance_type</code> parameter in scikit-learn's GMM to <code>diag</code>.</p> <p>The following link includes an example of comparing <strong>GMM</strong> using different covariance matrices on a toy dataset, <a href="http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_covariances.html#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py" target="_blank" rel="noopener noreferrer">sckit-learn docs: GMM classification<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p></div></div>  <div class="page-edit"><!----> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2025/06/13, 14:24:49</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/blog/pages/2cc3f6/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Learning to Rank</div></a> <a href="/blog/pages/049472/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">Gradient Boost 细节</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/blog/pages/2cc3f6/" class="prev">Learning to Rank</a></span> <span class="next"><a href="/blog/pages/049472/">Gradient Boost 细节</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/blog/archives" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/blog/pages/aed865/"><div>
            Makemore 5 - WaveNet
            <!----></div></a> <span class="date">07-04</span></dt></dl><dl><dd>02</dd> <dt><a href="/blog/pages/049b6e/"><div>
            Makemore 4 - Backpropagation Ninja
            <!----></div></a> <span class="date">07-04</span></dt></dl><dl><dd>03</dd> <dt><a href="/blog/pages/c0d04f/"><div>
            Makemore 3 - Activations &amp; Gradients, BatchNorm
            <!----></div></a> <span class="date">07-04</span></dt></dl> <dl><dd></dd> <dt><a href="/blog/archives" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><!----> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2025
    <span>emmableu | <a href="https://github.com/emmableu/vuepress-theme-vdoing/blob/master/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/blog/assets/js/app.fa6bfa40.js" defer></script><script src="/blog/assets/js/2.7ce49225.js" defer></script><script src="/blog/assets/js/451.c6fed955.js" defer></script>
  </body>
</html>
