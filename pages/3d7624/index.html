<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Makemore 1.2 - trigram 1 | Emma&#39;s Blog</title>
    <meta name="generator" content="VuePress 1.9.9">
    <link rel="icon" href="/blog/img/favicon.ico">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
    <meta name="description" content="blog">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/blog/assets/css/0.styles.f2b65211.css" as="style"><link rel="preload" href="/blog/assets/js/app.fa6bfa40.js" as="script"><link rel="preload" href="/blog/assets/js/2.7ce49225.js" as="script"><link rel="preload" href="/blog/assets/js/421.9a9fcf9c.js" as="script"><link rel="prefetch" href="/blog/assets/js/10.9b4fdd47.js"><link rel="prefetch" href="/blog/assets/js/100.e7eefa33.js"><link rel="prefetch" href="/blog/assets/js/101.229b595f.js"><link rel="prefetch" href="/blog/assets/js/102.0869e27b.js"><link rel="prefetch" href="/blog/assets/js/103.67051ee3.js"><link rel="prefetch" href="/blog/assets/js/104.5e9ec206.js"><link rel="prefetch" href="/blog/assets/js/105.812b7b15.js"><link rel="prefetch" href="/blog/assets/js/106.d2afd06e.js"><link rel="prefetch" href="/blog/assets/js/107.0e992a28.js"><link rel="prefetch" href="/blog/assets/js/108.d7af612a.js"><link rel="prefetch" href="/blog/assets/js/109.0511ab99.js"><link rel="prefetch" href="/blog/assets/js/11.2658286a.js"><link rel="prefetch" href="/blog/assets/js/110.66eb4fe8.js"><link rel="prefetch" href="/blog/assets/js/111.c4a3506e.js"><link rel="prefetch" href="/blog/assets/js/112.96ad5e97.js"><link rel="prefetch" href="/blog/assets/js/113.d898d02f.js"><link rel="prefetch" href="/blog/assets/js/114.d26fe027.js"><link rel="prefetch" href="/blog/assets/js/115.adbc8f5f.js"><link rel="prefetch" href="/blog/assets/js/116.1932a92b.js"><link rel="prefetch" href="/blog/assets/js/117.969e94f6.js"><link rel="prefetch" href="/blog/assets/js/118.8a40c4b7.js"><link rel="prefetch" href="/blog/assets/js/119.4d5ac55d.js"><link rel="prefetch" href="/blog/assets/js/12.e397a550.js"><link rel="prefetch" href="/blog/assets/js/120.1ea31920.js"><link rel="prefetch" href="/blog/assets/js/121.0f8bbe64.js"><link rel="prefetch" href="/blog/assets/js/122.62cb2b98.js"><link rel="prefetch" href="/blog/assets/js/123.36fb89d8.js"><link rel="prefetch" href="/blog/assets/js/124.51e9f053.js"><link rel="prefetch" href="/blog/assets/js/125.707afbcb.js"><link rel="prefetch" href="/blog/assets/js/126.3f936437.js"><link rel="prefetch" href="/blog/assets/js/127.63ddddea.js"><link rel="prefetch" href="/blog/assets/js/128.45eedbf7.js"><link rel="prefetch" href="/blog/assets/js/129.309b8006.js"><link rel="prefetch" href="/blog/assets/js/13.19ccc9bf.js"><link rel="prefetch" href="/blog/assets/js/130.341188a0.js"><link rel="prefetch" href="/blog/assets/js/131.e6979d87.js"><link rel="prefetch" href="/blog/assets/js/132.162f434b.js"><link rel="prefetch" href="/blog/assets/js/133.3dbe6586.js"><link rel="prefetch" href="/blog/assets/js/134.020e2147.js"><link rel="prefetch" href="/blog/assets/js/135.c830889a.js"><link rel="prefetch" href="/blog/assets/js/136.1f295f91.js"><link rel="prefetch" href="/blog/assets/js/137.e7ff1cf2.js"><link rel="prefetch" href="/blog/assets/js/138.926cd296.js"><link rel="prefetch" href="/blog/assets/js/139.d8973f4f.js"><link rel="prefetch" href="/blog/assets/js/14.3973f32e.js"><link rel="prefetch" href="/blog/assets/js/140.3f410d2a.js"><link rel="prefetch" href="/blog/assets/js/141.29a6ec98.js"><link rel="prefetch" href="/blog/assets/js/142.76cee5a1.js"><link rel="prefetch" href="/blog/assets/js/143.1e68adfd.js"><link rel="prefetch" href="/blog/assets/js/144.0e90fa28.js"><link rel="prefetch" href="/blog/assets/js/145.b461e3eb.js"><link rel="prefetch" href="/blog/assets/js/146.0efa1a6d.js"><link rel="prefetch" href="/blog/assets/js/147.6cb2ae59.js"><link rel="prefetch" href="/blog/assets/js/148.7f9717b8.js"><link rel="prefetch" href="/blog/assets/js/149.b70d37e3.js"><link rel="prefetch" href="/blog/assets/js/15.60c21287.js"><link rel="prefetch" href="/blog/assets/js/150.ef9c5330.js"><link rel="prefetch" href="/blog/assets/js/151.495f2fe3.js"><link rel="prefetch" href="/blog/assets/js/152.399484c7.js"><link rel="prefetch" href="/blog/assets/js/153.b3f76d44.js"><link rel="prefetch" href="/blog/assets/js/154.9b4bcee9.js"><link rel="prefetch" href="/blog/assets/js/155.86d30484.js"><link rel="prefetch" href="/blog/assets/js/156.69309282.js"><link rel="prefetch" href="/blog/assets/js/157.50628274.js"><link rel="prefetch" href="/blog/assets/js/158.6201075e.js"><link rel="prefetch" href="/blog/assets/js/159.6b236af8.js"><link rel="prefetch" href="/blog/assets/js/16.f60df41a.js"><link rel="prefetch" href="/blog/assets/js/160.7cef879a.js"><link rel="prefetch" href="/blog/assets/js/161.e069cc00.js"><link rel="prefetch" href="/blog/assets/js/162.c840bba7.js"><link rel="prefetch" href="/blog/assets/js/163.d92fc034.js"><link rel="prefetch" href="/blog/assets/js/164.1654d287.js"><link rel="prefetch" href="/blog/assets/js/165.488a29ef.js"><link rel="prefetch" href="/blog/assets/js/166.f45211e9.js"><link rel="prefetch" href="/blog/assets/js/167.7c7dab06.js"><link rel="prefetch" href="/blog/assets/js/168.5487e398.js"><link rel="prefetch" href="/blog/assets/js/169.d33859fc.js"><link rel="prefetch" href="/blog/assets/js/17.e4f94e71.js"><link rel="prefetch" href="/blog/assets/js/170.8138d2a9.js"><link rel="prefetch" href="/blog/assets/js/171.f9803ede.js"><link rel="prefetch" href="/blog/assets/js/172.d083e11e.js"><link rel="prefetch" href="/blog/assets/js/173.8bc9a3da.js"><link rel="prefetch" href="/blog/assets/js/174.7bdf84df.js"><link rel="prefetch" href="/blog/assets/js/175.662c4a7d.js"><link rel="prefetch" href="/blog/assets/js/176.7501abe7.js"><link rel="prefetch" href="/blog/assets/js/177.27a6ea08.js"><link rel="prefetch" href="/blog/assets/js/178.542a2e15.js"><link rel="prefetch" href="/blog/assets/js/179.bd90a759.js"><link rel="prefetch" href="/blog/assets/js/18.ce8d611d.js"><link rel="prefetch" href="/blog/assets/js/180.bad5b48f.js"><link rel="prefetch" href="/blog/assets/js/181.75204ef2.js"><link rel="prefetch" href="/blog/assets/js/182.07c3b582.js"><link rel="prefetch" href="/blog/assets/js/183.684e4590.js"><link rel="prefetch" href="/blog/assets/js/184.1ddc109c.js"><link rel="prefetch" href="/blog/assets/js/185.23eefeba.js"><link rel="prefetch" href="/blog/assets/js/186.5023b10a.js"><link rel="prefetch" href="/blog/assets/js/187.82cdd79b.js"><link rel="prefetch" href="/blog/assets/js/188.dfbce339.js"><link rel="prefetch" href="/blog/assets/js/189.3c758dee.js"><link rel="prefetch" href="/blog/assets/js/19.98c0abc0.js"><link rel="prefetch" href="/blog/assets/js/190.b1eff947.js"><link rel="prefetch" href="/blog/assets/js/191.c88913b2.js"><link rel="prefetch" href="/blog/assets/js/192.54f0647d.js"><link rel="prefetch" href="/blog/assets/js/193.54d6343e.js"><link rel="prefetch" href="/blog/assets/js/194.abe54e8a.js"><link rel="prefetch" href="/blog/assets/js/195.099dd0e8.js"><link rel="prefetch" href="/blog/assets/js/196.ab3cc2bc.js"><link rel="prefetch" href="/blog/assets/js/197.a895813f.js"><link rel="prefetch" href="/blog/assets/js/198.94d4bf63.js"><link rel="prefetch" href="/blog/assets/js/199.22ba978c.js"><link rel="prefetch" href="/blog/assets/js/20.1bac6a12.js"><link rel="prefetch" href="/blog/assets/js/200.e0c0c5db.js"><link rel="prefetch" href="/blog/assets/js/201.3decc849.js"><link rel="prefetch" href="/blog/assets/js/202.ddbf28b3.js"><link rel="prefetch" href="/blog/assets/js/203.2397895a.js"><link rel="prefetch" href="/blog/assets/js/204.5f519032.js"><link rel="prefetch" href="/blog/assets/js/205.0f9caae2.js"><link rel="prefetch" href="/blog/assets/js/206.1f6339b7.js"><link rel="prefetch" href="/blog/assets/js/207.3757cf50.js"><link rel="prefetch" href="/blog/assets/js/208.a7f08e37.js"><link rel="prefetch" href="/blog/assets/js/209.c5597e2f.js"><link rel="prefetch" href="/blog/assets/js/21.5d7ecf97.js"><link rel="prefetch" href="/blog/assets/js/210.cba479b0.js"><link rel="prefetch" href="/blog/assets/js/211.0e468dce.js"><link rel="prefetch" href="/blog/assets/js/212.1276f952.js"><link rel="prefetch" href="/blog/assets/js/213.0ab1cbd2.js"><link rel="prefetch" href="/blog/assets/js/214.beab31e6.js"><link rel="prefetch" href="/blog/assets/js/215.85ce8952.js"><link rel="prefetch" href="/blog/assets/js/216.7ae13582.js"><link rel="prefetch" href="/blog/assets/js/217.21c5c4ae.js"><link rel="prefetch" href="/blog/assets/js/218.459846f9.js"><link rel="prefetch" href="/blog/assets/js/219.3ec1a6f1.js"><link rel="prefetch" href="/blog/assets/js/22.2bdcb11a.js"><link rel="prefetch" href="/blog/assets/js/220.0efee18a.js"><link rel="prefetch" href="/blog/assets/js/221.ecd509c6.js"><link rel="prefetch" href="/blog/assets/js/222.068be0e3.js"><link rel="prefetch" href="/blog/assets/js/223.0d7a3417.js"><link rel="prefetch" href="/blog/assets/js/224.e45bfd31.js"><link rel="prefetch" href="/blog/assets/js/225.c94c8651.js"><link rel="prefetch" href="/blog/assets/js/226.2dfa74fd.js"><link rel="prefetch" href="/blog/assets/js/227.38105785.js"><link rel="prefetch" href="/blog/assets/js/228.76ceed84.js"><link rel="prefetch" href="/blog/assets/js/229.54907291.js"><link rel="prefetch" href="/blog/assets/js/23.9bdaa3ab.js"><link rel="prefetch" href="/blog/assets/js/230.bab07940.js"><link rel="prefetch" href="/blog/assets/js/231.15ca6ff3.js"><link rel="prefetch" href="/blog/assets/js/232.22e17e11.js"><link rel="prefetch" href="/blog/assets/js/233.562e078c.js"><link rel="prefetch" href="/blog/assets/js/234.dba05df0.js"><link rel="prefetch" href="/blog/assets/js/235.3e377078.js"><link rel="prefetch" href="/blog/assets/js/236.ee8ef4f7.js"><link rel="prefetch" href="/blog/assets/js/237.342d5a94.js"><link rel="prefetch" href="/blog/assets/js/238.d9a5194f.js"><link rel="prefetch" href="/blog/assets/js/239.3f0ef554.js"><link rel="prefetch" href="/blog/assets/js/24.a091ba45.js"><link rel="prefetch" href="/blog/assets/js/240.73553fb4.js"><link rel="prefetch" href="/blog/assets/js/241.dc725e0b.js"><link rel="prefetch" href="/blog/assets/js/242.a19631f5.js"><link rel="prefetch" href="/blog/assets/js/243.8dad3f92.js"><link rel="prefetch" href="/blog/assets/js/244.1e7085b7.js"><link rel="prefetch" href="/blog/assets/js/245.e32e5959.js"><link rel="prefetch" href="/blog/assets/js/246.abb8f6fc.js"><link rel="prefetch" href="/blog/assets/js/247.40778e7b.js"><link rel="prefetch" href="/blog/assets/js/248.f3129994.js"><link rel="prefetch" href="/blog/assets/js/249.284fbd88.js"><link rel="prefetch" href="/blog/assets/js/25.01fddff0.js"><link rel="prefetch" href="/blog/assets/js/250.e5604caf.js"><link rel="prefetch" href="/blog/assets/js/251.4db1b5d4.js"><link rel="prefetch" href="/blog/assets/js/252.8ee09136.js"><link rel="prefetch" href="/blog/assets/js/253.886ea653.js"><link rel="prefetch" href="/blog/assets/js/254.9570cd86.js"><link rel="prefetch" href="/blog/assets/js/255.3f45535c.js"><link rel="prefetch" href="/blog/assets/js/256.5e65a4d3.js"><link rel="prefetch" href="/blog/assets/js/257.d73448be.js"><link rel="prefetch" href="/blog/assets/js/258.fd2f8dac.js"><link rel="prefetch" href="/blog/assets/js/259.41805386.js"><link rel="prefetch" href="/blog/assets/js/26.ab34c3b9.js"><link rel="prefetch" href="/blog/assets/js/260.940745e5.js"><link rel="prefetch" href="/blog/assets/js/261.4e120cbf.js"><link rel="prefetch" href="/blog/assets/js/262.387220ac.js"><link rel="prefetch" href="/blog/assets/js/263.2ce8ccb8.js"><link rel="prefetch" href="/blog/assets/js/264.f6306429.js"><link rel="prefetch" href="/blog/assets/js/265.f42b5960.js"><link rel="prefetch" href="/blog/assets/js/266.fe571a04.js"><link rel="prefetch" href="/blog/assets/js/267.cdceab63.js"><link rel="prefetch" href="/blog/assets/js/268.e76d12d5.js"><link rel="prefetch" href="/blog/assets/js/269.325b654d.js"><link rel="prefetch" href="/blog/assets/js/27.211e008f.js"><link rel="prefetch" href="/blog/assets/js/270.c5a09ebc.js"><link rel="prefetch" href="/blog/assets/js/271.8582d9ef.js"><link rel="prefetch" href="/blog/assets/js/272.25a996e7.js"><link rel="prefetch" href="/blog/assets/js/273.3cea407a.js"><link rel="prefetch" href="/blog/assets/js/274.e8037b9f.js"><link rel="prefetch" href="/blog/assets/js/275.c24fadc6.js"><link rel="prefetch" href="/blog/assets/js/276.15f6846b.js"><link rel="prefetch" href="/blog/assets/js/277.312bdd0d.js"><link rel="prefetch" href="/blog/assets/js/278.9a3d8365.js"><link rel="prefetch" href="/blog/assets/js/279.f033b4f8.js"><link rel="prefetch" href="/blog/assets/js/28.66852ae6.js"><link rel="prefetch" href="/blog/assets/js/280.35226986.js"><link rel="prefetch" href="/blog/assets/js/281.24522fa7.js"><link rel="prefetch" href="/blog/assets/js/282.2f2bf22d.js"><link rel="prefetch" href="/blog/assets/js/283.7a318e26.js"><link rel="prefetch" href="/blog/assets/js/284.dc2ed524.js"><link rel="prefetch" href="/blog/assets/js/285.0740fa3d.js"><link rel="prefetch" href="/blog/assets/js/286.d800de15.js"><link rel="prefetch" href="/blog/assets/js/287.37d62b42.js"><link rel="prefetch" href="/blog/assets/js/288.9aef5358.js"><link rel="prefetch" href="/blog/assets/js/289.2bf079d7.js"><link rel="prefetch" href="/blog/assets/js/29.141730bc.js"><link rel="prefetch" href="/blog/assets/js/290.23861619.js"><link rel="prefetch" href="/blog/assets/js/291.b90053de.js"><link rel="prefetch" href="/blog/assets/js/292.1ecc1810.js"><link rel="prefetch" href="/blog/assets/js/293.162a2bfd.js"><link rel="prefetch" href="/blog/assets/js/294.7e872ddf.js"><link rel="prefetch" href="/blog/assets/js/295.a67c9dc4.js"><link rel="prefetch" href="/blog/assets/js/296.cd5f1739.js"><link rel="prefetch" href="/blog/assets/js/297.5fba221f.js"><link rel="prefetch" href="/blog/assets/js/298.2698065d.js"><link rel="prefetch" href="/blog/assets/js/299.9ad4582c.js"><link rel="prefetch" href="/blog/assets/js/3.fb6b6218.js"><link rel="prefetch" href="/blog/assets/js/30.057cc531.js"><link rel="prefetch" href="/blog/assets/js/300.52c1803f.js"><link rel="prefetch" href="/blog/assets/js/301.b03a706d.js"><link rel="prefetch" href="/blog/assets/js/302.8ea88eb9.js"><link rel="prefetch" href="/blog/assets/js/303.1502ae39.js"><link rel="prefetch" href="/blog/assets/js/304.f20513d3.js"><link rel="prefetch" href="/blog/assets/js/305.aa35fcf1.js"><link rel="prefetch" href="/blog/assets/js/306.1897421f.js"><link rel="prefetch" href="/blog/assets/js/307.c3d97536.js"><link rel="prefetch" href="/blog/assets/js/308.4f22d76b.js"><link rel="prefetch" href="/blog/assets/js/309.7e7f7c52.js"><link rel="prefetch" href="/blog/assets/js/31.0a0b4625.js"><link rel="prefetch" href="/blog/assets/js/310.2e22d9e1.js"><link rel="prefetch" href="/blog/assets/js/311.974bbf97.js"><link rel="prefetch" href="/blog/assets/js/312.f28c61dc.js"><link rel="prefetch" href="/blog/assets/js/313.3c51e0fa.js"><link rel="prefetch" href="/blog/assets/js/314.d998ea43.js"><link rel="prefetch" href="/blog/assets/js/315.3e9a511f.js"><link rel="prefetch" href="/blog/assets/js/316.5969895b.js"><link rel="prefetch" href="/blog/assets/js/317.fc61c649.js"><link rel="prefetch" href="/blog/assets/js/318.0e38281f.js"><link rel="prefetch" href="/blog/assets/js/319.3c721d92.js"><link rel="prefetch" href="/blog/assets/js/32.ea991562.js"><link rel="prefetch" href="/blog/assets/js/320.b4ab4b4f.js"><link rel="prefetch" href="/blog/assets/js/321.56f69d1a.js"><link rel="prefetch" href="/blog/assets/js/322.20ab832b.js"><link rel="prefetch" href="/blog/assets/js/323.4b2d7ea3.js"><link rel="prefetch" href="/blog/assets/js/324.d81f5847.js"><link rel="prefetch" href="/blog/assets/js/325.7edfab8f.js"><link rel="prefetch" href="/blog/assets/js/326.45f4da77.js"><link rel="prefetch" href="/blog/assets/js/327.ba458f2c.js"><link rel="prefetch" href="/blog/assets/js/328.d86d670d.js"><link rel="prefetch" href="/blog/assets/js/329.f7eac607.js"><link rel="prefetch" href="/blog/assets/js/33.59727a1a.js"><link rel="prefetch" href="/blog/assets/js/330.10d24789.js"><link rel="prefetch" href="/blog/assets/js/331.60d73f78.js"><link rel="prefetch" href="/blog/assets/js/332.6c5b6b35.js"><link rel="prefetch" href="/blog/assets/js/333.7b1b290d.js"><link rel="prefetch" href="/blog/assets/js/334.285526b7.js"><link rel="prefetch" href="/blog/assets/js/335.4780d81e.js"><link rel="prefetch" href="/blog/assets/js/336.5ecc836e.js"><link rel="prefetch" href="/blog/assets/js/337.6fba51e2.js"><link rel="prefetch" href="/blog/assets/js/338.d646ffe0.js"><link rel="prefetch" href="/blog/assets/js/339.45c11835.js"><link rel="prefetch" href="/blog/assets/js/34.e0063628.js"><link rel="prefetch" href="/blog/assets/js/340.f3ae78d4.js"><link rel="prefetch" href="/blog/assets/js/341.0e5e0af1.js"><link rel="prefetch" href="/blog/assets/js/342.5e9536e2.js"><link rel="prefetch" href="/blog/assets/js/343.d2f5b148.js"><link rel="prefetch" href="/blog/assets/js/344.b076b331.js"><link rel="prefetch" href="/blog/assets/js/345.ccb92f9a.js"><link rel="prefetch" href="/blog/assets/js/346.c1d7088c.js"><link rel="prefetch" href="/blog/assets/js/347.76e6b595.js"><link rel="prefetch" href="/blog/assets/js/348.d08fd4eb.js"><link rel="prefetch" href="/blog/assets/js/349.b0633c03.js"><link rel="prefetch" href="/blog/assets/js/35.d02fcd5b.js"><link rel="prefetch" href="/blog/assets/js/350.58bd91c8.js"><link rel="prefetch" href="/blog/assets/js/351.4eeb8781.js"><link rel="prefetch" href="/blog/assets/js/352.92e0273b.js"><link rel="prefetch" href="/blog/assets/js/353.4316b720.js"><link rel="prefetch" href="/blog/assets/js/354.8b1ec3de.js"><link rel="prefetch" href="/blog/assets/js/355.d09b94bf.js"><link rel="prefetch" href="/blog/assets/js/356.5b548a21.js"><link rel="prefetch" href="/blog/assets/js/357.deef470d.js"><link rel="prefetch" href="/blog/assets/js/358.1b8619f3.js"><link rel="prefetch" href="/blog/assets/js/359.62109421.js"><link rel="prefetch" href="/blog/assets/js/36.9a2bf2cb.js"><link rel="prefetch" href="/blog/assets/js/360.b0fbc8bc.js"><link rel="prefetch" href="/blog/assets/js/361.9f4082fe.js"><link rel="prefetch" href="/blog/assets/js/362.998cb7ce.js"><link rel="prefetch" href="/blog/assets/js/363.59416eb7.js"><link rel="prefetch" href="/blog/assets/js/364.673a993e.js"><link rel="prefetch" href="/blog/assets/js/365.2ce18574.js"><link rel="prefetch" href="/blog/assets/js/366.06fb2db3.js"><link rel="prefetch" href="/blog/assets/js/367.82a80c1b.js"><link rel="prefetch" href="/blog/assets/js/368.c6eded31.js"><link rel="prefetch" href="/blog/assets/js/369.cf8dcc59.js"><link rel="prefetch" href="/blog/assets/js/37.14ce705f.js"><link rel="prefetch" href="/blog/assets/js/370.cc5c5295.js"><link rel="prefetch" href="/blog/assets/js/371.03d01383.js"><link rel="prefetch" href="/blog/assets/js/372.84d458d3.js"><link rel="prefetch" href="/blog/assets/js/373.69e36286.js"><link rel="prefetch" href="/blog/assets/js/374.325318a2.js"><link rel="prefetch" href="/blog/assets/js/375.0faf9354.js"><link rel="prefetch" href="/blog/assets/js/376.e383d5f8.js"><link rel="prefetch" href="/blog/assets/js/377.a45039dd.js"><link rel="prefetch" href="/blog/assets/js/378.e6bf1f8a.js"><link rel="prefetch" href="/blog/assets/js/379.ab3908c4.js"><link rel="prefetch" href="/blog/assets/js/38.d8358ff1.js"><link rel="prefetch" href="/blog/assets/js/380.9155ba09.js"><link rel="prefetch" href="/blog/assets/js/381.964c9828.js"><link rel="prefetch" href="/blog/assets/js/382.b2c17375.js"><link rel="prefetch" href="/blog/assets/js/383.f74bb63d.js"><link rel="prefetch" href="/blog/assets/js/384.f46a5f9f.js"><link rel="prefetch" href="/blog/assets/js/385.2b0fad5e.js"><link rel="prefetch" href="/blog/assets/js/386.b7fd30fd.js"><link rel="prefetch" href="/blog/assets/js/387.e387b6d2.js"><link rel="prefetch" href="/blog/assets/js/388.66733dc7.js"><link rel="prefetch" href="/blog/assets/js/389.3b9dc956.js"><link rel="prefetch" href="/blog/assets/js/39.52d6d224.js"><link rel="prefetch" href="/blog/assets/js/390.aa1a3f13.js"><link rel="prefetch" href="/blog/assets/js/391.b98a3f89.js"><link rel="prefetch" href="/blog/assets/js/392.51947d62.js"><link rel="prefetch" href="/blog/assets/js/393.4e8ca73f.js"><link rel="prefetch" href="/blog/assets/js/394.4eae3c2a.js"><link rel="prefetch" href="/blog/assets/js/395.b41e57dd.js"><link rel="prefetch" href="/blog/assets/js/396.f19229fd.js"><link rel="prefetch" href="/blog/assets/js/397.8caf94d9.js"><link rel="prefetch" href="/blog/assets/js/398.a79fa068.js"><link rel="prefetch" href="/blog/assets/js/399.1f8f72a8.js"><link rel="prefetch" href="/blog/assets/js/4.72adf461.js"><link rel="prefetch" href="/blog/assets/js/40.42598248.js"><link rel="prefetch" href="/blog/assets/js/400.31d2590c.js"><link rel="prefetch" href="/blog/assets/js/401.430ee10a.js"><link rel="prefetch" href="/blog/assets/js/402.0969de14.js"><link rel="prefetch" href="/blog/assets/js/403.22305621.js"><link rel="prefetch" href="/blog/assets/js/404.c24c1ea8.js"><link rel="prefetch" href="/blog/assets/js/405.a7531e74.js"><link rel="prefetch" href="/blog/assets/js/406.44308bfa.js"><link rel="prefetch" href="/blog/assets/js/407.5bea8380.js"><link rel="prefetch" href="/blog/assets/js/408.47124f69.js"><link rel="prefetch" href="/blog/assets/js/409.f2eb55a4.js"><link rel="prefetch" href="/blog/assets/js/41.78de33b5.js"><link rel="prefetch" href="/blog/assets/js/410.75f37834.js"><link rel="prefetch" href="/blog/assets/js/411.af5a1d9f.js"><link rel="prefetch" href="/blog/assets/js/412.70ce0662.js"><link rel="prefetch" href="/blog/assets/js/413.4773178b.js"><link rel="prefetch" href="/blog/assets/js/414.b91b3c53.js"><link rel="prefetch" href="/blog/assets/js/415.93254e87.js"><link rel="prefetch" href="/blog/assets/js/416.30e849d5.js"><link rel="prefetch" href="/blog/assets/js/417.1d626e6d.js"><link rel="prefetch" href="/blog/assets/js/418.c2830038.js"><link rel="prefetch" href="/blog/assets/js/419.de704363.js"><link rel="prefetch" href="/blog/assets/js/42.f02bfe3b.js"><link rel="prefetch" href="/blog/assets/js/420.934cfa49.js"><link rel="prefetch" href="/blog/assets/js/422.716d7de1.js"><link rel="prefetch" href="/blog/assets/js/423.5502a762.js"><link rel="prefetch" href="/blog/assets/js/424.9362a268.js"><link rel="prefetch" href="/blog/assets/js/425.40010459.js"><link rel="prefetch" href="/blog/assets/js/426.9012302f.js"><link rel="prefetch" href="/blog/assets/js/427.2f4f8329.js"><link rel="prefetch" href="/blog/assets/js/428.48911c6b.js"><link rel="prefetch" href="/blog/assets/js/429.6beb6f8a.js"><link rel="prefetch" href="/blog/assets/js/43.027dffdd.js"><link rel="prefetch" href="/blog/assets/js/430.20547f3b.js"><link rel="prefetch" href="/blog/assets/js/431.f7d8b272.js"><link rel="prefetch" href="/blog/assets/js/432.29f6c6c5.js"><link rel="prefetch" href="/blog/assets/js/433.053472dd.js"><link rel="prefetch" href="/blog/assets/js/434.fe7a6b42.js"><link rel="prefetch" href="/blog/assets/js/435.7b095c52.js"><link rel="prefetch" href="/blog/assets/js/436.8e65b85b.js"><link rel="prefetch" href="/blog/assets/js/437.6f2be763.js"><link rel="prefetch" href="/blog/assets/js/438.696a4a24.js"><link rel="prefetch" href="/blog/assets/js/439.8e0ffda2.js"><link rel="prefetch" href="/blog/assets/js/44.60d7bff7.js"><link rel="prefetch" href="/blog/assets/js/440.0f9d7601.js"><link rel="prefetch" href="/blog/assets/js/441.9293a0c0.js"><link rel="prefetch" href="/blog/assets/js/442.3ab911fb.js"><link rel="prefetch" href="/blog/assets/js/443.84e874a2.js"><link rel="prefetch" href="/blog/assets/js/444.a5560886.js"><link rel="prefetch" href="/blog/assets/js/445.ee43400f.js"><link rel="prefetch" href="/blog/assets/js/446.e451b4a7.js"><link rel="prefetch" href="/blog/assets/js/447.af57b4dd.js"><link rel="prefetch" href="/blog/assets/js/448.8369a48d.js"><link rel="prefetch" href="/blog/assets/js/449.81a81117.js"><link rel="prefetch" href="/blog/assets/js/45.54197661.js"><link rel="prefetch" href="/blog/assets/js/450.ed1865ae.js"><link rel="prefetch" href="/blog/assets/js/451.c6fed955.js"><link rel="prefetch" href="/blog/assets/js/452.c490fd3f.js"><link rel="prefetch" href="/blog/assets/js/453.ce54e414.js"><link rel="prefetch" href="/blog/assets/js/454.0fcc3b33.js"><link rel="prefetch" href="/blog/assets/js/455.49b6deb2.js"><link rel="prefetch" href="/blog/assets/js/456.cea18d70.js"><link rel="prefetch" href="/blog/assets/js/457.eeb4e4ea.js"><link rel="prefetch" href="/blog/assets/js/458.6536f79d.js"><link rel="prefetch" href="/blog/assets/js/459.08049472.js"><link rel="prefetch" href="/blog/assets/js/46.2ea156c5.js"><link rel="prefetch" href="/blog/assets/js/460.ce2134bf.js"><link rel="prefetch" href="/blog/assets/js/461.4ef74cbc.js"><link rel="prefetch" href="/blog/assets/js/462.0135ab05.js"><link rel="prefetch" href="/blog/assets/js/463.75c97bc9.js"><link rel="prefetch" href="/blog/assets/js/464.0731e3a8.js"><link rel="prefetch" href="/blog/assets/js/465.58716aaa.js"><link rel="prefetch" href="/blog/assets/js/466.5d1c9632.js"><link rel="prefetch" href="/blog/assets/js/467.4a0cc264.js"><link rel="prefetch" href="/blog/assets/js/468.4d62ec95.js"><link rel="prefetch" href="/blog/assets/js/469.371bf824.js"><link rel="prefetch" href="/blog/assets/js/47.9c2846f6.js"><link rel="prefetch" href="/blog/assets/js/470.20c9b1d0.js"><link rel="prefetch" href="/blog/assets/js/471.b55b7293.js"><link rel="prefetch" href="/blog/assets/js/472.af9bed94.js"><link rel="prefetch" href="/blog/assets/js/473.763ed78b.js"><link rel="prefetch" href="/blog/assets/js/474.0c984479.js"><link rel="prefetch" href="/blog/assets/js/475.64086e43.js"><link rel="prefetch" href="/blog/assets/js/476.87a9a0cc.js"><link rel="prefetch" href="/blog/assets/js/477.bf829a5b.js"><link rel="prefetch" href="/blog/assets/js/478.e4b446ce.js"><link rel="prefetch" href="/blog/assets/js/479.2b9f77a6.js"><link rel="prefetch" href="/blog/assets/js/48.9a1455cf.js"><link rel="prefetch" href="/blog/assets/js/480.17cc6a47.js"><link rel="prefetch" href="/blog/assets/js/481.fa5b561f.js"><link rel="prefetch" href="/blog/assets/js/482.03b3eb32.js"><link rel="prefetch" href="/blog/assets/js/483.31191665.js"><link rel="prefetch" href="/blog/assets/js/484.d8a4c9bc.js"><link rel="prefetch" href="/blog/assets/js/485.e249dec7.js"><link rel="prefetch" href="/blog/assets/js/486.0fc0098f.js"><link rel="prefetch" href="/blog/assets/js/487.324062ec.js"><link rel="prefetch" href="/blog/assets/js/488.8ca4dee4.js"><link rel="prefetch" href="/blog/assets/js/489.efc83e4a.js"><link rel="prefetch" href="/blog/assets/js/49.697a7a9f.js"><link rel="prefetch" href="/blog/assets/js/490.45710d33.js"><link rel="prefetch" href="/blog/assets/js/491.8642a532.js"><link rel="prefetch" href="/blog/assets/js/492.6fd7cdf1.js"><link rel="prefetch" href="/blog/assets/js/493.e66269d0.js"><link rel="prefetch" href="/blog/assets/js/494.8617e18f.js"><link rel="prefetch" href="/blog/assets/js/495.a701486e.js"><link rel="prefetch" href="/blog/assets/js/496.6c880390.js"><link rel="prefetch" href="/blog/assets/js/497.d270d556.js"><link rel="prefetch" href="/blog/assets/js/498.88cbb5cd.js"><link rel="prefetch" href="/blog/assets/js/499.9e5d240e.js"><link rel="prefetch" href="/blog/assets/js/5.15a5c21b.js"><link rel="prefetch" href="/blog/assets/js/50.c6827336.js"><link rel="prefetch" href="/blog/assets/js/500.75b98d7e.js"><link rel="prefetch" href="/blog/assets/js/501.56835982.js"><link rel="prefetch" href="/blog/assets/js/502.6b40298b.js"><link rel="prefetch" href="/blog/assets/js/503.c1d698cc.js"><link rel="prefetch" href="/blog/assets/js/504.ccad05c2.js"><link rel="prefetch" href="/blog/assets/js/505.6f0caa3b.js"><link rel="prefetch" href="/blog/assets/js/506.aebe2376.js"><link rel="prefetch" href="/blog/assets/js/507.211ef741.js"><link rel="prefetch" href="/blog/assets/js/508.fa181cc2.js"><link rel="prefetch" href="/blog/assets/js/509.3d4bb4eb.js"><link rel="prefetch" href="/blog/assets/js/51.e12228d3.js"><link rel="prefetch" href="/blog/assets/js/510.7bc8cf92.js"><link rel="prefetch" href="/blog/assets/js/511.11fdfdc1.js"><link rel="prefetch" href="/blog/assets/js/512.ecc52d98.js"><link rel="prefetch" href="/blog/assets/js/513.7297573b.js"><link rel="prefetch" href="/blog/assets/js/514.7b747cce.js"><link rel="prefetch" href="/blog/assets/js/515.026fed32.js"><link rel="prefetch" href="/blog/assets/js/516.ed28c764.js"><link rel="prefetch" href="/blog/assets/js/517.2f57e972.js"><link rel="prefetch" href="/blog/assets/js/518.f88b52b4.js"><link rel="prefetch" href="/blog/assets/js/519.7c75386a.js"><link rel="prefetch" href="/blog/assets/js/52.c2faa40b.js"><link rel="prefetch" href="/blog/assets/js/520.75a48154.js"><link rel="prefetch" href="/blog/assets/js/521.895157dd.js"><link rel="prefetch" href="/blog/assets/js/522.7d0e847a.js"><link rel="prefetch" href="/blog/assets/js/523.01484cdc.js"><link rel="prefetch" href="/blog/assets/js/524.4d90ab64.js"><link rel="prefetch" href="/blog/assets/js/525.d1549e6c.js"><link rel="prefetch" href="/blog/assets/js/526.05483b68.js"><link rel="prefetch" href="/blog/assets/js/527.c3429fe2.js"><link rel="prefetch" href="/blog/assets/js/528.6203d42b.js"><link rel="prefetch" href="/blog/assets/js/529.5d865bd5.js"><link rel="prefetch" href="/blog/assets/js/53.5709a523.js"><link rel="prefetch" href="/blog/assets/js/530.a70a1acb.js"><link rel="prefetch" href="/blog/assets/js/531.66905b3e.js"><link rel="prefetch" href="/blog/assets/js/532.9f948fd2.js"><link rel="prefetch" href="/blog/assets/js/533.9c3dcf3c.js"><link rel="prefetch" href="/blog/assets/js/534.bcecc9a9.js"><link rel="prefetch" href="/blog/assets/js/535.01da0e85.js"><link rel="prefetch" href="/blog/assets/js/536.18503588.js"><link rel="prefetch" href="/blog/assets/js/537.3b07f2d9.js"><link rel="prefetch" href="/blog/assets/js/538.5435ae36.js"><link rel="prefetch" href="/blog/assets/js/539.bb504961.js"><link rel="prefetch" href="/blog/assets/js/54.07a4a582.js"><link rel="prefetch" href="/blog/assets/js/540.dc306ab2.js"><link rel="prefetch" href="/blog/assets/js/541.3a27f51c.js"><link rel="prefetch" href="/blog/assets/js/542.5760d344.js"><link rel="prefetch" href="/blog/assets/js/543.c2b318db.js"><link rel="prefetch" href="/blog/assets/js/544.3e7dfe68.js"><link rel="prefetch" href="/blog/assets/js/545.b9d38be9.js"><link rel="prefetch" href="/blog/assets/js/546.57f76a93.js"><link rel="prefetch" href="/blog/assets/js/547.a24678cb.js"><link rel="prefetch" href="/blog/assets/js/548.92a9e320.js"><link rel="prefetch" href="/blog/assets/js/549.ba3f7475.js"><link rel="prefetch" href="/blog/assets/js/55.f0ff0d7c.js"><link rel="prefetch" href="/blog/assets/js/550.85bf139d.js"><link rel="prefetch" href="/blog/assets/js/551.36783254.js"><link rel="prefetch" href="/blog/assets/js/552.e5e86f31.js"><link rel="prefetch" href="/blog/assets/js/553.7be649df.js"><link rel="prefetch" href="/blog/assets/js/554.8be323b3.js"><link rel="prefetch" href="/blog/assets/js/555.97049205.js"><link rel="prefetch" href="/blog/assets/js/556.a85939ec.js"><link rel="prefetch" href="/blog/assets/js/557.f0ea5bef.js"><link rel="prefetch" href="/blog/assets/js/558.f8d4d2d7.js"><link rel="prefetch" href="/blog/assets/js/559.2ef926c7.js"><link rel="prefetch" href="/blog/assets/js/56.c0cbcd65.js"><link rel="prefetch" href="/blog/assets/js/560.56eb82c5.js"><link rel="prefetch" href="/blog/assets/js/561.03a320f1.js"><link rel="prefetch" href="/blog/assets/js/562.649a7599.js"><link rel="prefetch" href="/blog/assets/js/563.8721466c.js"><link rel="prefetch" href="/blog/assets/js/564.3baad1bf.js"><link rel="prefetch" href="/blog/assets/js/565.e5e5c627.js"><link rel="prefetch" href="/blog/assets/js/566.315c4528.js"><link rel="prefetch" href="/blog/assets/js/567.b12e27ea.js"><link rel="prefetch" href="/blog/assets/js/568.225226ec.js"><link rel="prefetch" href="/blog/assets/js/569.da29d7d5.js"><link rel="prefetch" href="/blog/assets/js/57.19d05b74.js"><link rel="prefetch" href="/blog/assets/js/570.acc63d86.js"><link rel="prefetch" href="/blog/assets/js/571.a1637cdc.js"><link rel="prefetch" href="/blog/assets/js/572.bb88c6a3.js"><link rel="prefetch" href="/blog/assets/js/573.3fdb3549.js"><link rel="prefetch" href="/blog/assets/js/574.e83e19eb.js"><link rel="prefetch" href="/blog/assets/js/575.4314526d.js"><link rel="prefetch" href="/blog/assets/js/576.45816383.js"><link rel="prefetch" href="/blog/assets/js/577.27b63977.js"><link rel="prefetch" href="/blog/assets/js/578.20d32e8a.js"><link rel="prefetch" href="/blog/assets/js/579.55cf4824.js"><link rel="prefetch" href="/blog/assets/js/58.6e93d3bf.js"><link rel="prefetch" href="/blog/assets/js/580.d531b052.js"><link rel="prefetch" href="/blog/assets/js/581.f627031b.js"><link rel="prefetch" href="/blog/assets/js/582.7a256d37.js"><link rel="prefetch" href="/blog/assets/js/583.7e6734b3.js"><link rel="prefetch" href="/blog/assets/js/584.dfb3a9cb.js"><link rel="prefetch" href="/blog/assets/js/585.a71b9e6e.js"><link rel="prefetch" href="/blog/assets/js/586.5137eb0c.js"><link rel="prefetch" href="/blog/assets/js/587.5b00ff50.js"><link rel="prefetch" href="/blog/assets/js/588.6683a53f.js"><link rel="prefetch" href="/blog/assets/js/589.c2bb0000.js"><link rel="prefetch" href="/blog/assets/js/59.74303d32.js"><link rel="prefetch" href="/blog/assets/js/590.ac1e550c.js"><link rel="prefetch" href="/blog/assets/js/591.124f0d02.js"><link rel="prefetch" href="/blog/assets/js/592.c930684a.js"><link rel="prefetch" href="/blog/assets/js/593.5010d3e0.js"><link rel="prefetch" href="/blog/assets/js/594.26376a7e.js"><link rel="prefetch" href="/blog/assets/js/595.b0a30b26.js"><link rel="prefetch" href="/blog/assets/js/596.b3f21662.js"><link rel="prefetch" href="/blog/assets/js/597.c26a075e.js"><link rel="prefetch" href="/blog/assets/js/598.baaa2008.js"><link rel="prefetch" href="/blog/assets/js/599.76aefe16.js"><link rel="prefetch" href="/blog/assets/js/6.c39ed483.js"><link rel="prefetch" href="/blog/assets/js/60.ef364511.js"><link rel="prefetch" href="/blog/assets/js/600.adf240b2.js"><link rel="prefetch" href="/blog/assets/js/601.e5c38ddf.js"><link rel="prefetch" href="/blog/assets/js/602.c9ffa321.js"><link rel="prefetch" href="/blog/assets/js/603.36192b41.js"><link rel="prefetch" href="/blog/assets/js/604.5c4f5034.js"><link rel="prefetch" href="/blog/assets/js/605.51fbb0a4.js"><link rel="prefetch" href="/blog/assets/js/606.88fe8276.js"><link rel="prefetch" href="/blog/assets/js/607.7dc7d0b1.js"><link rel="prefetch" href="/blog/assets/js/608.0b5d9f52.js"><link rel="prefetch" href="/blog/assets/js/609.a7830f0c.js"><link rel="prefetch" href="/blog/assets/js/61.436e46a1.js"><link rel="prefetch" href="/blog/assets/js/610.031fa893.js"><link rel="prefetch" href="/blog/assets/js/611.90e0e4d3.js"><link rel="prefetch" href="/blog/assets/js/612.2b9a79d8.js"><link rel="prefetch" href="/blog/assets/js/613.d38f2851.js"><link rel="prefetch" href="/blog/assets/js/614.6cfef72e.js"><link rel="prefetch" href="/blog/assets/js/615.73222425.js"><link rel="prefetch" href="/blog/assets/js/616.771db440.js"><link rel="prefetch" href="/blog/assets/js/617.a4729ad6.js"><link rel="prefetch" href="/blog/assets/js/618.5ea9e128.js"><link rel="prefetch" href="/blog/assets/js/619.10f5472f.js"><link rel="prefetch" href="/blog/assets/js/62.9490960b.js"><link rel="prefetch" href="/blog/assets/js/620.d0069dce.js"><link rel="prefetch" href="/blog/assets/js/621.d19ea508.js"><link rel="prefetch" href="/blog/assets/js/622.9e5920b2.js"><link rel="prefetch" href="/blog/assets/js/623.78d93448.js"><link rel="prefetch" href="/blog/assets/js/624.d37d7fce.js"><link rel="prefetch" href="/blog/assets/js/625.447be412.js"><link rel="prefetch" href="/blog/assets/js/626.e59af340.js"><link rel="prefetch" href="/blog/assets/js/627.7e6d7c95.js"><link rel="prefetch" href="/blog/assets/js/628.d135b01b.js"><link rel="prefetch" href="/blog/assets/js/629.8886d8ea.js"><link rel="prefetch" href="/blog/assets/js/63.6cc1bcab.js"><link rel="prefetch" href="/blog/assets/js/630.22d4ced4.js"><link rel="prefetch" href="/blog/assets/js/631.9e7843f6.js"><link rel="prefetch" href="/blog/assets/js/632.4803808d.js"><link rel="prefetch" href="/blog/assets/js/633.50e4112f.js"><link rel="prefetch" href="/blog/assets/js/634.bb993c38.js"><link rel="prefetch" href="/blog/assets/js/635.5d6b9e6f.js"><link rel="prefetch" href="/blog/assets/js/636.9b48556d.js"><link rel="prefetch" href="/blog/assets/js/637.c42758ba.js"><link rel="prefetch" href="/blog/assets/js/638.68cc6fae.js"><link rel="prefetch" href="/blog/assets/js/639.169fa156.js"><link rel="prefetch" href="/blog/assets/js/64.abdee43a.js"><link rel="prefetch" href="/blog/assets/js/640.fbe8a02e.js"><link rel="prefetch" href="/blog/assets/js/641.ec22012c.js"><link rel="prefetch" href="/blog/assets/js/642.d4d1938f.js"><link rel="prefetch" href="/blog/assets/js/643.10235c62.js"><link rel="prefetch" href="/blog/assets/js/644.c1fadb2f.js"><link rel="prefetch" href="/blog/assets/js/645.c149df88.js"><link rel="prefetch" href="/blog/assets/js/646.c6c3f8e0.js"><link rel="prefetch" href="/blog/assets/js/647.6958847b.js"><link rel="prefetch" href="/blog/assets/js/648.5c76d596.js"><link rel="prefetch" href="/blog/assets/js/649.d6beec02.js"><link rel="prefetch" href="/blog/assets/js/65.68211d02.js"><link rel="prefetch" href="/blog/assets/js/650.89cbe447.js"><link rel="prefetch" href="/blog/assets/js/651.92467f48.js"><link rel="prefetch" href="/blog/assets/js/652.4845f96a.js"><link rel="prefetch" href="/blog/assets/js/653.a47fdb3b.js"><link rel="prefetch" href="/blog/assets/js/654.fcea3f5b.js"><link rel="prefetch" href="/blog/assets/js/655.4e38720d.js"><link rel="prefetch" href="/blog/assets/js/656.a397f16b.js"><link rel="prefetch" href="/blog/assets/js/657.dde34611.js"><link rel="prefetch" href="/blog/assets/js/658.0039ce51.js"><link rel="prefetch" href="/blog/assets/js/659.a0c401bc.js"><link rel="prefetch" href="/blog/assets/js/66.82efb6b8.js"><link rel="prefetch" href="/blog/assets/js/660.23dd5e68.js"><link rel="prefetch" href="/blog/assets/js/661.bc079b94.js"><link rel="prefetch" href="/blog/assets/js/662.f43d86c6.js"><link rel="prefetch" href="/blog/assets/js/663.a612b987.js"><link rel="prefetch" href="/blog/assets/js/664.f19257f7.js"><link rel="prefetch" href="/blog/assets/js/665.0cbf6fc1.js"><link rel="prefetch" href="/blog/assets/js/666.7a7c5b50.js"><link rel="prefetch" href="/blog/assets/js/667.70bcb46c.js"><link rel="prefetch" href="/blog/assets/js/668.c1c81ab6.js"><link rel="prefetch" href="/blog/assets/js/669.75638ed7.js"><link rel="prefetch" href="/blog/assets/js/67.9f6abed5.js"><link rel="prefetch" href="/blog/assets/js/670.2f90459b.js"><link rel="prefetch" href="/blog/assets/js/671.2ab85c06.js"><link rel="prefetch" href="/blog/assets/js/672.6975af2f.js"><link rel="prefetch" href="/blog/assets/js/673.4a5e0d55.js"><link rel="prefetch" href="/blog/assets/js/674.4b1db2e3.js"><link rel="prefetch" href="/blog/assets/js/675.162422a7.js"><link rel="prefetch" href="/blog/assets/js/676.5712b341.js"><link rel="prefetch" href="/blog/assets/js/677.f0d472cb.js"><link rel="prefetch" href="/blog/assets/js/678.a25199d2.js"><link rel="prefetch" href="/blog/assets/js/679.eebf998e.js"><link rel="prefetch" href="/blog/assets/js/68.b54c5d39.js"><link rel="prefetch" href="/blog/assets/js/680.9b45dc26.js"><link rel="prefetch" href="/blog/assets/js/681.d998bda3.js"><link rel="prefetch" href="/blog/assets/js/682.26a6b3b8.js"><link rel="prefetch" href="/blog/assets/js/683.3d3255b3.js"><link rel="prefetch" href="/blog/assets/js/684.01350009.js"><link rel="prefetch" href="/blog/assets/js/685.d94d2d49.js"><link rel="prefetch" href="/blog/assets/js/686.14b9a854.js"><link rel="prefetch" href="/blog/assets/js/687.6801763c.js"><link rel="prefetch" href="/blog/assets/js/688.c869d83c.js"><link rel="prefetch" href="/blog/assets/js/689.721c5842.js"><link rel="prefetch" href="/blog/assets/js/69.96961d17.js"><link rel="prefetch" href="/blog/assets/js/690.c58e3111.js"><link rel="prefetch" href="/blog/assets/js/691.a3ba298b.js"><link rel="prefetch" href="/blog/assets/js/692.976c9961.js"><link rel="prefetch" href="/blog/assets/js/693.dfa1dc96.js"><link rel="prefetch" href="/blog/assets/js/694.d5095ad8.js"><link rel="prefetch" href="/blog/assets/js/695.75a9299f.js"><link rel="prefetch" href="/blog/assets/js/696.47cd8b93.js"><link rel="prefetch" href="/blog/assets/js/697.f7bd7f56.js"><link rel="prefetch" href="/blog/assets/js/698.bfe02dd1.js"><link rel="prefetch" href="/blog/assets/js/699.5b6fee9c.js"><link rel="prefetch" href="/blog/assets/js/7.8763782e.js"><link rel="prefetch" href="/blog/assets/js/70.1c7c67c2.js"><link rel="prefetch" href="/blog/assets/js/700.49ecc111.js"><link rel="prefetch" href="/blog/assets/js/701.b19efefd.js"><link rel="prefetch" href="/blog/assets/js/702.d89fba61.js"><link rel="prefetch" href="/blog/assets/js/703.cbbe6ab7.js"><link rel="prefetch" href="/blog/assets/js/704.f221501a.js"><link rel="prefetch" href="/blog/assets/js/705.9b1567f8.js"><link rel="prefetch" href="/blog/assets/js/706.83b5a9bc.js"><link rel="prefetch" href="/blog/assets/js/707.38bfe6a4.js"><link rel="prefetch" href="/blog/assets/js/708.c4a02d49.js"><link rel="prefetch" href="/blog/assets/js/709.c37c1d0b.js"><link rel="prefetch" href="/blog/assets/js/71.136106d8.js"><link rel="prefetch" href="/blog/assets/js/710.b6daefb8.js"><link rel="prefetch" href="/blog/assets/js/711.60a8d807.js"><link rel="prefetch" href="/blog/assets/js/712.f1600b25.js"><link rel="prefetch" href="/blog/assets/js/713.9b84fe0f.js"><link rel="prefetch" href="/blog/assets/js/714.85f8dfd7.js"><link rel="prefetch" href="/blog/assets/js/715.2e7ac623.js"><link rel="prefetch" href="/blog/assets/js/716.d4016dae.js"><link rel="prefetch" href="/blog/assets/js/72.d1192ec4.js"><link rel="prefetch" href="/blog/assets/js/73.cefbd395.js"><link rel="prefetch" href="/blog/assets/js/74.f7652c2d.js"><link rel="prefetch" href="/blog/assets/js/75.93794018.js"><link rel="prefetch" href="/blog/assets/js/76.ea74a9e5.js"><link rel="prefetch" href="/blog/assets/js/77.5ab8d933.js"><link rel="prefetch" href="/blog/assets/js/78.d99be8f9.js"><link rel="prefetch" href="/blog/assets/js/79.514e7b92.js"><link rel="prefetch" href="/blog/assets/js/8.4f413a3f.js"><link rel="prefetch" href="/blog/assets/js/80.311c1c3d.js"><link rel="prefetch" href="/blog/assets/js/81.20e611a2.js"><link rel="prefetch" href="/blog/assets/js/82.33311f3c.js"><link rel="prefetch" href="/blog/assets/js/83.d0445fd9.js"><link rel="prefetch" href="/blog/assets/js/84.cdf6237f.js"><link rel="prefetch" href="/blog/assets/js/85.39e8a5b1.js"><link rel="prefetch" href="/blog/assets/js/86.5c32af0a.js"><link rel="prefetch" href="/blog/assets/js/87.66683f39.js"><link rel="prefetch" href="/blog/assets/js/88.7ad0a079.js"><link rel="prefetch" href="/blog/assets/js/89.2d677ef4.js"><link rel="prefetch" href="/blog/assets/js/9.4a0f256f.js"><link rel="prefetch" href="/blog/assets/js/90.322cff52.js"><link rel="prefetch" href="/blog/assets/js/91.5f07c279.js"><link rel="prefetch" href="/blog/assets/js/92.d6c06cd2.js"><link rel="prefetch" href="/blog/assets/js/93.6ba1a145.js"><link rel="prefetch" href="/blog/assets/js/94.b917fb97.js"><link rel="prefetch" href="/blog/assets/js/95.05ebd8ca.js"><link rel="prefetch" href="/blog/assets/js/96.649aca28.js"><link rel="prefetch" href="/blog/assets/js/97.6cfc54b2.js"><link rel="prefetch" href="/blog/assets/js/98.754036a7.js"><link rel="prefetch" href="/blog/assets/js/99.c0a4fe5b.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.f2b65211.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blog/" class="home-link router-link-active"><img src="/blog/img/logo.png" alt="Emma's Blog" class="logo"> <span class="site-name can-hide">Emma's Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/" class="nav-link">首页</a></div><div class="nav-item"><a href="/blog/bytag/" class="nav-link">By Tag</a></div><div class="nav-item"><a href="/blog/google/" class="nav-link">Google</a></div><div class="nav-item"><a href="/blog/ml/" class="nav-link">机器学习</a></div><div class="nav-item"><a href="/blog/bq/" class="nav-link">BQ</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Companies" class="dropdown-title"><!----> <span class="title" style="display:;">Companies</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/ls/" class="nav-link">Facebook</a></li><li class="dropdown-item"><!----> <a href="/blog/design/" class="nav-link">System Design</a></li><li class="dropdown-item"><!----> <a href="/blog/twosigma/" class="nav-link">标准差</a></li><li class="dropdown-item"><!----> <a href="/blog/leetcode/" class="nav-link">其它</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/blog/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/blog/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/blog/archives/" class="nav-link">归档</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://raw.githubusercontent.com/emmableu/image/master/202204101726398.png"> <div class="blogger-info"><h3>emmableu</h3> <span></span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/blog/" class="nav-link">首页</a></div><div class="nav-item"><a href="/blog/bytag/" class="nav-link">By Tag</a></div><div class="nav-item"><a href="/blog/google/" class="nav-link">Google</a></div><div class="nav-item"><a href="/blog/ml/" class="nav-link">机器学习</a></div><div class="nav-item"><a href="/blog/bq/" class="nav-link">BQ</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Companies" class="dropdown-title"><!----> <span class="title" style="display:;">Companies</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/ls/" class="nav-link">Facebook</a></li><li class="dropdown-item"><!----> <a href="/blog/design/" class="nav-link">System Design</a></li><li class="dropdown-item"><!----> <a href="/blog/twosigma/" class="nav-link">标准差</a></li><li class="dropdown-item"><!----> <a href="/blog/leetcode/" class="nav-link">其它</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/blog/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/blog/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/blog/archives/" class="nav-link">归档</a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Zero To Hero</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/blog/pages/5de0af/" class="sidebar-link">Micrograd</a></li><li><a href="/blog/pages/072835/" class="sidebar-link">Makemore 1.1 - bigram</a></li><li><a href="/blog/pages/3d7624/" aria-current="page" class="active sidebar-link">Makemore 1.2 - trigram 1</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/blog/pages/3d7624/#exercise-1-use-trigram-probabilities-to-generate-new-trigram-samples" class="sidebar-link">Exercise 1: Use trigram probabilities to generate new trigram samples.</a></li><li class="sidebar-sub-header level2"><a href="/blog/pages/3d7624/#_1-1-step-1-create-a-count-matrix-n" class="sidebar-link">1.1 Step 1: Create a Count Matrix N</a></li><li class="sidebar-sub-header level2"><a href="/blog/pages/3d7624/#_1-2-step-2-use-a-multinomial-probability-to-generate-trigrams" class="sidebar-link">1.2 Step 2: Use a Multinomial Probability to Generate Trigrams</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#_1-2-1-to-do-that-first-generate-the-probability-matrix" class="sidebar-link">1.2.1: To do that, first generate the probability matrix</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#_1-2-2-add-a-fake-count-regularization" class="sidebar-link">1.2.2: Add a fake count (Regularization)</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#_1-2-3-verify-the-created-probability-matrix-is-correct" class="sidebar-link">1.2.3: Verify the created probability matrix is correct</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#_1-2-4-generate-words" class="sidebar-link">1.2.4: Generate words</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#_2-1-step-1-prepare-x-and-y" class="sidebar-link">2.1 Step 1: Prepare X and y</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#_2-2-step-2-model-training" class="sidebar-link">2.2. Step 2: Model training</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#_2-3-step-3-verify-from-the-loss-in-step-1" class="sidebar-link">2.3 Step 3: Verify from the loss in step 1.</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#_2-4-step-4-generate-names-based-on-the-probabilities" class="sidebar-link">2.4 Step 4: Generate names based on the probabilities</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#_2-5-step-5-smoothing-regularization" class="sidebar-link">2.5 Step 5: Smoothing/Regularization</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/blog/pages/3d7624/#appendix-1-broadcasting-rules" class="sidebar-link">Appendix 1. Broadcasting rules</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#trailing-dimension" class="sidebar-link">Trailing Dimension</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#broadcasting" class="sidebar-link">Broadcasting</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#rules-for-broadcasting" class="sidebar-link">Rules for Broadcasting</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#the-statement-explained" class="sidebar-link">The Statement Explained</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#examples" class="sidebar-link">Examples</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#example-1-compatible-arrays" class="sidebar-link">Example 1: Compatible Arrays</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#example-2-incompatible-arrays" class="sidebar-link">Example 2: Incompatible Arrays</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#visual-example" class="sidebar-link">Visual Example</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/blog/pages/3d7624/#appendix-2-torch-generator" class="sidebar-link">Appendix 2. Torch.Generator</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#what-it-does" class="sidebar-link">What It Does</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#why-you-need-this" class="sidebar-link">Why You Need This</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#difference-if-not-using-this" class="sidebar-link">Difference If Not Using This</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#example-usage" class="sidebar-link">Example Usage</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#summary" class="sidebar-link">Summary</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/blog/pages/3d7624/#appendix-3-indexing-multiple-items-in-torch" class="sidebar-link">Appendix 3: Indexing multiple items in torch</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#matrix-r1-r2-r3-c1-c2-c3" class="sidebar-link">matrix[[r1, r2, r3], [c1, c2, c3]]</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/blog/pages/3d7624/#appendix-4-dim" class="sidebar-link">Appendix 4: dim</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#key-idea" class="sidebar-link">Key Idea:</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/blog/pages/3d7624/#appendix-5-torch-cat" class="sidebar-link">Appendix 5: torch.cat</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#example-1-concatenating-2d-tensors" class="sidebar-link">Example 1: Concatenating 2D Tensors</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#concatenate-along-dim-0-rows-means-expanding-on-number-of-rows" class="sidebar-link">Concatenate along `dim=0` (rows): - means expanding on number of rows.</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/3d7624/#concatenate-along-dim-1-columns" class="sidebar-link">Concatenate along `dim=1` (columns):</a></li></ul></li></ul></li><li><a href="/blog/pages/fd8228/" class="sidebar-link">Makemore 2 - MLP</a></li><li><a href="/blog/pages/c0d04f/" class="sidebar-link">Makemore 3 - Activations &amp; Gradients, BatchNorm</a></li><li><a href="/blog/pages/049b6e/" class="sidebar-link">Makemore 4 - Backpropagation Ninja</a></li><li><a href="/blog/pages/aed865/" class="sidebar-link">Makemore 5 - WaveNet</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Machine Learning General</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Machine Learning Concepts</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Reinforcement Learning</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>PyTorch</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span> Complete ML Projects</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-1"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/blog/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/blog/ml/#机器学习八股文" data-v-06225672>机器学习八股文</a></li><li data-v-06225672><a href="/blog/ml/#Zero To Hero" data-v-06225672>Zero To Hero</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="javascript:;" data-v-06225672>emmableu</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2025-06-12</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><!---->Makemore 1.2 - trigram 1<!----></h1>  <div class="theme-vdoing-content content__default"><p>Youtube link: <a href="https://www.youtube.com/watch?v=PaCmpygFfXo&amp;list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&amp;index=2" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=PaCmpygFfXo&amp;list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&amp;index=2<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>github link: <a href="https://github.com/karpathy/makemore" target="_blank" rel="noopener noreferrer">https://github.com/karpathy/makemore<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>jupyter notebook: <a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbWtKMk5XaW81QzJMTjVFSUhvdG9kMlo4ZGgyQXxBQ3Jtc0ttMmNrUUNDcWJFcHYxWUdFV3J0ZkppVE1HUG1yZktyUE52QmMzTWxZWW90c280N3NVeG55ekFibF9vdlluTnBBRFhDc2FnZ29hdjdiaGVxeVhleUczcWdpQ0pqcnNQbHozUUNacWlTbE91OFllMmpUcw&amp;q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fnn-zero-to-hero%2Fblob%2Fmaster%2Flectures%2Fmakemore%2Fmakemore_part1_bigrams.ipynb&amp;v=PaCmpygFfXo" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><a href="https://github.com/karpathy/nn-zero-t" target="_blank" rel="noopener noreferrer">https://github.com/karpathy/nn-zero-t<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>...</p> <h1 id="exercises-train-and-evaluate-a-trigram-model"><a href="#exercises-train-and-evaluate-a-trigram-model" class="header-anchor">#</a> Exercises: Train and Evaluate a Trigram Model</h1> <h2 id="exercise-1-use-trigram-probabilities-to-generate-new-trigram-samples"><a href="#exercise-1-use-trigram-probabilities-to-generate-new-trigram-samples" class="header-anchor">#</a> Exercise 1: Use trigram probabilities to generate new trigram samples.</h2> <p>Use the probabilities to generate new sequence of names, that looks like</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token punctuation">.</span>aylandia<span class="token punctuation">.</span>
<span class="token punctuation">.</span>hosannaleine<span class="token punctuation">.</span>
<span class="token punctuation">.</span>pieliyya<span class="token punctuation">.</span>
<span class="token punctuation">.</span>jeah<span class="token punctuation">.</span>
<span class="token punctuation">.</span>drielana<span class="token punctuation">.</span>
<span class="token punctuation">.</span>anishlia<span class="token punctuation">.</span>
<span class="token punctuation">.</span>el<span class="token punctuation">.</span>
<span class="token punctuation">.</span>comon<span class="token punctuation">.</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h2 id="_1-1-step-1-create-a-count-matrix-n"><a href="#_1-1-step-1-create-a-count-matrix-n" class="header-anchor">#</a> 1.1 Step 1: Create a Count Matrix N</h2> <ul><li><code>N[1,2,3]</code> means how many counts of trigrams are &quot;abc&quot;.</li> <li><code>N[1,:,:].sum()</code> means the number of all trigrams that starts with &quot;a&quot;.</li></ul> <p>here’s the names.txt file: <a href="https://github.com/karpathy/makemore/blob/master/names.txt" target="_blank" rel="noopener noreferrer">https://github.com/karpathy/makemore/blob/master/names.txt<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
names <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;makemore-master/names.txt&quot;</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>splitlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
N <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>

chars <span class="token operator">=</span> <span class="token string">'.abcedfghijklmnopqrstuvwxyz'</span>
stoi <span class="token operator">=</span> <span class="token punctuation">{</span>s<span class="token punctuation">:</span> i <span class="token keyword">for</span> i<span class="token punctuation">,</span> s <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>chars<span class="token punctuation">)</span><span class="token punctuation">}</span>
<span class="token keyword">for</span> w <span class="token keyword">in</span> names<span class="token punctuation">:</span>
    chs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'.'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">list</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'.'</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> ch1<span class="token punctuation">,</span> ch2<span class="token punctuation">,</span> ch3 <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>chs<span class="token punctuation">,</span> chs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> chs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        trigram <span class="token operator">=</span> <span class="token punctuation">(</span>stoi<span class="token punctuation">[</span>ch1<span class="token punctuation">]</span><span class="token punctuation">,</span> stoi<span class="token punctuation">[</span>ch2<span class="token punctuation">]</span><span class="token punctuation">,</span> stoi<span class="token punctuation">[</span>ch3<span class="token punctuation">]</span><span class="token punctuation">)</span>
        N<span class="token punctuation">[</span>trigram<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h2 id="_1-2-step-2-use-a-multinomial-probability-to-generate-trigrams"><a href="#_1-2-step-2-use-a-multinomial-probability-to-generate-trigrams" class="header-anchor">#</a> 1.2 Step 2: Use a Multinomial Probability to Generate Trigrams</h2> <ul><li>The chances of &quot;.&quot; appearing first = 1 (since &quot;.&quot; is always the starting point).</li> <li>If &quot;.&quot; is the first, the chances of &quot;a&quot; appearing next = <code>N[0, 1, :].sum() / N[0, :, :].sum()</code> <ul><li>Using the below <code>second_prob_matrix</code>, this same chance can be obtained at <code>second_prob_matrix[1]</code>.</li></ul></li> <li>If &quot;a&quot; is the second, the chances of &quot;b&quot; appearing after &quot;.a&quot; = <code>N[0, 1, 2] / N[0, 1, :].sum()</code> <ul><li>Using the below <code>third_prob_matrix</code>, this same chance can be obtained at <code>third_prob_matrix[0, 1, 2]</code>.</li></ul></li> <li>If the previous 2 items are &quot;ab&quot;, the chances of &quot;c&quot; appearing after &quot;ab&quot; = <code>N[1, 2, 3] / N[1, 2, :].sum()</code> <ul><li>Using the below <code>third_prob_matrix</code>, this same chance can be obtained at <code>third_prob_matrix[1, 2, 3]</code>.</li></ul></li> <li>If the previous 2 items are &quot;bc&quot;, the chances of &quot;d&quot; appearing after &quot;bc&quot; = <code>N[2, 3, 4] / N[2, 3, :].sum()</code>.</li> <li>If the previous 2 items are &quot;cd&quot;, the chances of &quot;e&quot; appearing after &quot;cd&quot; = <code>N[3, 4, 5] / N[3, 4, :].sum()</code>.</li></ul> <h3 id="_1-2-1-to-do-that-first-generate-the-probability-matrix"><a href="#_1-2-1-to-do-that-first-generate-the-probability-matrix" class="header-anchor">#</a> 1.2.1: To do that, first generate the probability matrix</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code>second_prob_matrix <span class="token operator">=</span> N<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> N<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
third_prob_matrix <span class="token operator">=</span> N<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">/</span> N<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p><strong>Note:</strong> It is essential to use <code>keepdim=True</code> in the <code>third_prob_matrix</code> calculation. If not, the dimensions will not align correctly for subsequent operations. Please check the below example to see the issue:</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>M <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>M<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>M<span class="token operator">/</span>M<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&quot;&quot;&quot;
output:
torch.Size([2, 3])
Traceback (most recent call last):
  File &quot;/Users/wengranwang/Documents/applebot_page_classification/page-classification/test-script/zero-to-hero/test.py&quot;, line 4, in &lt;module&gt;
    print(M/M.sum(dim=2))
RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 2
&quot;&quot;&quot;</span>

M <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>M<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>M<span class="token operator">/</span>M<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
output:
torch.Size([2, 3, 1])
tensor([[[0.2500, 0.2500, 0.2500, 0.2500],
         [0.2500, 0.2500, 0.2500, 0.2500],
         [0.2500, 0.2500, 0.2500, 0.2500]],

        [[0.2500, 0.2500, 0.2500, 0.2500],
         [0.2500, 0.2500, 0.2500, 0.2500],
         [0.2500, 0.2500, 0.2500, 0.2500]]])
&quot;&quot;&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><p>In our example, as the N matrix is 27 * 27 * 27, without keepdim=True it will not throw errors, but the way the matrix broadcast (i.e., copy item) is on a different direction.</p> <h3 id="_1-2-2-add-a-fake-count-regularization"><a href="#_1-2-2-add-a-fake-count-regularization" class="header-anchor">#</a> 1.2.2: Add a fake count (Regularization)</h3> <p>Note, if you print <code>third_prob_matrix</code>, you can see quite a few that has nan, e.g., <code>vp</code>, this is because there’s no trigram starts with <code>vp</code> , so the denominator becomes 0. This would cause issues:</p> <ul><li>in later step (1.2.4), when we generate samples based on this probability, we can’t use <code>nan</code> as the probability.</li> <li>Also, it is common to use the log probability as part of the calculation for the negative log likelihood loss function. For this calculation, <code>- log(0)</code> becomes <code>inf</code>, and we can’t calculate <code>log(nan)</code> .</li> <li>To fix this, we add a fake count to each element in N.</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code>N <span class="token operator">=</span> N <span class="token operator">+</span> <span class="token number">1</span>
second_prob_matrix <span class="token operator">=</span> N<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> N<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
third_prob_matrix <span class="token operator">=</span> N<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">/</span> N<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>Note:</strong> This is actually a regularization step that when done, can prevent overfitting. We will revisit why this is so in Exercise 2.</p> <h3 id="_1-2-3-verify-the-created-probability-matrix-is-correct"><a href="#_1-2-3-verify-the-created-probability-matrix-is-correct" class="header-anchor">#</a> 1.2.3: Verify the created probability matrix is correct</h3> <p>probabilities of [a,b,:] should sum up to 1, [a,c,:] sum up to 1, ..</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>trigrams <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
prob_sum <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> c1 <span class="token keyword">in</span> chars<span class="token punctuation">:</span>
    <span class="token keyword">for</span> c2 <span class="token keyword">in</span> chars<span class="token punctuation">:</span>
        cur_sum <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> c3 <span class="token keyword">in</span> chars<span class="token punctuation">:</span>
            prob <span class="token operator">=</span> third_prob_matrix<span class="token punctuation">[</span>stoi<span class="token punctuation">[</span>c1<span class="token punctuation">]</span><span class="token punctuation">,</span> stoi<span class="token punctuation">[</span>c2<span class="token punctuation">]</span><span class="token punctuation">,</span> stoi<span class="token punctuation">[</span>c3<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            prob_sum <span class="token operator">+=</span> prob
            cur_sum <span class="token operator">+=</span> prob
        <span class="token keyword">assert</span> <span class="token number">1</span> <span class="token operator">-</span> cur_sum <span class="token operator">&lt;</span> <span class="token number">0.001</span>
        <span class="token comment"># ^ this should sum up to 1</span>

<span class="token keyword">assert</span> prob_sum <span class="token operator">-</span> <span class="token number">27</span> <span class="token operator">*</span> <span class="token number">27</span> <span class="token operator">&lt;</span> <span class="token number">0.001</span>
<span class="token comment"># prob sum should sum up to 27*27 = 729</span>
<span class="token comment"># this is because [a,b,:] should sum up to 1, [a,c,:] sum up to 1, ..</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><h3 id="_1-2-4-generate-words"><a href="#_1-2-4-generate-words" class="header-anchor">#</a> 1.2.4: Generate words</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    first <span class="token operator">=</span> <span class="token number">0</span>
    second <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>second_prob_matrix<span class="token punctuation">,</span> replacement<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>g<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    third <span class="token operator">=</span> <span class="token boolean">None</span>
    generated_sequence <span class="token operator">=</span> <span class="token punctuation">[</span>first<span class="token punctuation">,</span> second<span class="token punctuation">]</span>
    <span class="token keyword">while</span> third <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
        third <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>third_prob_matrix<span class="token punctuation">[</span>first<span class="token punctuation">,</span> second<span class="token punctuation">]</span><span class="token punctuation">,</span> replacement<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>g<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        generated_sequence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>third<span class="token punctuation">)</span>
        first <span class="token operator">=</span> second
        second <span class="token operator">=</span> third

    generated_word <span class="token operator">=</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>chars<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> generated_sequence<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>generated_word<span class="token punctuation">)</span>
 
 <span class="token triple-quoted-string string">&quot;&quot;&quot;
 output:
 .aylandia.
.hvtonnaleine.
.pieliyya.
.jeah.
.drielana.
.anishlia.
.el.
.cy.
.lanicolie.
.den.
 &quot;&quot;&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><p>how to verify the generated word is indeed coming from the trigram probability:</p> <ul><li>replace the multinomial sampling to:
<ul><li><code>third = torch.multinomial(torch.ones(27)/27.0, replacement=True, generator=g, num_samples=1).item()</code></li></ul></li> <li>and then check the results. You can see that the words changed from pronounceable to non-pronounceable and quite random.</li></ul> <h1 id="exercise-2-use-neural-network-to-complete-the-same-above"><a href="#exercise-2-use-neural-network-to-complete-the-same-above" class="header-anchor">#</a> Exercise 2: Use Neural Network to complete the same above.</h1> <p>In this exercise, instead of generating <code>third_prob_matrix</code> using the probability of the counts, we generate the <code>third_prob_matrix</code> by estimating all of the parameters using gradient descent.</p> <p>i.e., we estimate the probability of <code>given “ab”, the third character is &quot;c&quot;</code> using gradient descent, instead of the observed probability from the data.</p> <p>Because this is <code>ab</code>, <code>ac</code> , … <code>zy</code>, <code>zz</code> , .. <code>.a</code> , .. 27_27 types of occurrance of first 2 chars, we construct a 1 layer neural network with 27_27 = 729 neurons.</p> <p>Let’s use 1 input word <code>emma</code></p> <ul><li><code>.em</code> , <code>emm</code>, <code>mma</code>, <code>ma.</code> are the 4 trigrams,</li> <li>seperating them to x and y, then x = [ <code>.e</code> , <code>em</code>, <code>mm</code>, <code>ma</code> ], y = [ <code>m</code>, <code>m</code>, <code>a</code>, <code>.</code> ] )</li></ul> <p>Use <code>emma</code> as an example, here’s how the neural network look like:</p> <p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/453ca8e2-cee0-4cc0-94b7-2515fce2cbff/fd57270b-8d45-4013-830b-4eb13526184b/Untitled.png" alt="Untitled"></p> <p>In the above function, how do we estimate how fit the parameters in W are:</p> <ul><li>We use the Maximum Likelihood Estimation, i.e., we maximum the probability that our output matches [m, m, a, .]</li> <li>To do that, we want the probability of <code>e^xi/sum(e^xi) for all xi in each row</code> for all 4 rows multiplied to be the highest,
<ul><li>e.g., p(first row = m) = 0.3, p(second row = m) = 0.5, p(third row = a) = 0.1, p(4th row = .) = 0.9, then all prob = 0.3 * 0.5 * 0.1 * 0.9. We want this prob to be the highest possible.</li> <li>that means having the log likelihood to be highest possible
<ul><li>i.e., <code>log(0.3) + log(0.5) + log(0.1) + log(0.9)</code> to be highest possible.</li> <li>which means for the negative log likelihood to be lowest possible.</li> <li>i.e., <code>- (log(0.3) + log(0.5) + log(0.1) + log(0.9)) / 4</code> to be lowest possible. Note getting the mean is the convention of how this is done.</li></ul></li></ul></li> <li>this <code>- (log(0.3) + log(0.5) + log(0.1) + log(0.9))/4</code> negative log likelihood is called the <strong>loss function.</strong></li></ul> <p>Based on the above, let’s write down how to use gradient descent to estimate the W.</p> <h3 id="_2-1-step-1-prepare-x-and-y"><a href="#_2-1-step-1-prepare-x-and-y" class="header-anchor">#</a> 2.1 Step 1: Prepare X and y</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

names <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;makemore-master/names.txt&quot;</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>splitlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
chars <span class="token operator">=</span> <span class="token string">'.abcdefghijklmnopqrstuvwxyz'</span>
stoi_27 <span class="token operator">=</span> <span class="token punctuation">{</span>c<span class="token punctuation">:</span> i <span class="token keyword">for</span> i<span class="token punctuation">,</span> c <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>chars<span class="token punctuation">)</span><span class="token punctuation">}</span>
itos_729 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
stoi_729 <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
i <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> c1 <span class="token keyword">in</span> chars<span class="token punctuation">:</span>
    <span class="token keyword">for</span> c2 <span class="token keyword">in</span> chars<span class="token punctuation">:</span>
        i <span class="token operator">+=</span> <span class="token number">1</span>
        stoi_729<span class="token punctuation">[</span><span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c2<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> i
        itos_729<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># names = ['emma']  # starts with one word only</span>
X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> name <span class="token keyword">in</span> names<span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'.'</span> <span class="token operator">+</span> name <span class="token operator">+</span> <span class="token string">'.'</span>
    <span class="token keyword">for</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> c3 <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> name<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        X<span class="token punctuation">.</span>append<span class="token punctuation">(</span>stoi_729<span class="token punctuation">[</span><span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c2<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>stoi_27<span class="token punctuation">[</span>c3<span class="token punctuation">]</span><span class="token punctuation">)</span>

X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
X <span class="token operator">=</span> F<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">730</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 
<span class="token comment"># 27 * 27 = 729, but seems like torch needs the num_classes to be larger than the actual classes</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><h3 id="_2-2-step-2-model-training"><a href="#_2-2-step-2-model-training" class="header-anchor">#</a> 2.2. Step 2: Model training</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code>W <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">730</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    logits <span class="token operator">=</span> X @ W
    counts <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>logits<span class="token punctuation">)</span>
    prob <span class="token operator">=</span> counts <span class="token operator">/</span> counts<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    prob <span class="token operator">=</span> prob<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>X<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span>
    loss <span class="token operator">=</span> <span class="token operator">-</span> torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>prob<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># this is negative log likelihood loss</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
    step_size <span class="token operator">=</span> <span class="token number">0.01</span>
    W<span class="token punctuation">.</span>data <span class="token operator">=</span> W<span class="token punctuation">.</span>data <span class="token operator">-</span> step_size <span class="token operator">*</span> W<span class="token punctuation">.</span>grad
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>Last few lines of the printed loss looks like</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tensor<span class="token punctuation">(</span><span class="token number">2.7786</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7780</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7773</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7766</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7760</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7754</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7747</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7741</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7735</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7729</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7723</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7717</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7712</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7706</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7701</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7696</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7690</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7686</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7681</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7676</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.7672</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>NegBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><h3 id="_2-3-step-3-verify-from-the-loss-in-step-1"><a href="#_2-3-step-3-verify-from-the-loss-in-step-1" class="header-anchor">#</a> 2.3 Step 3: Verify from the loss in step 1.</h3> <p>The estimate from Step 1 is an analytical estimate. our new estimate should be very close to the analytical estimate.</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>neg_log_likelihood <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> name <span class="token keyword">in</span> names<span class="token punctuation">:</span>
    <span class="token keyword">for</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> c3 <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> name<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        prob <span class="token operator">=</span> third_prob_matrix<span class="token punctuation">[</span>stoi<span class="token punctuation">[</span>c1<span class="token punctuation">]</span><span class="token punctuation">,</span> stoi<span class="token punctuation">[</span>c2<span class="token punctuation">]</span><span class="token punctuation">,</span> stoi<span class="token punctuation">[</span>c3<span class="token punctuation">]</span><span class="token punctuation">]</span>
        neg_log_likelihood<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span> torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>prob<span class="token punctuation">)</span><span class="token punctuation">)</span>
neg_log_likelihood <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>neg_log_likelihood<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>neg_log_likelihood<span class="token punctuation">)</span> 
<span class="token triple-quoted-string string">&quot;&quot;&quot;
output:
tensor(2.3313)
&quot;&quot;&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><h3 id="_2-4-step-4-generate-names-based-on-the-probabilities"><a href="#_2-4-step-4-generate-names-based-on-the-probabilities" class="header-anchor">#</a> 2.4 Step 4: Generate names based on the probabilities</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code>g <span class="token operator">=</span> torch<span class="token punctuation">.</span>Generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    first <span class="token operator">=</span> <span class="token number">0</span>
    second <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>second_prob_matrix<span class="token punctuation">,</span> replacement<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>g<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    third <span class="token operator">=</span> <span class="token boolean">None</span>
    generated_sequence <span class="token operator">=</span> <span class="token punctuation">[</span>first<span class="token punctuation">,</span> second<span class="token punctuation">]</span>
    <span class="token keyword">while</span> third <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
        idx <span class="token operator">=</span> stoi_729<span class="token punctuation">[</span><span class="token punctuation">(</span>chars<span class="token punctuation">[</span>first<span class="token punctuation">]</span><span class="token punctuation">,</span> chars<span class="token punctuation">[</span>second<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        logits <span class="token operator">=</span> W<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        counts <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>logits<span class="token punctuation">)</span>
        probs <span class="token operator">=</span> counts<span class="token operator">/</span>counts<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        third <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>probs<span class="token punctuation">,</span> replacement<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>g<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        generated_sequence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>third<span class="token punctuation">)</span>
        first <span class="token operator">=</span> second
        second <span class="token operator">=</span> third

    generated_word <span class="token operator">=</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>chars<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> generated_sequence<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>generated_word<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&quot;&quot;&quot;
output:
.ael.
.ddisah.
.taslmpkzyejpruouyra.
.jabwourreyah.
.tafwsxlfwper.
.cymon.
.zznpwm.
.dapv.
.caridgyiujge.
.sanna.
&quot;&quot;&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br></div></div><h3 id="_2-5-step-5-smoothing-regularization"><a href="#_2-5-step-5-smoothing-regularization" class="header-anchor">#</a> 2.5 Step 5: Smoothing/Regularization</h3> <p>Similar to when we did <code>N = N + 1</code> in 1.2.2, we can do the same here to prevent certain parameter have very high negative log likelihood, which could cause overfit and affect the loss calculation.</p> <p>Know that when a parameter in |W| is very extreme (e.g., 10, -10), it will then cause the negative log likelihood to be very high or very low, and this affects how we calculate the loss function and how we run gradient descent, and also caused the parameters we get to overfit to the training data.</p> <p>To run smoothing, on top of the step 2 model training,</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>W <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">730</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    logits <span class="token operator">=</span> X @ W
    counts <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>logits<span class="token punctuation">)</span>
    prob <span class="token operator">=</span> counts <span class="token operator">/</span> counts<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    prob <span class="token operator">=</span> prob<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>X<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span>
    loss <span class="token operator">=</span> <span class="token operator">-</span> torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>prob<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># this is negative log likelihood loss</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
    step_size <span class="token operator">=</span> <span class="token number">0.01</span>
    W<span class="token punctuation">.</span>data <span class="token operator">=</span> W<span class="token punctuation">.</span>data <span class="token operator">-</span> step_size <span class="token operator">*</span> W<span class="token punctuation">.</span>grad
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>we can change the function <code>loss = - torch.log(prob).mean()</code></p> <p>to be</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>loss <span class="token operator">=</span> <span class="token operator">-</span> torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>prob<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span> <span class="token operator">*</span> <span class="token punctuation">(</span>W<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>essentially, this means the higher the absolute value of W is, the higher the loss. This adds a penalty when the the absolute value of W is too high.</p> <h1 id="appendix"><a href="#appendix" class="header-anchor">#</a> Appendix:</h1> <h2 id="appendix-1-broadcasting-rules"><a href="#appendix-1-broadcasting-rules" class="header-anchor">#</a> Appendix 1. Broadcasting rules</h2> <p><code>Broadcasting rule: Two tensors are “broadcastable” if the following rules hold:- Each tensor has at least one dimension.- When iterating over the dimension sizes, star ting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.</code></p> <h3 id="trailing-dimension"><a href="#trailing-dimension" class="header-anchor">#</a> Trailing Dimension</h3> <p>The trailing dimension of an array is the last dimension in its shape. For instance:</p> <ul><li>For a 1D array with shape <code>(5,)</code>, the trailing dimension is <code>5</code>.</li> <li>For a 2D array with shape <code>(3, 4)</code>, the trailing dimension is <code>4</code>.</li> <li>For a 3D array with shape <code>(2, 3, 4)</code>, the trailing dimension is <code>4</code>.</li></ul> <h3 id="broadcasting"><a href="#broadcasting" class="header-anchor">#</a> Broadcasting</h3> <p>Broadcasting is the process of making arrays with different shapes compatible for arithmetic operations. It involves &quot;stretching&quot; the smaller array across the larger array so that they have compatible shapes.</p> <h3 id="rules-for-broadcasting"><a href="#rules-for-broadcasting" class="header-anchor">#</a> Rules for Broadcasting</h3> <p>The rules for broadcasting are:</p> <ol><li><strong>Same Size</strong>: The dimensions are equal., OR</li> <li><strong>Size of One</strong>: One of the dimensions is 1., OR</li> <li><strong>Nonexistent Dimension</strong>: The dimension is nonexistent in the smaller array.,</li></ol> <h3 id="the-statement-explained"><a href="#the-statement-explained" class="header-anchor">#</a> The Statement Explained</h3> <blockquote><p>&quot;When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.&quot;</p></blockquote> <p>This means that, when aligning the dimensions of two arrays for broadcasting, you start comparing from the last dimension (the trailing dimension) and move towards the first dimension. For each pair of dimensions you compare:</p> <ol><li>If they are the same size, they are compatible.</li> <li>If one of them is 1, it can be stretched to match the other size.</li> <li>If one of them does not exist (the smaller array has fewer dimensions), it is treated as if it has a size of 1 in that dimension.</li></ol> <h3 id="examples"><a href="#examples" class="header-anchor">#</a> Examples</h3> <h3 id="example-1-compatible-arrays"><a href="#example-1-compatible-arrays" class="header-anchor">#</a> Example 1: Compatible Arrays</h3> <ul><li>Array A: Shape <code>(4, 3, 2)</code></li> <li>Array B: Shape <code>(3, 1)</code></li></ul> <p>Step-by-step broadcasting:</p> <ol><li><strong>Trailing dimensions</strong> (last dimension):
<ul><li>A: 2</li> <li>B: 1 (B can be stretched to size 2)</li></ul></li> <li><strong>Next dimensions</strong>:
<ul><li>A: 3</li> <li>B: 3 (Same size, compatible)</li></ul></li> <li><strong>Next dimensions</strong>:
<ul><li>A: 4</li> <li>B: Does not exist (Treated as 1, B can be stretched to size 4)</li></ul></li></ol> <p>Result: B can be broadcasted to shape <code>(4, 3, 2)</code>.</p> <h3 id="example-2-incompatible-arrays"><a href="#example-2-incompatible-arrays" class="header-anchor">#</a> Example 2: Incompatible Arrays</h3> <ul><li>Array A: Shape <code>(3, 2)</code></li> <li>Array B: Shape <code>(4, 3)</code></li></ul> <p>Step-by-step broadcasting:</p> <ol><li><strong>Trailing dimensions</strong> (last dimension):
<ul><li>A: 2</li> <li>B: 3 (Different sizes and neither is 1, not compatible)</li></ul></li></ol> <p>Result: A and B cannot be broadcasted together.</p> <h3 id="visual-example"><a href="#visual-example" class="header-anchor">#</a> Visual Example</h3> <p>Consider arrays:</p> <ul><li>Array A: Shape <code>(4, 1, 3)</code></li> <li>Array B: Shape <code>(1, 5, 3)</code></li></ul> <p>Broadcasting steps:</p> <ol><li><strong>Trailing dimensions</strong>:
<ul><li>A: 3</li> <li>B: 3 (Same size, compatible)</li></ul></li> <li><strong>Next dimensions</strong>:
<ul><li>A: 1</li> <li>B: 5 (A can be stretched to size 5)</li></ul></li> <li><strong>Next dimensions</strong>:
<ul><li>A: 4</li> <li>B: 1 (B can be stretched to size 4)</li></ul></li></ol> <p>Final shapes after broadcasting:</p> <ul><li>Array A: Shape <code>(4, 5, 3)</code></li> <li>Array B: Shape <code>(4, 5, 3)</code></li></ul> <h2 id="appendix-2-torch-generator"><a href="#appendix-2-torch-generator" class="header-anchor">#</a> Appendix 2. Torch.Generator</h2> <p>The line <code>g = torch.Generator().manual_seed(123)</code> is used to create a random number generator with a specific seed. Here's what it does, why you might need it, and the differences if you don't use it:</p> <h3 id="what-it-does"><a href="#what-it-does" class="header-anchor">#</a> What It Does</h3> <ol><li><strong>Creates a Random Number Generator</strong>:
<ul><li><code>torch.Generator()</code> creates a random number generator object. This generator can be used to control the random number generation process in PyTorch.</li></ul></li> <li><strong>Sets a Manual Seed</strong>:
<ul><li><code>manual_seed(123)</code> sets the seed for the random number generator to <code>123</code>. A seed is a starting point for the sequence of random numbers. By setting the seed, you ensure that the sequence of random numbers is reproducible.</li></ul></li></ol> <h3 id="why-you-need-this"><a href="#why-you-need-this" class="header-anchor">#</a> Why You Need This</h3> <ol><li><strong>Reproducibility</strong>:
<ul><li>Setting a seed ensures that the results of your experiments are reproducible. This means that if you run the same code multiple times, you will get the same results each time. This is crucial for debugging, comparing models, and ensuring that your results are reliable.</li></ul></li> <li><strong>Consistency Across Runs</strong>:
<ul><li>When you are developing and testing machine learning models, you often need to ensure that your results are consistent across different runs. Setting a seed helps in achieving this consistency.</li></ul></li> <li><strong>Experiment Tracking</strong>:
<ul><li>In research and production environments, being able to reproduce the results is essential for tracking the progress of experiments and verifying results.</li></ul></li></ol> <h3 id="difference-if-not-using-this"><a href="#difference-if-not-using-this" class="header-anchor">#</a> Difference If Not Using This</h3> <ol><li><strong>Non-Reproducible Results</strong>:
<ul><li>Without setting a seed, the random number generator will produce different sequences of random numbers each time you run your code. This can lead to variations in the results of your experiments or model training runs, making it hard to reproduce your results.</li></ul></li> <li><strong>Difficulty in Debugging</strong>:
<ul><li>If you encounter an issue in your code and you need to debug it, having reproducible results is extremely helpful. Without a set seed, the randomness can make it difficult to identify the root cause of issues.</li></ul></li> <li><strong>Inconsistent Model Performance</strong>:
<ul><li>In machine learning, the initial weights of a model, the order of data shuffling, and other stochastic processes can affect the performance of your model. Without a set seed, these factors can lead to different performance metrics across runs, making it harder to compare different models or hyperparameter settings.</li></ul></li></ol> <h3 id="example-usage"><a href="#example-usage" class="header-anchor">#</a> Example Usage</h3> <p>Here's an example to illustrate the use of <code>torch.Generator</code> with a manual seed:</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch

<span class="token comment"># Create a generator with a manual seed</span>
g <span class="token operator">=</span> torch<span class="token punctuation">.</span>Generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>

<span class="token comment"># Generate a random tensor with the generator</span>
random_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>g<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>random_tensor<span class="token punctuation">)</span>

<span class="token comment"># Generate another random tensor with the same generator</span>
random_tensor_2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>g<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>random_tensor_2<span class="token punctuation">)</span>

<span class="token comment"># Reset the seed and generate the tensor again</span>
g<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>
random_tensor_3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>g<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>random_tensor_3<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&quot;&quot;&quot;
output:
tensor([[-0.1115,  0.1204, -0.3696],
        [-0.2404, -1.1969,  0.2093],
        [-0.9724, -0.7550,  0.3239]])
tensor([[-0.1085,  0.2103, -0.3908],
        [ 0.2350,  0.6653,  0.3528],
        [ 0.9728, -0.0386, -0.8861]])
tensor([[-0.1115,  0.1204, -0.3696],
        [-0.2404, -1.1969,  0.2093],
        [-0.9724, -0.7550,  0.3239]])
&quot;&quot;&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><p>In this example:</p> <ul><li>The first tensor (<code>random_tensor</code>) is generated using the generator with the seed set to <code>123</code>.</li> <li>The second tensor (<code>random_tensor_2</code>) is generated using the same generator, continuing the random sequence.</li> <li>After resetting the seed to <code>123</code>, generating the tensor again (<code>random_tensor_3</code>) produces the same values as <code>random_tensor</code>.</li></ul> <h3 id="summary"><a href="#summary" class="header-anchor">#</a> Summary</h3> <p>Using <code>torch.Generator(manual_seed=123)</code> is crucial for ensuring reproducibility and consistency in your experiments. Without setting a seed, the random processes in your code can lead to non-reproducible and inconsistent results, which can complicate debugging and result verification.</p> <h2 id="appendix-3-indexing-multiple-items-in-torch"><a href="#appendix-3-indexing-multiple-items-in-torch" class="header-anchor">#</a> Appendix 3: Indexing multiple items in torch</h2> <h3 id="matrix-r1-r2-r3-c1-c2-c3"><a href="#matrix-r1-r2-r3-c1-c2-c3" class="header-anchor">#</a> <code>matrix[[r1, r2, r3], [c1, c2, c3]]</code></h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
m <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&quot;&quot;&quot;
suppose I want to get 3, 6, if I first write 3's index, then 6's index: 
&quot;&quot;&quot;</span>
elements <span class="token operator">=</span> m<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
this will show an error, this is not possible:
IndexError: index 2 is out of bounds for dimension 0 with size 2
&quot;&quot;&quot;</span>

<span class="token triple-quoted-string string">&quot;&quot;&quot;
I will have to use the row index, then column index, 
i.e., matrix[[r1, r2, r3], [c1, c2, c3]]
i.e., [0,1], [2,2] 
&quot;&quot;&quot;</span>
elements <span class="token operator">=</span> m<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>elements<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
output:
tensor([3, 6])
&quot;&quot;&quot;</span>

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><h2 id="appendix-4-dim"><a href="#appendix-4-dim" class="header-anchor">#</a> Appendix 4: <code>dim</code></h2> <h3 id="key-idea"><a href="#key-idea" class="header-anchor">#</a> Key Idea:</h3> <p><strong>The <code>dim</code> argument specifies the axis that you &quot;reduce&quot; or &quot;operate on&quot;.</strong></p> <ol><li><strong>When you use operations like <code>sum</code>, <code>mean</code>, <code>max</code>, or <code>argmax</code>,</strong> specifying <code>dim=0</code> tells PyTorch to reduce or operate along rows (axis 0), which means you collapse the rows and perform the operation across columns.</li> <li><strong>When you use <code>dim=1</code>,</strong> you're telling PyTorch to operate along columns (axis 1), meaning you collapse the columns and perform the operation across rows.</li></ol> <p>i.e.:</p> <ul><li>if dim=0, shape=(2,5) 会变成 shape=(5), 也就是dim 0消失了</li> <li>if dim=1, shape=(2,5) 会变成 shape=(2)，也就是dim 1消失了</li></ul> <p><strong>dim=-1:</strong></p> <ul><li>In PyTorch, specifying <code>dim=-1</code> refers to the <strong>last</strong> axis of the tensor, regardless of its dimensionality. This is a convenient way to operate on the last dimension without explicitly knowing its index, which can be useful when working with tensors of varying shapes.</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
tensor([[0, 1, 2, 3, 4],
        [5, 6, 7, 8, 9]])
&quot;&quot;&quot;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
tensor([ 5,  7,  9, 11, 13])
&quot;&quot;&quot;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
tensor([10, 35])
&quot;&quot;&quot;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
tensor([10, 35])
&quot;&quot;&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><h2 id="appendix-5-torch-cat"><a href="#appendix-5-torch-cat" class="header-anchor">#</a> Appendix 5: torch.cat</h2> <p>In PyTorch, you can use <code>torch.cat</code> to concatenate tensors along a specified dimension. Here’s how you can do this with multi-dimensional tensors.</p> <h3 id="example-1-concatenating-2d-tensors"><a href="#example-1-concatenating-2d-tensors" class="header-anchor">#</a> Example 1: Concatenating 2D Tensors</h3> <p>Let's start with a simple example of concatenating two 2D tensors along different dimensions.</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>pythonCopy code
<span class="token keyword">import</span> torch

<span class="token comment"># Create two 2D tensors</span>
tensor1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

tensor2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Tensor 1:&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor1<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Tensor 2:&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor2<span class="token punctuation">)</span>

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><h3 id="concatenate-along-dim-0-rows-means-expanding-on-number-of-rows"><a href="#concatenate-along-dim-0-rows-means-expanding-on-number-of-rows" class="header-anchor">#</a> <strong>Concatenate along <code>dim=0</code></strong> (rows): - means expanding on number of rows.</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code>pythonCopy code
result_dim0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Concatenate along dim=0:&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result_dim0<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p><strong>Output:</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>plaintextCopy code
tensor([[ 1,  2,  3],
        [ 4,  5,  6],
        [ 7,  8,  9],
        [10, 11, 12]])

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><ul><li><strong>Explanation</strong>: Concatenating along <code>dim=0</code> adds the rows of <code>tensor2</code> below the rows of <code>tensor1</code>.</li></ul> <h3 id="concatenate-along-dim-1-columns"><a href="#concatenate-along-dim-1-columns" class="header-anchor">#</a> <strong>Concatenate along <code>dim=1</code></strong> (columns):</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code>pythonCopy code
result_dim1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>tensor1<span class="token punctuation">,</span> tensor2<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Concatenate along dim=1:&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result_dim1<span class="token punctuation">)</span>

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p><strong>Output:</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>plaintextCopy code
tensor([[ 1,  2,  3,  7,  8,  9],
        [ 4,  5,  6, 10, 11, 12]])

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><ul><li><strong>Explanation</strong>: Concatenating along <code>dim=1</code> adds the columns of <code>tensor2</code> to the right of the columns of <code>tensor1</code>.</li></ul></div></div>  <div class="page-edit"><!----> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2025/07/04, 23:19:22</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/blog/pages/072835/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Makemore 1.1 - bigram</div></a> <a href="/blog/pages/fd8228/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">Makemore 2 - MLP</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/blog/pages/072835/" class="prev">Makemore 1.1 - bigram</a></span> <span class="next"><a href="/blog/pages/fd8228/">Makemore 2 - MLP</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/blog/archives" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/blog/pages/aed865/"><div>
            Makemore 5 - WaveNet
            <!----></div></a> <span class="date">07-04</span></dt></dl><dl><dd>02</dd> <dt><a href="/blog/pages/049b6e/"><div>
            Makemore 4 - Backpropagation Ninja
            <!----></div></a> <span class="date">07-04</span></dt></dl><dl><dd>03</dd> <dt><a href="/blog/pages/c0d04f/"><div>
            Makemore 3 - Activations &amp; Gradients, BatchNorm
            <!----></div></a> <span class="date">07-04</span></dt></dl> <dl><dd></dd> <dt><a href="/blog/archives" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><!----> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2025
    <span>emmableu | <a href="https://github.com/emmableu/vuepress-theme-vdoing/blob/master/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/blog/assets/js/app.fa6bfa40.js" defer></script><script src="/blog/assets/js/2.7ce49225.js" defer></script><script src="/blog/assets/js/421.9a9fcf9c.js" defer></script>
  </body>
</html>
