<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Makemore 5 - WaveNet | Emma&#39;s Blog</title>
    <meta name="generator" content="VuePress 1.9.9">
    <link rel="icon" href="/blog/img/favicon.ico">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">
    <meta name="description" content="blog">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/blog/assets/css/0.styles.f2b65211.css" as="style"><link rel="preload" href="/blog/assets/js/app.fa6bfa40.js" as="script"><link rel="preload" href="/blog/assets/js/2.7ce49225.js" as="script"><link rel="preload" href="/blog/assets/js/425.40010459.js" as="script"><link rel="prefetch" href="/blog/assets/js/10.9b4fdd47.js"><link rel="prefetch" href="/blog/assets/js/100.e7eefa33.js"><link rel="prefetch" href="/blog/assets/js/101.229b595f.js"><link rel="prefetch" href="/blog/assets/js/102.0869e27b.js"><link rel="prefetch" href="/blog/assets/js/103.67051ee3.js"><link rel="prefetch" href="/blog/assets/js/104.5e9ec206.js"><link rel="prefetch" href="/blog/assets/js/105.812b7b15.js"><link rel="prefetch" href="/blog/assets/js/106.d2afd06e.js"><link rel="prefetch" href="/blog/assets/js/107.0e992a28.js"><link rel="prefetch" href="/blog/assets/js/108.d7af612a.js"><link rel="prefetch" href="/blog/assets/js/109.0511ab99.js"><link rel="prefetch" href="/blog/assets/js/11.2658286a.js"><link rel="prefetch" href="/blog/assets/js/110.66eb4fe8.js"><link rel="prefetch" href="/blog/assets/js/111.c4a3506e.js"><link rel="prefetch" href="/blog/assets/js/112.96ad5e97.js"><link rel="prefetch" href="/blog/assets/js/113.d898d02f.js"><link rel="prefetch" href="/blog/assets/js/114.d26fe027.js"><link rel="prefetch" href="/blog/assets/js/115.adbc8f5f.js"><link rel="prefetch" href="/blog/assets/js/116.1932a92b.js"><link rel="prefetch" href="/blog/assets/js/117.969e94f6.js"><link rel="prefetch" href="/blog/assets/js/118.8a40c4b7.js"><link rel="prefetch" href="/blog/assets/js/119.4d5ac55d.js"><link rel="prefetch" href="/blog/assets/js/12.e397a550.js"><link rel="prefetch" href="/blog/assets/js/120.1ea31920.js"><link rel="prefetch" href="/blog/assets/js/121.0f8bbe64.js"><link rel="prefetch" href="/blog/assets/js/122.62cb2b98.js"><link rel="prefetch" href="/blog/assets/js/123.36fb89d8.js"><link rel="prefetch" href="/blog/assets/js/124.51e9f053.js"><link rel="prefetch" href="/blog/assets/js/125.707afbcb.js"><link rel="prefetch" href="/blog/assets/js/126.3f936437.js"><link rel="prefetch" href="/blog/assets/js/127.63ddddea.js"><link rel="prefetch" href="/blog/assets/js/128.45eedbf7.js"><link rel="prefetch" href="/blog/assets/js/129.309b8006.js"><link rel="prefetch" href="/blog/assets/js/13.19ccc9bf.js"><link rel="prefetch" href="/blog/assets/js/130.341188a0.js"><link rel="prefetch" href="/blog/assets/js/131.e6979d87.js"><link rel="prefetch" href="/blog/assets/js/132.162f434b.js"><link rel="prefetch" href="/blog/assets/js/133.3dbe6586.js"><link rel="prefetch" href="/blog/assets/js/134.020e2147.js"><link rel="prefetch" href="/blog/assets/js/135.c830889a.js"><link rel="prefetch" href="/blog/assets/js/136.1f295f91.js"><link rel="prefetch" href="/blog/assets/js/137.e7ff1cf2.js"><link rel="prefetch" href="/blog/assets/js/138.926cd296.js"><link rel="prefetch" href="/blog/assets/js/139.d8973f4f.js"><link rel="prefetch" href="/blog/assets/js/14.3973f32e.js"><link rel="prefetch" href="/blog/assets/js/140.3f410d2a.js"><link rel="prefetch" href="/blog/assets/js/141.29a6ec98.js"><link rel="prefetch" href="/blog/assets/js/142.76cee5a1.js"><link rel="prefetch" href="/blog/assets/js/143.1e68adfd.js"><link rel="prefetch" href="/blog/assets/js/144.0e90fa28.js"><link rel="prefetch" href="/blog/assets/js/145.b461e3eb.js"><link rel="prefetch" href="/blog/assets/js/146.0efa1a6d.js"><link rel="prefetch" href="/blog/assets/js/147.6cb2ae59.js"><link rel="prefetch" href="/blog/assets/js/148.7f9717b8.js"><link rel="prefetch" href="/blog/assets/js/149.b70d37e3.js"><link rel="prefetch" href="/blog/assets/js/15.60c21287.js"><link rel="prefetch" href="/blog/assets/js/150.ef9c5330.js"><link rel="prefetch" href="/blog/assets/js/151.495f2fe3.js"><link rel="prefetch" href="/blog/assets/js/152.399484c7.js"><link rel="prefetch" href="/blog/assets/js/153.b3f76d44.js"><link rel="prefetch" href="/blog/assets/js/154.9b4bcee9.js"><link rel="prefetch" href="/blog/assets/js/155.86d30484.js"><link rel="prefetch" href="/blog/assets/js/156.69309282.js"><link rel="prefetch" href="/blog/assets/js/157.50628274.js"><link rel="prefetch" href="/blog/assets/js/158.6201075e.js"><link rel="prefetch" href="/blog/assets/js/159.6b236af8.js"><link rel="prefetch" href="/blog/assets/js/16.f60df41a.js"><link rel="prefetch" href="/blog/assets/js/160.7cef879a.js"><link rel="prefetch" href="/blog/assets/js/161.e069cc00.js"><link rel="prefetch" href="/blog/assets/js/162.c840bba7.js"><link rel="prefetch" href="/blog/assets/js/163.d92fc034.js"><link rel="prefetch" href="/blog/assets/js/164.1654d287.js"><link rel="prefetch" href="/blog/assets/js/165.488a29ef.js"><link rel="prefetch" href="/blog/assets/js/166.f45211e9.js"><link rel="prefetch" href="/blog/assets/js/167.7c7dab06.js"><link rel="prefetch" href="/blog/assets/js/168.5487e398.js"><link rel="prefetch" href="/blog/assets/js/169.d33859fc.js"><link rel="prefetch" href="/blog/assets/js/17.e4f94e71.js"><link rel="prefetch" href="/blog/assets/js/170.8138d2a9.js"><link rel="prefetch" href="/blog/assets/js/171.f9803ede.js"><link rel="prefetch" href="/blog/assets/js/172.d083e11e.js"><link rel="prefetch" href="/blog/assets/js/173.8bc9a3da.js"><link rel="prefetch" href="/blog/assets/js/174.7bdf84df.js"><link rel="prefetch" href="/blog/assets/js/175.662c4a7d.js"><link rel="prefetch" href="/blog/assets/js/176.7501abe7.js"><link rel="prefetch" href="/blog/assets/js/177.27a6ea08.js"><link rel="prefetch" href="/blog/assets/js/178.542a2e15.js"><link rel="prefetch" href="/blog/assets/js/179.bd90a759.js"><link rel="prefetch" href="/blog/assets/js/18.ce8d611d.js"><link rel="prefetch" href="/blog/assets/js/180.bad5b48f.js"><link rel="prefetch" href="/blog/assets/js/181.75204ef2.js"><link rel="prefetch" href="/blog/assets/js/182.07c3b582.js"><link rel="prefetch" href="/blog/assets/js/183.684e4590.js"><link rel="prefetch" href="/blog/assets/js/184.1ddc109c.js"><link rel="prefetch" href="/blog/assets/js/185.23eefeba.js"><link rel="prefetch" href="/blog/assets/js/186.5023b10a.js"><link rel="prefetch" href="/blog/assets/js/187.82cdd79b.js"><link rel="prefetch" href="/blog/assets/js/188.dfbce339.js"><link rel="prefetch" href="/blog/assets/js/189.3c758dee.js"><link rel="prefetch" href="/blog/assets/js/19.98c0abc0.js"><link rel="prefetch" href="/blog/assets/js/190.b1eff947.js"><link rel="prefetch" href="/blog/assets/js/191.c88913b2.js"><link rel="prefetch" href="/blog/assets/js/192.54f0647d.js"><link rel="prefetch" href="/blog/assets/js/193.54d6343e.js"><link rel="prefetch" href="/blog/assets/js/194.abe54e8a.js"><link rel="prefetch" href="/blog/assets/js/195.099dd0e8.js"><link rel="prefetch" href="/blog/assets/js/196.ab3cc2bc.js"><link rel="prefetch" href="/blog/assets/js/197.a895813f.js"><link rel="prefetch" href="/blog/assets/js/198.94d4bf63.js"><link rel="prefetch" href="/blog/assets/js/199.22ba978c.js"><link rel="prefetch" href="/blog/assets/js/20.1bac6a12.js"><link rel="prefetch" href="/blog/assets/js/200.e0c0c5db.js"><link rel="prefetch" href="/blog/assets/js/201.3decc849.js"><link rel="prefetch" href="/blog/assets/js/202.ddbf28b3.js"><link rel="prefetch" href="/blog/assets/js/203.2397895a.js"><link rel="prefetch" href="/blog/assets/js/204.5f519032.js"><link rel="prefetch" href="/blog/assets/js/205.0f9caae2.js"><link rel="prefetch" href="/blog/assets/js/206.1f6339b7.js"><link rel="prefetch" href="/blog/assets/js/207.3757cf50.js"><link rel="prefetch" href="/blog/assets/js/208.a7f08e37.js"><link rel="prefetch" href="/blog/assets/js/209.c5597e2f.js"><link rel="prefetch" href="/blog/assets/js/21.5d7ecf97.js"><link rel="prefetch" href="/blog/assets/js/210.cba479b0.js"><link rel="prefetch" href="/blog/assets/js/211.0e468dce.js"><link rel="prefetch" href="/blog/assets/js/212.1276f952.js"><link rel="prefetch" href="/blog/assets/js/213.0ab1cbd2.js"><link rel="prefetch" href="/blog/assets/js/214.beab31e6.js"><link rel="prefetch" href="/blog/assets/js/215.85ce8952.js"><link rel="prefetch" href="/blog/assets/js/216.7ae13582.js"><link rel="prefetch" href="/blog/assets/js/217.21c5c4ae.js"><link rel="prefetch" href="/blog/assets/js/218.459846f9.js"><link rel="prefetch" href="/blog/assets/js/219.3ec1a6f1.js"><link rel="prefetch" href="/blog/assets/js/22.2bdcb11a.js"><link rel="prefetch" href="/blog/assets/js/220.0efee18a.js"><link rel="prefetch" href="/blog/assets/js/221.ecd509c6.js"><link rel="prefetch" href="/blog/assets/js/222.068be0e3.js"><link rel="prefetch" href="/blog/assets/js/223.0d7a3417.js"><link rel="prefetch" href="/blog/assets/js/224.e45bfd31.js"><link rel="prefetch" href="/blog/assets/js/225.c94c8651.js"><link rel="prefetch" href="/blog/assets/js/226.2dfa74fd.js"><link rel="prefetch" href="/blog/assets/js/227.38105785.js"><link rel="prefetch" href="/blog/assets/js/228.76ceed84.js"><link rel="prefetch" href="/blog/assets/js/229.54907291.js"><link rel="prefetch" href="/blog/assets/js/23.9bdaa3ab.js"><link rel="prefetch" href="/blog/assets/js/230.bab07940.js"><link rel="prefetch" href="/blog/assets/js/231.15ca6ff3.js"><link rel="prefetch" href="/blog/assets/js/232.22e17e11.js"><link rel="prefetch" href="/blog/assets/js/233.562e078c.js"><link rel="prefetch" href="/blog/assets/js/234.dba05df0.js"><link rel="prefetch" href="/blog/assets/js/235.3e377078.js"><link rel="prefetch" href="/blog/assets/js/236.ee8ef4f7.js"><link rel="prefetch" href="/blog/assets/js/237.342d5a94.js"><link rel="prefetch" href="/blog/assets/js/238.d9a5194f.js"><link rel="prefetch" href="/blog/assets/js/239.3f0ef554.js"><link rel="prefetch" href="/blog/assets/js/24.a091ba45.js"><link rel="prefetch" href="/blog/assets/js/240.73553fb4.js"><link rel="prefetch" href="/blog/assets/js/241.dc725e0b.js"><link rel="prefetch" href="/blog/assets/js/242.a19631f5.js"><link rel="prefetch" href="/blog/assets/js/243.8dad3f92.js"><link rel="prefetch" href="/blog/assets/js/244.1e7085b7.js"><link rel="prefetch" href="/blog/assets/js/245.e32e5959.js"><link rel="prefetch" href="/blog/assets/js/246.abb8f6fc.js"><link rel="prefetch" href="/blog/assets/js/247.40778e7b.js"><link rel="prefetch" href="/blog/assets/js/248.f3129994.js"><link rel="prefetch" href="/blog/assets/js/249.284fbd88.js"><link rel="prefetch" href="/blog/assets/js/25.01fddff0.js"><link rel="prefetch" href="/blog/assets/js/250.e5604caf.js"><link rel="prefetch" href="/blog/assets/js/251.4db1b5d4.js"><link rel="prefetch" href="/blog/assets/js/252.8ee09136.js"><link rel="prefetch" href="/blog/assets/js/253.886ea653.js"><link rel="prefetch" href="/blog/assets/js/254.9570cd86.js"><link rel="prefetch" href="/blog/assets/js/255.3f45535c.js"><link rel="prefetch" href="/blog/assets/js/256.5e65a4d3.js"><link rel="prefetch" href="/blog/assets/js/257.d73448be.js"><link rel="prefetch" href="/blog/assets/js/258.fd2f8dac.js"><link rel="prefetch" href="/blog/assets/js/259.41805386.js"><link rel="prefetch" href="/blog/assets/js/26.ab34c3b9.js"><link rel="prefetch" href="/blog/assets/js/260.940745e5.js"><link rel="prefetch" href="/blog/assets/js/261.4e120cbf.js"><link rel="prefetch" href="/blog/assets/js/262.387220ac.js"><link rel="prefetch" href="/blog/assets/js/263.2ce8ccb8.js"><link rel="prefetch" href="/blog/assets/js/264.f6306429.js"><link rel="prefetch" href="/blog/assets/js/265.f42b5960.js"><link rel="prefetch" href="/blog/assets/js/266.fe571a04.js"><link rel="prefetch" href="/blog/assets/js/267.cdceab63.js"><link rel="prefetch" href="/blog/assets/js/268.e76d12d5.js"><link rel="prefetch" href="/blog/assets/js/269.325b654d.js"><link rel="prefetch" href="/blog/assets/js/27.211e008f.js"><link rel="prefetch" href="/blog/assets/js/270.c5a09ebc.js"><link rel="prefetch" href="/blog/assets/js/271.8582d9ef.js"><link rel="prefetch" href="/blog/assets/js/272.25a996e7.js"><link rel="prefetch" href="/blog/assets/js/273.3cea407a.js"><link rel="prefetch" href="/blog/assets/js/274.e8037b9f.js"><link rel="prefetch" href="/blog/assets/js/275.c24fadc6.js"><link rel="prefetch" href="/blog/assets/js/276.15f6846b.js"><link rel="prefetch" href="/blog/assets/js/277.312bdd0d.js"><link rel="prefetch" href="/blog/assets/js/278.9a3d8365.js"><link rel="prefetch" href="/blog/assets/js/279.f033b4f8.js"><link rel="prefetch" href="/blog/assets/js/28.66852ae6.js"><link rel="prefetch" href="/blog/assets/js/280.35226986.js"><link rel="prefetch" href="/blog/assets/js/281.24522fa7.js"><link rel="prefetch" href="/blog/assets/js/282.2f2bf22d.js"><link rel="prefetch" href="/blog/assets/js/283.7a318e26.js"><link rel="prefetch" href="/blog/assets/js/284.dc2ed524.js"><link rel="prefetch" href="/blog/assets/js/285.0740fa3d.js"><link rel="prefetch" href="/blog/assets/js/286.d800de15.js"><link rel="prefetch" href="/blog/assets/js/287.37d62b42.js"><link rel="prefetch" href="/blog/assets/js/288.9aef5358.js"><link rel="prefetch" href="/blog/assets/js/289.2bf079d7.js"><link rel="prefetch" href="/blog/assets/js/29.141730bc.js"><link rel="prefetch" href="/blog/assets/js/290.23861619.js"><link rel="prefetch" href="/blog/assets/js/291.b90053de.js"><link rel="prefetch" href="/blog/assets/js/292.1ecc1810.js"><link rel="prefetch" href="/blog/assets/js/293.162a2bfd.js"><link rel="prefetch" href="/blog/assets/js/294.7e872ddf.js"><link rel="prefetch" href="/blog/assets/js/295.a67c9dc4.js"><link rel="prefetch" href="/blog/assets/js/296.cd5f1739.js"><link rel="prefetch" href="/blog/assets/js/297.5fba221f.js"><link rel="prefetch" href="/blog/assets/js/298.2698065d.js"><link rel="prefetch" href="/blog/assets/js/299.9ad4582c.js"><link rel="prefetch" href="/blog/assets/js/3.fb6b6218.js"><link rel="prefetch" href="/blog/assets/js/30.057cc531.js"><link rel="prefetch" href="/blog/assets/js/300.52c1803f.js"><link rel="prefetch" href="/blog/assets/js/301.b03a706d.js"><link rel="prefetch" href="/blog/assets/js/302.8ea88eb9.js"><link rel="prefetch" href="/blog/assets/js/303.1502ae39.js"><link rel="prefetch" href="/blog/assets/js/304.f20513d3.js"><link rel="prefetch" href="/blog/assets/js/305.aa35fcf1.js"><link rel="prefetch" href="/blog/assets/js/306.1897421f.js"><link rel="prefetch" href="/blog/assets/js/307.c3d97536.js"><link rel="prefetch" href="/blog/assets/js/308.4f22d76b.js"><link rel="prefetch" href="/blog/assets/js/309.7e7f7c52.js"><link rel="prefetch" href="/blog/assets/js/31.0a0b4625.js"><link rel="prefetch" href="/blog/assets/js/310.2e22d9e1.js"><link rel="prefetch" href="/blog/assets/js/311.974bbf97.js"><link rel="prefetch" href="/blog/assets/js/312.f28c61dc.js"><link rel="prefetch" href="/blog/assets/js/313.3c51e0fa.js"><link rel="prefetch" href="/blog/assets/js/314.d998ea43.js"><link rel="prefetch" href="/blog/assets/js/315.3e9a511f.js"><link rel="prefetch" href="/blog/assets/js/316.5969895b.js"><link rel="prefetch" href="/blog/assets/js/317.fc61c649.js"><link rel="prefetch" href="/blog/assets/js/318.0e38281f.js"><link rel="prefetch" href="/blog/assets/js/319.3c721d92.js"><link rel="prefetch" href="/blog/assets/js/32.ea991562.js"><link rel="prefetch" href="/blog/assets/js/320.b4ab4b4f.js"><link rel="prefetch" href="/blog/assets/js/321.56f69d1a.js"><link rel="prefetch" href="/blog/assets/js/322.20ab832b.js"><link rel="prefetch" href="/blog/assets/js/323.4b2d7ea3.js"><link rel="prefetch" href="/blog/assets/js/324.d81f5847.js"><link rel="prefetch" href="/blog/assets/js/325.7edfab8f.js"><link rel="prefetch" href="/blog/assets/js/326.45f4da77.js"><link rel="prefetch" href="/blog/assets/js/327.ba458f2c.js"><link rel="prefetch" href="/blog/assets/js/328.d86d670d.js"><link rel="prefetch" href="/blog/assets/js/329.f7eac607.js"><link rel="prefetch" href="/blog/assets/js/33.59727a1a.js"><link rel="prefetch" href="/blog/assets/js/330.10d24789.js"><link rel="prefetch" href="/blog/assets/js/331.60d73f78.js"><link rel="prefetch" href="/blog/assets/js/332.6c5b6b35.js"><link rel="prefetch" href="/blog/assets/js/333.7b1b290d.js"><link rel="prefetch" href="/blog/assets/js/334.285526b7.js"><link rel="prefetch" href="/blog/assets/js/335.4780d81e.js"><link rel="prefetch" href="/blog/assets/js/336.5ecc836e.js"><link rel="prefetch" href="/blog/assets/js/337.6fba51e2.js"><link rel="prefetch" href="/blog/assets/js/338.d646ffe0.js"><link rel="prefetch" href="/blog/assets/js/339.45c11835.js"><link rel="prefetch" href="/blog/assets/js/34.e0063628.js"><link rel="prefetch" href="/blog/assets/js/340.f3ae78d4.js"><link rel="prefetch" href="/blog/assets/js/341.0e5e0af1.js"><link rel="prefetch" href="/blog/assets/js/342.5e9536e2.js"><link rel="prefetch" href="/blog/assets/js/343.d2f5b148.js"><link rel="prefetch" href="/blog/assets/js/344.b076b331.js"><link rel="prefetch" href="/blog/assets/js/345.ccb92f9a.js"><link rel="prefetch" href="/blog/assets/js/346.c1d7088c.js"><link rel="prefetch" href="/blog/assets/js/347.76e6b595.js"><link rel="prefetch" href="/blog/assets/js/348.d08fd4eb.js"><link rel="prefetch" href="/blog/assets/js/349.b0633c03.js"><link rel="prefetch" href="/blog/assets/js/35.d02fcd5b.js"><link rel="prefetch" href="/blog/assets/js/350.58bd91c8.js"><link rel="prefetch" href="/blog/assets/js/351.4eeb8781.js"><link rel="prefetch" href="/blog/assets/js/352.92e0273b.js"><link rel="prefetch" href="/blog/assets/js/353.4316b720.js"><link rel="prefetch" href="/blog/assets/js/354.8b1ec3de.js"><link rel="prefetch" href="/blog/assets/js/355.d09b94bf.js"><link rel="prefetch" href="/blog/assets/js/356.5b548a21.js"><link rel="prefetch" href="/blog/assets/js/357.deef470d.js"><link rel="prefetch" href="/blog/assets/js/358.1b8619f3.js"><link rel="prefetch" href="/blog/assets/js/359.62109421.js"><link rel="prefetch" href="/blog/assets/js/36.9a2bf2cb.js"><link rel="prefetch" href="/blog/assets/js/360.b0fbc8bc.js"><link rel="prefetch" href="/blog/assets/js/361.9f4082fe.js"><link rel="prefetch" href="/blog/assets/js/362.998cb7ce.js"><link rel="prefetch" href="/blog/assets/js/363.59416eb7.js"><link rel="prefetch" href="/blog/assets/js/364.673a993e.js"><link rel="prefetch" href="/blog/assets/js/365.2ce18574.js"><link rel="prefetch" href="/blog/assets/js/366.06fb2db3.js"><link rel="prefetch" href="/blog/assets/js/367.82a80c1b.js"><link rel="prefetch" href="/blog/assets/js/368.c6eded31.js"><link rel="prefetch" href="/blog/assets/js/369.cf8dcc59.js"><link rel="prefetch" href="/blog/assets/js/37.14ce705f.js"><link rel="prefetch" href="/blog/assets/js/370.cc5c5295.js"><link rel="prefetch" href="/blog/assets/js/371.03d01383.js"><link rel="prefetch" href="/blog/assets/js/372.84d458d3.js"><link rel="prefetch" href="/blog/assets/js/373.69e36286.js"><link rel="prefetch" href="/blog/assets/js/374.325318a2.js"><link rel="prefetch" href="/blog/assets/js/375.0faf9354.js"><link rel="prefetch" href="/blog/assets/js/376.e383d5f8.js"><link rel="prefetch" href="/blog/assets/js/377.a45039dd.js"><link rel="prefetch" href="/blog/assets/js/378.e6bf1f8a.js"><link rel="prefetch" href="/blog/assets/js/379.ab3908c4.js"><link rel="prefetch" href="/blog/assets/js/38.d8358ff1.js"><link rel="prefetch" href="/blog/assets/js/380.9155ba09.js"><link rel="prefetch" href="/blog/assets/js/381.964c9828.js"><link rel="prefetch" href="/blog/assets/js/382.b2c17375.js"><link rel="prefetch" href="/blog/assets/js/383.f74bb63d.js"><link rel="prefetch" href="/blog/assets/js/384.f46a5f9f.js"><link rel="prefetch" href="/blog/assets/js/385.2b0fad5e.js"><link rel="prefetch" href="/blog/assets/js/386.b7fd30fd.js"><link rel="prefetch" href="/blog/assets/js/387.e387b6d2.js"><link rel="prefetch" href="/blog/assets/js/388.66733dc7.js"><link rel="prefetch" href="/blog/assets/js/389.3b9dc956.js"><link rel="prefetch" href="/blog/assets/js/39.52d6d224.js"><link rel="prefetch" href="/blog/assets/js/390.aa1a3f13.js"><link rel="prefetch" href="/blog/assets/js/391.b98a3f89.js"><link rel="prefetch" href="/blog/assets/js/392.51947d62.js"><link rel="prefetch" href="/blog/assets/js/393.4e8ca73f.js"><link rel="prefetch" href="/blog/assets/js/394.4eae3c2a.js"><link rel="prefetch" href="/blog/assets/js/395.b41e57dd.js"><link rel="prefetch" href="/blog/assets/js/396.f19229fd.js"><link rel="prefetch" href="/blog/assets/js/397.8caf94d9.js"><link rel="prefetch" href="/blog/assets/js/398.a79fa068.js"><link rel="prefetch" href="/blog/assets/js/399.1f8f72a8.js"><link rel="prefetch" href="/blog/assets/js/4.72adf461.js"><link rel="prefetch" href="/blog/assets/js/40.42598248.js"><link rel="prefetch" href="/blog/assets/js/400.31d2590c.js"><link rel="prefetch" href="/blog/assets/js/401.430ee10a.js"><link rel="prefetch" href="/blog/assets/js/402.0969de14.js"><link rel="prefetch" href="/blog/assets/js/403.22305621.js"><link rel="prefetch" href="/blog/assets/js/404.c24c1ea8.js"><link rel="prefetch" href="/blog/assets/js/405.a7531e74.js"><link rel="prefetch" href="/blog/assets/js/406.44308bfa.js"><link rel="prefetch" href="/blog/assets/js/407.5bea8380.js"><link rel="prefetch" href="/blog/assets/js/408.47124f69.js"><link rel="prefetch" href="/blog/assets/js/409.f2eb55a4.js"><link rel="prefetch" href="/blog/assets/js/41.78de33b5.js"><link rel="prefetch" href="/blog/assets/js/410.75f37834.js"><link rel="prefetch" href="/blog/assets/js/411.af5a1d9f.js"><link rel="prefetch" href="/blog/assets/js/412.70ce0662.js"><link rel="prefetch" href="/blog/assets/js/413.4773178b.js"><link rel="prefetch" href="/blog/assets/js/414.b91b3c53.js"><link rel="prefetch" href="/blog/assets/js/415.93254e87.js"><link rel="prefetch" href="/blog/assets/js/416.30e849d5.js"><link rel="prefetch" href="/blog/assets/js/417.1d626e6d.js"><link rel="prefetch" href="/blog/assets/js/418.c2830038.js"><link rel="prefetch" href="/blog/assets/js/419.de704363.js"><link rel="prefetch" href="/blog/assets/js/42.f02bfe3b.js"><link rel="prefetch" href="/blog/assets/js/420.934cfa49.js"><link rel="prefetch" href="/blog/assets/js/421.9a9fcf9c.js"><link rel="prefetch" href="/blog/assets/js/422.716d7de1.js"><link rel="prefetch" href="/blog/assets/js/423.5502a762.js"><link rel="prefetch" href="/blog/assets/js/424.9362a268.js"><link rel="prefetch" href="/blog/assets/js/426.9012302f.js"><link rel="prefetch" href="/blog/assets/js/427.2f4f8329.js"><link rel="prefetch" href="/blog/assets/js/428.48911c6b.js"><link rel="prefetch" href="/blog/assets/js/429.6beb6f8a.js"><link rel="prefetch" href="/blog/assets/js/43.027dffdd.js"><link rel="prefetch" href="/blog/assets/js/430.20547f3b.js"><link rel="prefetch" href="/blog/assets/js/431.f7d8b272.js"><link rel="prefetch" href="/blog/assets/js/432.29f6c6c5.js"><link rel="prefetch" href="/blog/assets/js/433.053472dd.js"><link rel="prefetch" href="/blog/assets/js/434.fe7a6b42.js"><link rel="prefetch" href="/blog/assets/js/435.7b095c52.js"><link rel="prefetch" href="/blog/assets/js/436.8e65b85b.js"><link rel="prefetch" href="/blog/assets/js/437.6f2be763.js"><link rel="prefetch" href="/blog/assets/js/438.696a4a24.js"><link rel="prefetch" href="/blog/assets/js/439.8e0ffda2.js"><link rel="prefetch" href="/blog/assets/js/44.60d7bff7.js"><link rel="prefetch" href="/blog/assets/js/440.0f9d7601.js"><link rel="prefetch" href="/blog/assets/js/441.9293a0c0.js"><link rel="prefetch" href="/blog/assets/js/442.3ab911fb.js"><link rel="prefetch" href="/blog/assets/js/443.84e874a2.js"><link rel="prefetch" href="/blog/assets/js/444.a5560886.js"><link rel="prefetch" href="/blog/assets/js/445.ee43400f.js"><link rel="prefetch" href="/blog/assets/js/446.e451b4a7.js"><link rel="prefetch" href="/blog/assets/js/447.af57b4dd.js"><link rel="prefetch" href="/blog/assets/js/448.8369a48d.js"><link rel="prefetch" href="/blog/assets/js/449.81a81117.js"><link rel="prefetch" href="/blog/assets/js/45.54197661.js"><link rel="prefetch" href="/blog/assets/js/450.ed1865ae.js"><link rel="prefetch" href="/blog/assets/js/451.c6fed955.js"><link rel="prefetch" href="/blog/assets/js/452.c490fd3f.js"><link rel="prefetch" href="/blog/assets/js/453.ce54e414.js"><link rel="prefetch" href="/blog/assets/js/454.0fcc3b33.js"><link rel="prefetch" href="/blog/assets/js/455.49b6deb2.js"><link rel="prefetch" href="/blog/assets/js/456.cea18d70.js"><link rel="prefetch" href="/blog/assets/js/457.eeb4e4ea.js"><link rel="prefetch" href="/blog/assets/js/458.6536f79d.js"><link rel="prefetch" href="/blog/assets/js/459.08049472.js"><link rel="prefetch" href="/blog/assets/js/46.2ea156c5.js"><link rel="prefetch" href="/blog/assets/js/460.ce2134bf.js"><link rel="prefetch" href="/blog/assets/js/461.4ef74cbc.js"><link rel="prefetch" href="/blog/assets/js/462.0135ab05.js"><link rel="prefetch" href="/blog/assets/js/463.75c97bc9.js"><link rel="prefetch" href="/blog/assets/js/464.0731e3a8.js"><link rel="prefetch" href="/blog/assets/js/465.58716aaa.js"><link rel="prefetch" href="/blog/assets/js/466.5d1c9632.js"><link rel="prefetch" href="/blog/assets/js/467.4a0cc264.js"><link rel="prefetch" href="/blog/assets/js/468.4d62ec95.js"><link rel="prefetch" href="/blog/assets/js/469.371bf824.js"><link rel="prefetch" href="/blog/assets/js/47.9c2846f6.js"><link rel="prefetch" href="/blog/assets/js/470.20c9b1d0.js"><link rel="prefetch" href="/blog/assets/js/471.b55b7293.js"><link rel="prefetch" href="/blog/assets/js/472.af9bed94.js"><link rel="prefetch" href="/blog/assets/js/473.763ed78b.js"><link rel="prefetch" href="/blog/assets/js/474.0c984479.js"><link rel="prefetch" href="/blog/assets/js/475.64086e43.js"><link rel="prefetch" href="/blog/assets/js/476.87a9a0cc.js"><link rel="prefetch" href="/blog/assets/js/477.bf829a5b.js"><link rel="prefetch" href="/blog/assets/js/478.e4b446ce.js"><link rel="prefetch" href="/blog/assets/js/479.2b9f77a6.js"><link rel="prefetch" href="/blog/assets/js/48.9a1455cf.js"><link rel="prefetch" href="/blog/assets/js/480.17cc6a47.js"><link rel="prefetch" href="/blog/assets/js/481.fa5b561f.js"><link rel="prefetch" href="/blog/assets/js/482.03b3eb32.js"><link rel="prefetch" href="/blog/assets/js/483.31191665.js"><link rel="prefetch" href="/blog/assets/js/484.d8a4c9bc.js"><link rel="prefetch" href="/blog/assets/js/485.e249dec7.js"><link rel="prefetch" href="/blog/assets/js/486.0fc0098f.js"><link rel="prefetch" href="/blog/assets/js/487.324062ec.js"><link rel="prefetch" href="/blog/assets/js/488.8ca4dee4.js"><link rel="prefetch" href="/blog/assets/js/489.efc83e4a.js"><link rel="prefetch" href="/blog/assets/js/49.697a7a9f.js"><link rel="prefetch" href="/blog/assets/js/490.45710d33.js"><link rel="prefetch" href="/blog/assets/js/491.8642a532.js"><link rel="prefetch" href="/blog/assets/js/492.6fd7cdf1.js"><link rel="prefetch" href="/blog/assets/js/493.e66269d0.js"><link rel="prefetch" href="/blog/assets/js/494.8617e18f.js"><link rel="prefetch" href="/blog/assets/js/495.a701486e.js"><link rel="prefetch" href="/blog/assets/js/496.6c880390.js"><link rel="prefetch" href="/blog/assets/js/497.d270d556.js"><link rel="prefetch" href="/blog/assets/js/498.88cbb5cd.js"><link rel="prefetch" href="/blog/assets/js/499.9e5d240e.js"><link rel="prefetch" href="/blog/assets/js/5.15a5c21b.js"><link rel="prefetch" href="/blog/assets/js/50.c6827336.js"><link rel="prefetch" href="/blog/assets/js/500.75b98d7e.js"><link rel="prefetch" href="/blog/assets/js/501.56835982.js"><link rel="prefetch" href="/blog/assets/js/502.6b40298b.js"><link rel="prefetch" href="/blog/assets/js/503.c1d698cc.js"><link rel="prefetch" href="/blog/assets/js/504.ccad05c2.js"><link rel="prefetch" href="/blog/assets/js/505.6f0caa3b.js"><link rel="prefetch" href="/blog/assets/js/506.aebe2376.js"><link rel="prefetch" href="/blog/assets/js/507.211ef741.js"><link rel="prefetch" href="/blog/assets/js/508.fa181cc2.js"><link rel="prefetch" href="/blog/assets/js/509.3d4bb4eb.js"><link rel="prefetch" href="/blog/assets/js/51.e12228d3.js"><link rel="prefetch" href="/blog/assets/js/510.7bc8cf92.js"><link rel="prefetch" href="/blog/assets/js/511.11fdfdc1.js"><link rel="prefetch" href="/blog/assets/js/512.ecc52d98.js"><link rel="prefetch" href="/blog/assets/js/513.7297573b.js"><link rel="prefetch" href="/blog/assets/js/514.7b747cce.js"><link rel="prefetch" href="/blog/assets/js/515.026fed32.js"><link rel="prefetch" href="/blog/assets/js/516.ed28c764.js"><link rel="prefetch" href="/blog/assets/js/517.2f57e972.js"><link rel="prefetch" href="/blog/assets/js/518.f88b52b4.js"><link rel="prefetch" href="/blog/assets/js/519.7c75386a.js"><link rel="prefetch" href="/blog/assets/js/52.c2faa40b.js"><link rel="prefetch" href="/blog/assets/js/520.75a48154.js"><link rel="prefetch" href="/blog/assets/js/521.895157dd.js"><link rel="prefetch" href="/blog/assets/js/522.7d0e847a.js"><link rel="prefetch" href="/blog/assets/js/523.01484cdc.js"><link rel="prefetch" href="/blog/assets/js/524.4d90ab64.js"><link rel="prefetch" href="/blog/assets/js/525.d1549e6c.js"><link rel="prefetch" href="/blog/assets/js/526.05483b68.js"><link rel="prefetch" href="/blog/assets/js/527.c3429fe2.js"><link rel="prefetch" href="/blog/assets/js/528.6203d42b.js"><link rel="prefetch" href="/blog/assets/js/529.5d865bd5.js"><link rel="prefetch" href="/blog/assets/js/53.5709a523.js"><link rel="prefetch" href="/blog/assets/js/530.a70a1acb.js"><link rel="prefetch" href="/blog/assets/js/531.66905b3e.js"><link rel="prefetch" href="/blog/assets/js/532.9f948fd2.js"><link rel="prefetch" href="/blog/assets/js/533.9c3dcf3c.js"><link rel="prefetch" href="/blog/assets/js/534.bcecc9a9.js"><link rel="prefetch" href="/blog/assets/js/535.01da0e85.js"><link rel="prefetch" href="/blog/assets/js/536.18503588.js"><link rel="prefetch" href="/blog/assets/js/537.3b07f2d9.js"><link rel="prefetch" href="/blog/assets/js/538.5435ae36.js"><link rel="prefetch" href="/blog/assets/js/539.bb504961.js"><link rel="prefetch" href="/blog/assets/js/54.07a4a582.js"><link rel="prefetch" href="/blog/assets/js/540.dc306ab2.js"><link rel="prefetch" href="/blog/assets/js/541.3a27f51c.js"><link rel="prefetch" href="/blog/assets/js/542.5760d344.js"><link rel="prefetch" href="/blog/assets/js/543.c2b318db.js"><link rel="prefetch" href="/blog/assets/js/544.3e7dfe68.js"><link rel="prefetch" href="/blog/assets/js/545.b9d38be9.js"><link rel="prefetch" href="/blog/assets/js/546.57f76a93.js"><link rel="prefetch" href="/blog/assets/js/547.a24678cb.js"><link rel="prefetch" href="/blog/assets/js/548.92a9e320.js"><link rel="prefetch" href="/blog/assets/js/549.ba3f7475.js"><link rel="prefetch" href="/blog/assets/js/55.f0ff0d7c.js"><link rel="prefetch" href="/blog/assets/js/550.85bf139d.js"><link rel="prefetch" href="/blog/assets/js/551.36783254.js"><link rel="prefetch" href="/blog/assets/js/552.e5e86f31.js"><link rel="prefetch" href="/blog/assets/js/553.7be649df.js"><link rel="prefetch" href="/blog/assets/js/554.8be323b3.js"><link rel="prefetch" href="/blog/assets/js/555.97049205.js"><link rel="prefetch" href="/blog/assets/js/556.a85939ec.js"><link rel="prefetch" href="/blog/assets/js/557.f0ea5bef.js"><link rel="prefetch" href="/blog/assets/js/558.f8d4d2d7.js"><link rel="prefetch" href="/blog/assets/js/559.2ef926c7.js"><link rel="prefetch" href="/blog/assets/js/56.c0cbcd65.js"><link rel="prefetch" href="/blog/assets/js/560.56eb82c5.js"><link rel="prefetch" href="/blog/assets/js/561.03a320f1.js"><link rel="prefetch" href="/blog/assets/js/562.649a7599.js"><link rel="prefetch" href="/blog/assets/js/563.8721466c.js"><link rel="prefetch" href="/blog/assets/js/564.3baad1bf.js"><link rel="prefetch" href="/blog/assets/js/565.e5e5c627.js"><link rel="prefetch" href="/blog/assets/js/566.315c4528.js"><link rel="prefetch" href="/blog/assets/js/567.b12e27ea.js"><link rel="prefetch" href="/blog/assets/js/568.225226ec.js"><link rel="prefetch" href="/blog/assets/js/569.da29d7d5.js"><link rel="prefetch" href="/blog/assets/js/57.19d05b74.js"><link rel="prefetch" href="/blog/assets/js/570.acc63d86.js"><link rel="prefetch" href="/blog/assets/js/571.a1637cdc.js"><link rel="prefetch" href="/blog/assets/js/572.bb88c6a3.js"><link rel="prefetch" href="/blog/assets/js/573.3fdb3549.js"><link rel="prefetch" href="/blog/assets/js/574.e83e19eb.js"><link rel="prefetch" href="/blog/assets/js/575.4314526d.js"><link rel="prefetch" href="/blog/assets/js/576.45816383.js"><link rel="prefetch" href="/blog/assets/js/577.27b63977.js"><link rel="prefetch" href="/blog/assets/js/578.20d32e8a.js"><link rel="prefetch" href="/blog/assets/js/579.55cf4824.js"><link rel="prefetch" href="/blog/assets/js/58.6e93d3bf.js"><link rel="prefetch" href="/blog/assets/js/580.d531b052.js"><link rel="prefetch" href="/blog/assets/js/581.f627031b.js"><link rel="prefetch" href="/blog/assets/js/582.7a256d37.js"><link rel="prefetch" href="/blog/assets/js/583.7e6734b3.js"><link rel="prefetch" href="/blog/assets/js/584.dfb3a9cb.js"><link rel="prefetch" href="/blog/assets/js/585.a71b9e6e.js"><link rel="prefetch" href="/blog/assets/js/586.5137eb0c.js"><link rel="prefetch" href="/blog/assets/js/587.5b00ff50.js"><link rel="prefetch" href="/blog/assets/js/588.6683a53f.js"><link rel="prefetch" href="/blog/assets/js/589.c2bb0000.js"><link rel="prefetch" href="/blog/assets/js/59.74303d32.js"><link rel="prefetch" href="/blog/assets/js/590.ac1e550c.js"><link rel="prefetch" href="/blog/assets/js/591.124f0d02.js"><link rel="prefetch" href="/blog/assets/js/592.c930684a.js"><link rel="prefetch" href="/blog/assets/js/593.5010d3e0.js"><link rel="prefetch" href="/blog/assets/js/594.26376a7e.js"><link rel="prefetch" href="/blog/assets/js/595.b0a30b26.js"><link rel="prefetch" href="/blog/assets/js/596.b3f21662.js"><link rel="prefetch" href="/blog/assets/js/597.c26a075e.js"><link rel="prefetch" href="/blog/assets/js/598.baaa2008.js"><link rel="prefetch" href="/blog/assets/js/599.76aefe16.js"><link rel="prefetch" href="/blog/assets/js/6.c39ed483.js"><link rel="prefetch" href="/blog/assets/js/60.ef364511.js"><link rel="prefetch" href="/blog/assets/js/600.adf240b2.js"><link rel="prefetch" href="/blog/assets/js/601.e5c38ddf.js"><link rel="prefetch" href="/blog/assets/js/602.c9ffa321.js"><link rel="prefetch" href="/blog/assets/js/603.36192b41.js"><link rel="prefetch" href="/blog/assets/js/604.5c4f5034.js"><link rel="prefetch" href="/blog/assets/js/605.51fbb0a4.js"><link rel="prefetch" href="/blog/assets/js/606.88fe8276.js"><link rel="prefetch" href="/blog/assets/js/607.7dc7d0b1.js"><link rel="prefetch" href="/blog/assets/js/608.0b5d9f52.js"><link rel="prefetch" href="/blog/assets/js/609.a7830f0c.js"><link rel="prefetch" href="/blog/assets/js/61.436e46a1.js"><link rel="prefetch" href="/blog/assets/js/610.031fa893.js"><link rel="prefetch" href="/blog/assets/js/611.90e0e4d3.js"><link rel="prefetch" href="/blog/assets/js/612.2b9a79d8.js"><link rel="prefetch" href="/blog/assets/js/613.d38f2851.js"><link rel="prefetch" href="/blog/assets/js/614.6cfef72e.js"><link rel="prefetch" href="/blog/assets/js/615.73222425.js"><link rel="prefetch" href="/blog/assets/js/616.771db440.js"><link rel="prefetch" href="/blog/assets/js/617.a4729ad6.js"><link rel="prefetch" href="/blog/assets/js/618.5ea9e128.js"><link rel="prefetch" href="/blog/assets/js/619.10f5472f.js"><link rel="prefetch" href="/blog/assets/js/62.9490960b.js"><link rel="prefetch" href="/blog/assets/js/620.d0069dce.js"><link rel="prefetch" href="/blog/assets/js/621.d19ea508.js"><link rel="prefetch" href="/blog/assets/js/622.9e5920b2.js"><link rel="prefetch" href="/blog/assets/js/623.78d93448.js"><link rel="prefetch" href="/blog/assets/js/624.d37d7fce.js"><link rel="prefetch" href="/blog/assets/js/625.447be412.js"><link rel="prefetch" href="/blog/assets/js/626.e59af340.js"><link rel="prefetch" href="/blog/assets/js/627.7e6d7c95.js"><link rel="prefetch" href="/blog/assets/js/628.d135b01b.js"><link rel="prefetch" href="/blog/assets/js/629.8886d8ea.js"><link rel="prefetch" href="/blog/assets/js/63.6cc1bcab.js"><link rel="prefetch" href="/blog/assets/js/630.22d4ced4.js"><link rel="prefetch" href="/blog/assets/js/631.9e7843f6.js"><link rel="prefetch" href="/blog/assets/js/632.4803808d.js"><link rel="prefetch" href="/blog/assets/js/633.50e4112f.js"><link rel="prefetch" href="/blog/assets/js/634.bb993c38.js"><link rel="prefetch" href="/blog/assets/js/635.5d6b9e6f.js"><link rel="prefetch" href="/blog/assets/js/636.9b48556d.js"><link rel="prefetch" href="/blog/assets/js/637.c42758ba.js"><link rel="prefetch" href="/blog/assets/js/638.68cc6fae.js"><link rel="prefetch" href="/blog/assets/js/639.169fa156.js"><link rel="prefetch" href="/blog/assets/js/64.abdee43a.js"><link rel="prefetch" href="/blog/assets/js/640.fbe8a02e.js"><link rel="prefetch" href="/blog/assets/js/641.ec22012c.js"><link rel="prefetch" href="/blog/assets/js/642.d4d1938f.js"><link rel="prefetch" href="/blog/assets/js/643.10235c62.js"><link rel="prefetch" href="/blog/assets/js/644.c1fadb2f.js"><link rel="prefetch" href="/blog/assets/js/645.c149df88.js"><link rel="prefetch" href="/blog/assets/js/646.c6c3f8e0.js"><link rel="prefetch" href="/blog/assets/js/647.6958847b.js"><link rel="prefetch" href="/blog/assets/js/648.5c76d596.js"><link rel="prefetch" href="/blog/assets/js/649.d6beec02.js"><link rel="prefetch" href="/blog/assets/js/65.68211d02.js"><link rel="prefetch" href="/blog/assets/js/650.89cbe447.js"><link rel="prefetch" href="/blog/assets/js/651.92467f48.js"><link rel="prefetch" href="/blog/assets/js/652.4845f96a.js"><link rel="prefetch" href="/blog/assets/js/653.a47fdb3b.js"><link rel="prefetch" href="/blog/assets/js/654.fcea3f5b.js"><link rel="prefetch" href="/blog/assets/js/655.4e38720d.js"><link rel="prefetch" href="/blog/assets/js/656.a397f16b.js"><link rel="prefetch" href="/blog/assets/js/657.dde34611.js"><link rel="prefetch" href="/blog/assets/js/658.0039ce51.js"><link rel="prefetch" href="/blog/assets/js/659.a0c401bc.js"><link rel="prefetch" href="/blog/assets/js/66.82efb6b8.js"><link rel="prefetch" href="/blog/assets/js/660.23dd5e68.js"><link rel="prefetch" href="/blog/assets/js/661.bc079b94.js"><link rel="prefetch" href="/blog/assets/js/662.f43d86c6.js"><link rel="prefetch" href="/blog/assets/js/663.a612b987.js"><link rel="prefetch" href="/blog/assets/js/664.f19257f7.js"><link rel="prefetch" href="/blog/assets/js/665.0cbf6fc1.js"><link rel="prefetch" href="/blog/assets/js/666.7a7c5b50.js"><link rel="prefetch" href="/blog/assets/js/667.70bcb46c.js"><link rel="prefetch" href="/blog/assets/js/668.c1c81ab6.js"><link rel="prefetch" href="/blog/assets/js/669.75638ed7.js"><link rel="prefetch" href="/blog/assets/js/67.9f6abed5.js"><link rel="prefetch" href="/blog/assets/js/670.2f90459b.js"><link rel="prefetch" href="/blog/assets/js/671.2ab85c06.js"><link rel="prefetch" href="/blog/assets/js/672.6975af2f.js"><link rel="prefetch" href="/blog/assets/js/673.4a5e0d55.js"><link rel="prefetch" href="/blog/assets/js/674.4b1db2e3.js"><link rel="prefetch" href="/blog/assets/js/675.162422a7.js"><link rel="prefetch" href="/blog/assets/js/676.5712b341.js"><link rel="prefetch" href="/blog/assets/js/677.f0d472cb.js"><link rel="prefetch" href="/blog/assets/js/678.a25199d2.js"><link rel="prefetch" href="/blog/assets/js/679.eebf998e.js"><link rel="prefetch" href="/blog/assets/js/68.b54c5d39.js"><link rel="prefetch" href="/blog/assets/js/680.9b45dc26.js"><link rel="prefetch" href="/blog/assets/js/681.d998bda3.js"><link rel="prefetch" href="/blog/assets/js/682.26a6b3b8.js"><link rel="prefetch" href="/blog/assets/js/683.3d3255b3.js"><link rel="prefetch" href="/blog/assets/js/684.01350009.js"><link rel="prefetch" href="/blog/assets/js/685.d94d2d49.js"><link rel="prefetch" href="/blog/assets/js/686.14b9a854.js"><link rel="prefetch" href="/blog/assets/js/687.6801763c.js"><link rel="prefetch" href="/blog/assets/js/688.c869d83c.js"><link rel="prefetch" href="/blog/assets/js/689.721c5842.js"><link rel="prefetch" href="/blog/assets/js/69.96961d17.js"><link rel="prefetch" href="/blog/assets/js/690.c58e3111.js"><link rel="prefetch" href="/blog/assets/js/691.a3ba298b.js"><link rel="prefetch" href="/blog/assets/js/692.976c9961.js"><link rel="prefetch" href="/blog/assets/js/693.dfa1dc96.js"><link rel="prefetch" href="/blog/assets/js/694.d5095ad8.js"><link rel="prefetch" href="/blog/assets/js/695.75a9299f.js"><link rel="prefetch" href="/blog/assets/js/696.47cd8b93.js"><link rel="prefetch" href="/blog/assets/js/697.f7bd7f56.js"><link rel="prefetch" href="/blog/assets/js/698.bfe02dd1.js"><link rel="prefetch" href="/blog/assets/js/699.5b6fee9c.js"><link rel="prefetch" href="/blog/assets/js/7.8763782e.js"><link rel="prefetch" href="/blog/assets/js/70.1c7c67c2.js"><link rel="prefetch" href="/blog/assets/js/700.49ecc111.js"><link rel="prefetch" href="/blog/assets/js/701.b19efefd.js"><link rel="prefetch" href="/blog/assets/js/702.d89fba61.js"><link rel="prefetch" href="/blog/assets/js/703.cbbe6ab7.js"><link rel="prefetch" href="/blog/assets/js/704.f221501a.js"><link rel="prefetch" href="/blog/assets/js/705.9b1567f8.js"><link rel="prefetch" href="/blog/assets/js/706.83b5a9bc.js"><link rel="prefetch" href="/blog/assets/js/707.38bfe6a4.js"><link rel="prefetch" href="/blog/assets/js/708.c4a02d49.js"><link rel="prefetch" href="/blog/assets/js/709.c37c1d0b.js"><link rel="prefetch" href="/blog/assets/js/71.136106d8.js"><link rel="prefetch" href="/blog/assets/js/710.b6daefb8.js"><link rel="prefetch" href="/blog/assets/js/711.60a8d807.js"><link rel="prefetch" href="/blog/assets/js/712.f1600b25.js"><link rel="prefetch" href="/blog/assets/js/713.9b84fe0f.js"><link rel="prefetch" href="/blog/assets/js/714.85f8dfd7.js"><link rel="prefetch" href="/blog/assets/js/715.2e7ac623.js"><link rel="prefetch" href="/blog/assets/js/716.d4016dae.js"><link rel="prefetch" href="/blog/assets/js/72.d1192ec4.js"><link rel="prefetch" href="/blog/assets/js/73.cefbd395.js"><link rel="prefetch" href="/blog/assets/js/74.f7652c2d.js"><link rel="prefetch" href="/blog/assets/js/75.93794018.js"><link rel="prefetch" href="/blog/assets/js/76.ea74a9e5.js"><link rel="prefetch" href="/blog/assets/js/77.5ab8d933.js"><link rel="prefetch" href="/blog/assets/js/78.d99be8f9.js"><link rel="prefetch" href="/blog/assets/js/79.514e7b92.js"><link rel="prefetch" href="/blog/assets/js/8.4f413a3f.js"><link rel="prefetch" href="/blog/assets/js/80.311c1c3d.js"><link rel="prefetch" href="/blog/assets/js/81.20e611a2.js"><link rel="prefetch" href="/blog/assets/js/82.33311f3c.js"><link rel="prefetch" href="/blog/assets/js/83.d0445fd9.js"><link rel="prefetch" href="/blog/assets/js/84.cdf6237f.js"><link rel="prefetch" href="/blog/assets/js/85.39e8a5b1.js"><link rel="prefetch" href="/blog/assets/js/86.5c32af0a.js"><link rel="prefetch" href="/blog/assets/js/87.66683f39.js"><link rel="prefetch" href="/blog/assets/js/88.7ad0a079.js"><link rel="prefetch" href="/blog/assets/js/89.2d677ef4.js"><link rel="prefetch" href="/blog/assets/js/9.4a0f256f.js"><link rel="prefetch" href="/blog/assets/js/90.322cff52.js"><link rel="prefetch" href="/blog/assets/js/91.5f07c279.js"><link rel="prefetch" href="/blog/assets/js/92.d6c06cd2.js"><link rel="prefetch" href="/blog/assets/js/93.6ba1a145.js"><link rel="prefetch" href="/blog/assets/js/94.b917fb97.js"><link rel="prefetch" href="/blog/assets/js/95.05ebd8ca.js"><link rel="prefetch" href="/blog/assets/js/96.649aca28.js"><link rel="prefetch" href="/blog/assets/js/97.6cfc54b2.js"><link rel="prefetch" href="/blog/assets/js/98.754036a7.js"><link rel="prefetch" href="/blog/assets/js/99.c0a4fe5b.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.f2b65211.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blog/" class="home-link router-link-active"><img src="/blog/img/logo.png" alt="Emma's Blog" class="logo"> <span class="site-name can-hide">Emma's Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/" class="nav-link">首页</a></div><div class="nav-item"><a href="/blog/bytag/" class="nav-link">By Tag</a></div><div class="nav-item"><a href="/blog/google/" class="nav-link">Google</a></div><div class="nav-item"><a href="/blog/ml/" class="nav-link">机器学习</a></div><div class="nav-item"><a href="/blog/bq/" class="nav-link">BQ</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Companies" class="dropdown-title"><!----> <span class="title" style="display:;">Companies</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/ls/" class="nav-link">Facebook</a></li><li class="dropdown-item"><!----> <a href="/blog/design/" class="nav-link">System Design</a></li><li class="dropdown-item"><!----> <a href="/blog/twosigma/" class="nav-link">标准差</a></li><li class="dropdown-item"><!----> <a href="/blog/leetcode/" class="nav-link">其它</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/blog/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/blog/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/blog/archives/" class="nav-link">归档</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://raw.githubusercontent.com/emmableu/image/master/202204101726398.png"> <div class="blogger-info"><h3>emmableu</h3> <span></span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/blog/" class="nav-link">首页</a></div><div class="nav-item"><a href="/blog/bytag/" class="nav-link">By Tag</a></div><div class="nav-item"><a href="/blog/google/" class="nav-link">Google</a></div><div class="nav-item"><a href="/blog/ml/" class="nav-link">机器学习</a></div><div class="nav-item"><a href="/blog/bq/" class="nav-link">BQ</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Companies" class="dropdown-title"><!----> <span class="title" style="display:;">Companies</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/ls/" class="nav-link">Facebook</a></li><li class="dropdown-item"><!----> <a href="/blog/design/" class="nav-link">System Design</a></li><li class="dropdown-item"><!----> <a href="/blog/twosigma/" class="nav-link">标准差</a></li><li class="dropdown-item"><!----> <a href="/blog/leetcode/" class="nav-link">其它</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/blog/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/blog/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/blog/archives/" class="nav-link">归档</a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Zero To Hero</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/blog/pages/5de0af/" class="sidebar-link">Micrograd</a></li><li><a href="/blog/pages/072835/" class="sidebar-link">Makemore 1.1 - bigram</a></li><li><a href="/blog/pages/3d7624/" class="sidebar-link">Makemore 1.2 - trigram 1</a></li><li><a href="/blog/pages/fd8228/" class="sidebar-link">Makemore 2 - MLP</a></li><li><a href="/blog/pages/c0d04f/" class="sidebar-link">Makemore 3 - Activations &amp; Gradients, BatchNorm</a></li><li><a href="/blog/pages/049b6e/" class="sidebar-link">Makemore 4 - Backpropagation Ninja</a></li><li><a href="/blog/pages/aed865/" aria-current="page" class="active sidebar-link">Makemore 5 - WaveNet</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/blog/pages/aed865/#step-2-1-adjust-input-to-allow-block-size-8" class="sidebar-link">Step 2.1: Adjust input to allow block_size = 8</a></li><li class="sidebar-sub-header level2"><a href="/blog/pages/aed865/#step-2-2-update-network-structure" class="sidebar-link">Step 2.2, Update Network Structure</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/blog/pages/aed865/#step-2-2-1-add-flattenconsecutive-layer" class="sidebar-link">Step 2.2.1: Add FlattenConsecutive Layer</a></li><li class="sidebar-sub-header level3"><a href="/blog/pages/aed865/#step-2-2-2-adjust-the-batchnorm-dimension" class="sidebar-link">Step 2.2.2: Adjust the BatchNorm Dimension</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/blog/pages/aed865/#_2-3-add-forward-hook-to-print-layer-shape" class="sidebar-link">2.3 Add Forward Hook to Print Layer Shape</a></li></ul></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Machine Learning General</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Machine Learning Concepts</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Reinforcement Learning</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>PyTorch</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span> Complete ML Projects</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-1"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/blog/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/blog/ml/#机器学习八股文" data-v-06225672>机器学习八股文</a></li><li data-v-06225672><a href="/blog/ml/#Zero To Hero" data-v-06225672>Zero To Hero</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="javascript:;" data-v-06225672>emmableu</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2025-07-04</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><!---->Makemore 5 - WaveNet<!----></h1>  <div class="theme-vdoing-content content__default"><p>We take the 2-layer MLP from previous video and make it deeper with a tree-like structure, arriving at a convolutional neural network architecture similar to the WaveNet (2016) from DeepMind. In the WaveNet paper, the same hierarchical architecture is implemented more efficiently using causal dilated convolutions (not yet covered). Along the way we get a better sense of torch.nn and what it is and how it works under the hood, and what a typical deep learning development process looks like (a lot of reading of documentation, keeping track of multidimensional tensor shapes, moving between jupyter notebooks and repository code, ...).</p> <p>Links:</p> <ul><li><p>makemore on github: <a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbThDX0luOEtJSlE5RC1TN2FJRlhtUk1uUVZtZ3xBQ3Jtc0tudDAtZDZHblpHOWVTQVhhRkdmWDI2RWp2eGE1UG5jcDhjb2NYM0lmeXpPTmtjWmVuT3pWN1dRcHdEQWM4NmhnS1Nub3RsWGt6NjhyeGtiZFNYRFpzQnNjbjUyRE1ZTG1Gck82RDFDdWRjYUpDVWhFNA&amp;q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fmakemore&amp;v=t3YJ5hKiMQ0" target="_blank" rel="noopener noreferrer">https://github.com/karpathy/makemore<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li> <li><p>jupyter notebook I built in this video: <a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbmVzRkhTM2NDS0ZDR2NiTkIwOGRXemt2R1I0UXxBQ3Jtc0ttNVJaUFQ0TVc5RllYanRtRzFnZ0lEakZoZnRmVWQxdWp5U0RZN25MWURCM050NzBEZUpGczJPSzVjWVY1Zk5tWjc1b3N5YlhRZ3hKRnlnakU5Sjg3TEVUd18wMGFRaWVFbHB5Vkh4YnJLYWdmRlQzbw&amp;q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fnn-zero-to-hero%2Fblob%2Fmaster%2Flectures%2Fmakemore%2Fmakemore_part5_cnn1.ipynb&amp;v=t3YJ5hKiMQ0" target="_blank" rel="noopener noreferrer">https://github.com/karpathy/nn-zero-t...<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li> <li><p>collab notebook: <a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbG9JcTlQVlFVX1huRkFzVHBPTjlGUzBHeTdHd3xBQ3Jtc0ttNE91S0FkajJsckZyOWswbTZ0ME5qd1N2MnNlcW9fVUNnQm5ndGhsZGFJUndGREIwS2FqZUtzYndkMHktOHh0TnprWkctVHA2RHJhc2xrUTlkWkVWdTZYbFNhRGVaYjdPeEtuaDlOWDd6cXdOMjFvcw&amp;q=https%3A%2F%2Fcolab.research.google.com%2Fdrive%2F1CXVEmCO_7r7WYZGb5qnjfyxTvQa13g5X%3Fusp%3Dsharing&amp;v=t3YJ5hKiMQ0" target="_blank" rel="noopener noreferrer">https://colab.research.google.com/dri...<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li></ul> <p>Supplementary links:</p> <ul><li><p>WaveNet 2016 from DeepMind <a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbm5VemlRazRSdWNKLXhGdThYUXQxZDBkUktFZ3xBQ3Jtc0ttV2pPTHZqcE9XbDNKbndMT1ZYT2cyU0tzTTd4bGdmZUZneENFOUFEUVVoLU5YbmhyOUJTSjJmRThGLW50Uk1TMmN2VGZPc0ZSc3hNN0xWTlRnb19hd0JEcTBlRjVxRnlxS1NQU1h5T3RSSnVxX3FjMA&amp;q=https%3A%2F%2Farxiv.org%2Fabs%2F1609.03499&amp;v=t3YJ5hKiMQ0" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/1609.03499<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li> <li><p>Bengio et al. 2003 MLP LM <a href="https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqa0VKVmdPaXJGR3l6Ui11OG80NURQRWpkQlNyQXxBQ3Jtc0trVTk0MS1hd0JOVUdiXzB0ZGtvWW1TTm9od2FkdEVyRUNoY0sxY2szcDByRkJsYlpaVTdCTjVJNi14b0RVVVdxcUp2WjFfRVphbDlldmhMekhZSjhhSWtiakpOaVp5UlB0YmpibjhndWZiX2UxbFhmSQ&amp;q=https%3A%2F%2Fwww.jmlr.org%2Fpapers%2Fvolume3%2Fbengio03a%2Fbengio03a.pdf&amp;v=t3YJ5hKiMQ0" target="_blank" rel="noopener noreferrer">https://www.jmlr.org/papers/volume3/b...<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li></ul> <h1 id="_1-step-1-refactor-the-mlp-code-from-makemore-3-using-the-nn-sequential-and-nn-flatten"><a href="#_1-step-1-refactor-the-mlp-code-from-makemore-3-using-the-nn-sequential-and-nn-flatten" class="header-anchor">#</a> 1. Step 1: Refactor the MLP code from Makemore 3 using the nn.Sequential and nn.Flatten</h1> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> random
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

words <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'makemore-master/names.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>splitlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
words <span class="token operator">=</span> words

<span class="token comment"># build the vocabulary of characters and mappings to/from integers</span>
chars <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
stoi <span class="token operator">=</span> <span class="token punctuation">{</span>s<span class="token punctuation">:</span> i <span class="token operator">+</span> <span class="token number">1</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> s <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>chars<span class="token punctuation">)</span><span class="token punctuation">}</span>
stoi<span class="token punctuation">[</span><span class="token string">'.'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
itos <span class="token operator">=</span> <span class="token punctuation">{</span>i<span class="token punctuation">:</span> s <span class="token keyword">for</span> s<span class="token punctuation">,</span> i <span class="token keyword">in</span> stoi<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>itos<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>itos<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>vocab_size<span class="token punctuation">)</span>

<span class="token comment"># build the dataset</span>
block_size <span class="token operator">=</span> <span class="token number">3</span>  <span class="token comment"># context length: how many characters do we take to predict the next one?</span>

<span class="token keyword">def</span> <span class="token function">build_dataset</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span>
    X<span class="token punctuation">,</span> Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">:</span>
        w <span class="token operator">=</span> <span class="token string">'...'</span> <span class="token operator">+</span> w <span class="token operator">+</span> <span class="token string">&quot;.&quot;</span>
        <span class="token keyword">for</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> c3<span class="token punctuation">,</span> c4 <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> w<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> w<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            X<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>stoi<span class="token punctuation">[</span>ele<span class="token punctuation">]</span> <span class="token keyword">for</span> ele <span class="token keyword">in</span> <span class="token punctuation">[</span>c1<span class="token punctuation">,</span>c2<span class="token punctuation">,</span>c3<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            Y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>stoi<span class="token punctuation">[</span>c4<span class="token punctuation">]</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Y<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">return</span> X<span class="token punctuation">,</span> Y

random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>
random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>words<span class="token punctuation">)</span>
n1 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>
n2 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.9</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>

Xtr<span class="token punctuation">,</span> Ytr <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>words<span class="token punctuation">[</span><span class="token punctuation">:</span>n1<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 80%</span>
Xdev<span class="token punctuation">,</span> Ydev <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>words<span class="token punctuation">[</span>n1<span class="token punctuation">:</span>n2<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 10%</span>
Xte<span class="token punctuation">,</span> Yte <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>words<span class="token punctuation">[</span>n2<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 10%s</span>

<span class="token comment"># MLP revisited</span>
embd_dim <span class="token operator">=</span> <span class="token number">10</span>  <span class="token comment"># the dimensionality of the character embedding vectors</span>
n_hidden <span class="token operator">=</span> <span class="token number">200</span>  <span class="token comment"># the number of neurons in the hidden layer of the MLP</span>

<span class="token keyword">def</span> <span class="token function">build_network</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span>embd_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>block_size <span class="token operator">*</span> embd_dim<span class="token punctuation">,</span> out_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> out_features<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    model<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data <span class="token operator">*=</span> <span class="token number">0.1</span> <span class="token comment"># make the last layer less confident</span>
    <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
    <span class="token keyword">return</span> model

build_network<span class="token punctuation">(</span><span class="token punctuation">)</span>

loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
NUM_EPOCHS <span class="token operator">=</span> <span class="token number">2</span>
step_size <span class="token operator">=</span> <span class="token number">0.1</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> build_network<span class="token punctuation">(</span><span class="token punctuation">)</span>
    lossi <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
    dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment">#use drop_last = true to avoid one sample batch</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>NUM_EPOCHS<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> j<span class="token punctuation">,</span> <span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                p<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>
            y_pred <span class="token operator">=</span> model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>train_x<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>
            <span class="token keyword">if</span> j <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">or</span> j <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">:</span><span class="token format-spec">3d</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>NUM_EPOCHS<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">3d</span><span class="token punctuation">}</span></span><span class="token string">, Batch </span><span class="token interpolation"><span class="token punctuation">{</span>j<span class="token punctuation">:</span><span class="token format-spec">4d</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">4d</span><span class="token punctuation">}</span></span><span class="token string">, loss=</span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            lossi<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>log10<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                p<span class="token punctuation">.</span>data <span class="token operator">-=</span> step_size <span class="token operator">*</span> p<span class="token punctuation">.</span>grad
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>lossi<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model

g <span class="token operator">=</span> torch<span class="token punctuation">.</span>Generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> train<span class="token punctuation">(</span>Xtr<span class="token punctuation">,</span> Ytr<span class="token punctuation">)</span>
    word_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            xi <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
            cur_word <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            y <span class="token operator">=</span> <span class="token string">'[INIT]'</span>
            <span class="token keyword">while</span> y <span class="token operator">!=</span> <span class="token string">&quot;.&quot;</span><span class="token punctuation">:</span>
                y_prob <span class="token operator">=</span> xi
                y_prob <span class="token operator">=</span> model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>y_prob<span class="token punctuation">)</span>
                y_prob <span class="token operator">=</span> y_prob<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
                iy <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>y_prob<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>g<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
                y <span class="token operator">=</span> itos<span class="token punctuation">[</span>iy<span class="token punctuation">]</span>
                xi <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>xi<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>iy<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
                cur_word<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
            word_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;&quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>cur_word<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>word_lst<span class="token punctuation">)</span>

generate<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br><span class="line-number">106</span><br><span class="line-number">107</span><br><span class="line-number">108</span><br><span class="line-number">109</span><br><span class="line-number">110</span><br><span class="line-number">111</span><br><span class="line-number">112</span><br><span class="line-number">113</span><br><span class="line-number">114</span><br></div></div><p>output:</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>Epoch   <span class="token number">0</span><span class="token operator">/</span>  <span class="token number">1</span><span class="token punctuation">,</span> Batch    <span class="token number">0</span><span class="token operator">/</span><span class="token number">1825</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">3.2999</span>
Epoch   <span class="token number">0</span><span class="token operator">/</span>  <span class="token number">1</span><span class="token punctuation">,</span> Batch <span class="token number">1000</span><span class="token operator">/</span><span class="token number">1825</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">2.2749</span>
Epoch   <span class="token number">0</span><span class="token operator">/</span>  <span class="token number">1</span><span class="token punctuation">,</span> Batch <span class="token number">1825</span><span class="token operator">/</span><span class="token number">1825</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">2.2904</span>
Epoch   <span class="token number">1</span><span class="token operator">/</span>  <span class="token number">1</span><span class="token punctuation">,</span> Batch    <span class="token number">0</span><span class="token operator">/</span><span class="token number">1825</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">2.3452</span>
Epoch   <span class="token number">1</span><span class="token operator">/</span>  <span class="token number">1</span><span class="token punctuation">,</span> Batch <span class="token number">1000</span><span class="token operator">/</span><span class="token number">1825</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">2.1585</span>
Epoch   <span class="token number">1</span><span class="token operator">/</span>  <span class="token number">1</span><span class="token punctuation">,</span> Batch <span class="token number">1825</span><span class="token operator">/</span><span class="token number">1825</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">2.2466</span>
<span class="token punctuation">[</span><span class="token string">'anuseen.'</span><span class="token punctuation">,</span> <span class="token string">'kis.'</span><span class="token punctuation">,</span> <span class="token string">'marian.'</span><span class="token punctuation">,</span> <span class="token string">'dan.'</span><span class="token punctuation">,</span> <span class="token string">'shan.'</span><span class="token punctuation">,</span> <span class="token string">'silaylen.'</span><span class="token punctuation">,</span> <span class="token string">'kemarie.'</span><span class="token punctuation">,</span> <span class="token string">'kan.'</span><span class="token punctuation">,</span> <span class="token string">'epiacholen.'</span><span class="token punctuation">,</span> <span class="token string">'dazi.'</span><span class="token punctuation">,</span> <span class="token string">'kend.'</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h1 id="step-2-get-the-train-and-validation-loss"><a href="#step-2-get-the-train-and-validation-loss" class="header-anchor">#</a> Step 2: Get the Train and Validation Loss</h1> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">calc_loss</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_logits <span class="token operator">=</span> model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    y_prob <span class="token operator">=</span> y_logits<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>y_prob<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> train<span class="token punctuation">(</span>Xtr<span class="token punctuation">,</span> Ytr<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Train Loss: &quot;</span><span class="token punctuation">,</span> calc_loss<span class="token punctuation">(</span>model<span class="token punctuation">,</span> Xtr<span class="token punctuation">,</span> Ytr<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Validation Loss: &quot;</span><span class="token punctuation">,</span> calc_loss<span class="token punctuation">(</span>model<span class="token punctuation">,</span> Xdev<span class="token punctuation">,</span> Ydev<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>output:</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>Train Loss<span class="token punctuation">:</span>  <span class="token number">3.1517810821533203</span>
Validation Loss<span class="token punctuation">:</span>  <span class="token number">3.152433156967163</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h1 id="step-3-update-network-structure-to-follow-the-wavenet-structure"><a href="#step-3-update-network-structure-to-follow-the-wavenet-structure" class="header-anchor">#</a> Step 3: Update network structure to follow the WaveNet structure:</h1> <p><img src="https://raw.githubusercontent.com/emmableu/image/master/202507042318495.png" alt=""></p> <p>example:</p> <p>input name:</p> <p>“emma”</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>   X                         Y		
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>e                     m
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>em                     m
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>emm                     a
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>emma                     <span class="token punctuation">.</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>layer dimension info:</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>embd_dim <span class="token operator">=</span> <span class="token number">10</span>  <span class="token comment"># the dimensionality of the character embedding vectors</span>
n_hidden <span class="token operator">=</span> <span class="token number">200</span>  <span class="token comment"># the number of neurons in the hidden layer of the MLP</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>Layers:</p> <ul><li>input</li> <li>embedding</li> <li>flatten_consecutive that concat 2 chars/input element
<ul><li>linear, batchnorm, tanh</li></ul></li> <li>flatten_consecutive that concat 2 chars/input element
<ul><li>linear, batchnorm, tanh</li></ul></li> <li>flatten_consecutive that concat 2 chars/input element
<ul><li>linear, batchnorm, tanh</li></ul></li></ul> <p>Adding the shape to the above layer information:</p> <ul><li>input 4 * 8</li> <li>embedding 4 * 8 * 10</li> <li>flatten_consecutive that concat 2 chars/input element 4 * 4 * 20
<ul><li>linear, 4 * 4 * 200</li> <li>batchnorm, tanh 4 * 4 * 200</li></ul></li> <li>flatten_consecutive that concat 2 chars/input element 4 * 2 * 400
<ul><li>linear, 4 * 2 * 200</li> <li>batchnorm, tanh 4 * 2 * 200</li></ul></li> <li>flatten_consecutive that concat 2 chars/input element 4 * 1 * 400 ⇒ 4 * 400
<ul><li>linear,  4 * 27</li> <li>batchnorm 4 * 27</li></ul></li></ul> <h2 id="step-2-1-adjust-input-to-allow-block-size-8"><a href="#step-2-1-adjust-input-to-allow-block-size-8" class="header-anchor">#</a> Step 2.1: Adjust input to allow block_size = 8</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code>block_size <span class="token operator">=</span> <span class="token number">8</span>  <span class="token comment"># context length: how many characters do we take to predict the next one?</span>

<span class="token keyword">def</span> <span class="token function">build_dataset</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span>
    X<span class="token punctuation">,</span> Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">:</span>
        w <span class="token operator">=</span> <span class="token string">'.'</span> <span class="token operator">*</span> <span class="token punctuation">(</span>block_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> w <span class="token operator">+</span> <span class="token string">&quot;.&quot;</span>
        zip_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>block_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
            zip_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>w<span class="token punctuation">[</span>i<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        zip_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>w<span class="token punctuation">[</span>block_size<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> data <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>zip_data<span class="token punctuation">)</span><span class="token punctuation">:</span>
            X<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>stoi<span class="token punctuation">[</span>ele<span class="token punctuation">]</span> <span class="token keyword">for</span> ele <span class="token keyword">in</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            Y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>stoi<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Y<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">return</span> X<span class="token punctuation">,</span> Y

random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>
random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>words<span class="token punctuation">)</span>
n1 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>
n2 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.9</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>

Xtr<span class="token punctuation">,</span> Ytr <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>words<span class="token punctuation">[</span><span class="token punctuation">:</span>n1<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 80%</span>
Xdev<span class="token punctuation">,</span> Ydev <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>words<span class="token punctuation">[</span>n1<span class="token punctuation">:</span>n2<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 10%</span>
Xte<span class="token punctuation">,</span> Yte <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>words<span class="token punctuation">[</span>n2<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 10%s</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><p>output:</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">:</span> <span class="token string">'e'</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">:</span> <span class="token string">'f'</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">:</span> <span class="token string">'g'</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">:</span> <span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">:</span> <span class="token string">'i'</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">:</span> <span class="token string">'j'</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">:</span> <span class="token string">'k'</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">:</span> <span class="token string">'l'</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">:</span> <span class="token string">'m'</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">:</span> <span class="token string">'n'</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">:</span> <span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">:</span> <span class="token string">'p'</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">:</span> <span class="token string">'q'</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">:</span> <span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">:</span> <span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">:</span> <span class="token string">'t'</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">:</span> <span class="token string">'u'</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">:</span> <span class="token string">'v'</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">:</span> <span class="token string">'w'</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">:</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">:</span> <span class="token string">'y'</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">:</span> <span class="token string">'z'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">'.'</span><span class="token punctuation">}</span>
<span class="token number">27</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">156999</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">156999</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">19452</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">19452</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">19662</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">19662</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h2 id="step-2-2-update-network-structure"><a href="#step-2-2-update-network-structure" class="header-anchor">#</a> Step 2.2, Update Network Structure</h2> <h3 id="step-2-2-1-add-flattenconsecutive-layer"><a href="#step-2-2-1-add-flattenconsecutive-layer" class="header-anchor">#</a> Step 2.2.1: Add FlattenConsecutive Layer</h3> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">FlattenConsecutive</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_concat_ele<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Call to super()</span>
        self<span class="token punctuation">.</span>num_concat_ele <span class="token operator">=</span> num_concat_ele
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        for example, if X is [4, 8, 10]  =&gt; [4, 4, 20] if num_concat_ele=2
        &quot;&quot;&quot;</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>view<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">//</span>self<span class="token punctuation">.</span>num_concat_ele<span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>num_concat_ele<span class="token punctuation">)</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># if [4, 1, 10] then change to [4, 10]</span>
        <span class="token keyword">return</span> X

<span class="token keyword">def</span> <span class="token function">build_network</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span>embd_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>
        FlattenConsecutive<span class="token punctuation">(</span>num_concat_ele<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2</span> <span class="token operator">*</span> embd_dim<span class="token punctuation">,</span> out_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

        FlattenConsecutive<span class="token punctuation">(</span>num_concat_ele<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>n_hidden <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

        FlattenConsecutive<span class="token punctuation">(</span>num_concat_ele<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>n_hidden <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    model<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data <span class="token operator">*=</span> <span class="token number">0.1</span> <span class="token comment"># make the last layer less confident</span>
    <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
    <span class="token keyword">return</span> model
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br></div></div><h3 id="step-2-2-2-adjust-the-batchnorm-dimension"><a href="#step-2-2-2-adjust-the-batchnorm-dimension" class="header-anchor">#</a> Step 2.2.2: Adjust the BatchNorm Dimension</h3> <p>From batchNorm Documentation</p> <p>Shape:</p> <ul><li>Input: (N, C) or (N, C, L), where N is the batch size, C is the number of features or channels, and L is the sequence length</li> <li>Output: (N, C) or (N, C, L) (same shape as input)</li></ul> <blockquote><p>The mean and standard-deviation are calculated per-dimension over the mini-batches and γ and β are learnable parameter vectors of size C (where C is the number of features or channels of the input). By default, the elements of γ are set to 1 and the elements of β are set to 0.</p></blockquote> <p>However, when we put our input to the batchnorm dimention e.g., <code>4 * 2 * 200</code></p> <ul><li>what we want for the bn_mean (indicated by gamma above) and bn_variance (indicated by beta above) are both of size [1 * 200]</li> <li>i.e., we want the 200 to be C.</li> <li>so, we need a way for the second dimension to be 200.</li></ul> <p>Now we update the networks structure to include this additional dimension adjustment.</p> <p>Below we check how do we make second dimension 200 to be C:</p> <p>Our goal is for the calculation of batchnorm to be the same.</p> <div class="language-markdown line-numbers-mode"><pre class="language-markdown"><code>if X is of shape 2 <span class="token italic"><span class="token punctuation">*</span><span class="token content"> 2 </span><span class="token punctuation">*</span></span> 3

[[[1,2,3],
	[4,5,6]]
  [[7,8,9],
 	[10,11,12]]]
 	
what we want as bn_mean is [(1+4+7+10)/4, (2+5+8+11)/4, (3+6+9+12)/4] = [5.5, 6.5, 7.5]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>To achieve that, the most easy update is to make 4 * 2 * 200 to be 8 * 200.</p> <p>but what if we use X.view(X.shape[0], X.shape[2], X.shape[1]):</p> <div class="language-markdown line-numbers-mode"><pre class="language-markdown"><code>[[[1,2,3],
	[4,5,6]],
	
  [[7,8,9],
 	[10,11,12]]]
 	
 	
becomes

[[[1,2],
	[3,4],
	[5,6]],
	
  [7,8],
	[9,10],
	[11,12]]]
	
	
when calculating mean over these dimensions we first get
[[(1+2)/2,
	(3+4)/2,
	(5+6)/2],
	
  [(7+8)/2,
	(9,10)/2,
	(11+12)/2]]
	
then we reduce these data

we can see that the mean is not the same as the above. 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><p>So, we CANNOT use X.view(X.shape[0], X.shape[2], X.shape[1]).</p> <p>So, we have to flatten and un_flatten the dimensions before and after batchNorm.</p> <p>Below are how to use Flatten and Unflatten:</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&quot;&quot;&quot;
Flatten from the 0th dimension onward, stop at 1th dimension
i.e., the first part is [0, 1], both side included,
the second part is starting from dimension 2 to the end.

if I do nn.Flatten(1,2), it will flatten 2 * 200, that way it is put to the second part of the result.
Result will be 4 * 400
&quot;&quot;&quot;</span>
flatten <span class="token operator">=</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> flatten<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&quot;&quot;&quot;
unflatten syntax:
nn.Unflatten(dim, unflattened_size)
dim: The dimension that you want to &quot;unflatten.&quot;
unflattened_size: The target shape (as a tuple) of the dimension you're unflattening.
&quot;&quot;&quot;</span>
unflatten <span class="token operator">=</span> nn<span class="token punctuation">.</span>Unflatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> unflatten<span class="token punctuation">(</span>output<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span>output <span class="token operator">==</span> x<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><p>output:</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>So, below is how we should build the model</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>
<span class="token keyword">class</span> <span class="token class-name">FlattenConsecutive</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_concat_ele<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Call to super()</span>
        self<span class="token punctuation">.</span>num_concat_ele <span class="token operator">=</span> num_concat_ele

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        for example, if X is [4, 8, 10]  =&gt; [4, 4, 20] if num_concat_ele=2
        &quot;&quot;&quot;</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>view<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>num_concat_ele<span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>num_concat_ele<span class="token punctuation">)</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># if [4, 1, 10] then change to [4, 10]</span>
        <span class="token keyword">return</span> X

<span class="token keyword">class</span> <span class="token class-name">Unflatten</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_folded_ele<span class="token punctuation">,</span> num_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_folded_ele <span class="token operator">=</span> num_folded_ele
        self<span class="token punctuation">.</span>num_features <span class="token operator">=</span> num_features

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># [16, 200] needs to be revert back to [4, 4, 200]</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_folded_ele<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_features<span class="token punctuation">)</span>
        <span class="token keyword">return</span> X

<span class="token keyword">def</span> <span class="token function">build_network</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span>embd_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>
        FlattenConsecutive<span class="token punctuation">(</span>num_concat_ele<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2</span> <span class="token operator">*</span> embd_dim<span class="token punctuation">,</span> out_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Unflatten<span class="token punctuation">(</span>num_folded_ele<span class="token operator">=</span>block_size<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

        FlattenConsecutive<span class="token punctuation">(</span>num_concat_ele<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>n_hidden <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Unflatten<span class="token punctuation">(</span>num_folded_ele<span class="token operator">=</span>block_size<span class="token operator">//</span><span class="token number">4</span><span class="token punctuation">,</span> num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>

        FlattenConsecutive<span class="token punctuation">(</span>num_concat_ele<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>n_hidden <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">:</span>
        layer<span class="token punctuation">.</span>register_forward_hook<span class="token punctuation">(</span>print_layer_shape<span class="token punctuation">)</span>
    model<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data <span class="token operator">*=</span> <span class="token number">0.1</span>  <span class="token comment"># make the last layer less confident</span>
    <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
    <span class="token keyword">return</span> model

build_network<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br></div></div><h2 id="_2-3-add-forward-hook-to-print-layer-shape"><a href="#_2-3-add-forward-hook-to-print-layer-shape" class="header-anchor">#</a> 2.3 Add Forward Hook to Print Layer Shape</h2> <p>We now add a forward hook to print layer shape, this is very useful for debug</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">print_layer_shape</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;</span><span class="token interpolation"><span class="token punctuation">{</span>layer<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__<span class="token punctuation">:</span><span class="token format-spec">20</span><span class="token punctuation">}</span></span><span class="token string">: in: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">30</span><span class="token punctuation">}</span></span><span class="token string">; out: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">str</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">30</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>In the training function, add the line:</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>    <span class="token keyword">for</span> layer <span class="token keyword">in</span> model<span class="token punctuation">:</span>
        layer<span class="token punctuation">.</span>register_forward_hook<span class="token punctuation">(</span>print_layer_shape<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>If we add a break after the first training iteration, it will give</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>Embedding           <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>          <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      
FlattenConsecutive  <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      
Linear              <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     
Flatten             <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        
BatchNorm1d         <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        
Unflatten           <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     
Tanh                <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     
FlattenConsecutive  <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     
Linear              <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     
Flatten             <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        
BatchNorm1d         <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        
Unflatten           <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     
FlattenConsecutive  <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        
Linear              <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">)</span>         
BatchNorm1d         <span class="token punctuation">:</span> <span class="token keyword">in</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">)</span>         <span class="token punctuation">;</span> out<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><h1 id="_3-final-code-and-output"><a href="#_3-final-code-and-output" class="header-anchor">#</a> 3. Final Code and Output</h1> <p>Below is the final code and final output, note that we removed the print message as that’s for debugging purpose</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> random
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

words <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'makemore-master/names.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>splitlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
words <span class="token operator">=</span> words

<span class="token comment"># build the vocabulary of characters and mappings to/from integers</span>
chars <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
stoi <span class="token operator">=</span> <span class="token punctuation">{</span>s<span class="token punctuation">:</span> i <span class="token operator">+</span> <span class="token number">1</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> s <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>chars<span class="token punctuation">)</span><span class="token punctuation">}</span>
stoi<span class="token punctuation">[</span><span class="token string">'.'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
itos <span class="token operator">=</span> <span class="token punctuation">{</span>i<span class="token punctuation">:</span> s <span class="token keyword">for</span> s<span class="token punctuation">,</span> i <span class="token keyword">in</span> stoi<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>itos<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>itos<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>vocab_size<span class="token punctuation">)</span>

<span class="token comment"># build the dataset</span>
block_size <span class="token operator">=</span> <span class="token number">8</span>  <span class="token comment"># context length: how many characters do we take to predict the next one?</span>

<span class="token keyword">def</span> <span class="token function">build_dataset</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span>
    X<span class="token punctuation">,</span> Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">:</span>
        w <span class="token operator">=</span> <span class="token string">'.'</span> <span class="token operator">*</span> <span class="token punctuation">(</span>block_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> w <span class="token operator">+</span> <span class="token string">&quot;.&quot;</span>
        zip_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>block_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
            zip_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>w<span class="token punctuation">[</span>i<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        zip_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>w<span class="token punctuation">[</span>block_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> data <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>zip_data<span class="token punctuation">)</span><span class="token punctuation">:</span>
            X<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>stoi<span class="token punctuation">[</span>ele<span class="token punctuation">]</span> <span class="token keyword">for</span> ele <span class="token keyword">in</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            Y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>stoi<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Y<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">return</span> X<span class="token punctuation">,</span> Y

random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>
random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>words<span class="token punctuation">)</span>
n1 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>
n2 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.9</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>

Xtr<span class="token punctuation">,</span> Ytr <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>words<span class="token punctuation">[</span><span class="token punctuation">:</span>n1<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 80%</span>
Xdev<span class="token punctuation">,</span> Ydev <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>words<span class="token punctuation">[</span>n1<span class="token punctuation">:</span>n2<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 10%</span>
Xte<span class="token punctuation">,</span> Yte <span class="token operator">=</span> build_dataset<span class="token punctuation">(</span>words<span class="token punctuation">[</span>n2<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 10%s</span>

<span class="token comment"># MLP revisited</span>
embd_dim <span class="token operator">=</span> <span class="token number">10</span>  <span class="token comment"># the dimensionality of the character embedding vectors</span>
n_hidden <span class="token operator">=</span> <span class="token number">200</span>  <span class="token comment"># the number of neurons in the hidden layer of the MLP</span>

<span class="token keyword">class</span> <span class="token class-name">FlattenConsecutive</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_concat_ele<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># Call to super()</span>
        self<span class="token punctuation">.</span>num_concat_ele <span class="token operator">=</span> num_concat_ele

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        for example, if X is [4, 8, 10]  =&gt; [4, 4, 20] if num_concat_ele=2
        &quot;&quot;&quot;</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>view<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>num_concat_ele<span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>num_concat_ele<span class="token punctuation">)</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># if [4, 1, 10] then change to [4, 10]</span>
        <span class="token keyword">return</span> X

<span class="token keyword">class</span> <span class="token class-name">Unflatten</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_folded_ele<span class="token punctuation">,</span> num_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_folded_ele <span class="token operator">=</span> num_folded_ele
        self<span class="token punctuation">.</span>num_features <span class="token operator">=</span> num_features

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># [16, 200] needs to be revert back to [4, 4, 200]</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_folded_ele<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_features<span class="token punctuation">)</span>
        <span class="token keyword">return</span> X

<span class="token keyword">def</span> <span class="token function">print_layer_shape</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;</span><span class="token interpolation"><span class="token punctuation">{</span>layer<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__<span class="token punctuation">:</span><span class="token format-spec">20</span><span class="token punctuation">}</span></span><span class="token string">: in: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">30</span><span class="token punctuation">}</span></span><span class="token string">; out: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">str</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">30</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">build_network</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
        nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span>embd_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>
        FlattenConsecutive<span class="token punctuation">(</span>num_concat_ele<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">2</span> <span class="token operator">*</span> embd_dim<span class="token punctuation">,</span> out_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Unflatten<span class="token punctuation">(</span>num_folded_ele<span class="token operator">=</span>block_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span> num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

        FlattenConsecutive<span class="token punctuation">(</span>num_concat_ele<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>n_hidden <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Unflatten<span class="token punctuation">(</span>num_folded_ele<span class="token operator">=</span>block_size <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">,</span> num_features<span class="token operator">=</span>n_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>

        FlattenConsecutive<span class="token punctuation">(</span>num_concat_ele<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>n_hidden <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>num_features<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token comment"># for layer in model:</span>
    <span class="token comment">#     layer.register_forward_hook(print_layer_shape)</span>
    model<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data <span class="token operator">*=</span> <span class="token number">0.1</span>  <span class="token comment"># make the last layer less confident</span>
    <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>
    <span class="token keyword">return</span> model

build_network<span class="token punctuation">(</span><span class="token punctuation">)</span>

loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
NUM_EPOCHS <span class="token operator">=</span> <span class="token number">2</span>
step_size <span class="token operator">=</span> <span class="token number">0.1</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> build_network<span class="token punctuation">(</span><span class="token punctuation">)</span>
    lossi <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
    dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
                                             drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># use drop_last = true to avoid one sample batch</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>NUM_EPOCHS<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> j<span class="token punctuation">,</span> <span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                p<span class="token punctuation">.</span>grad <span class="token operator">=</span> <span class="token boolean">None</span>
            y_pred <span class="token operator">=</span> model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>train_x<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>
            <span class="token keyword">if</span> j <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">or</span> j <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>
                    <span class="token string-interpolation"><span class="token string">f&quot;Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">:</span><span class="token format-spec">3d</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>NUM_EPOCHS <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">3d</span><span class="token punctuation">}</span></span><span class="token string">, Batch </span><span class="token interpolation"><span class="token punctuation">{</span>j<span class="token punctuation">:</span><span class="token format-spec">4d</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">4d</span><span class="token punctuation">}</span></span><span class="token string">, loss=</span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            lossi<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>log10<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                p<span class="token punctuation">.</span>data <span class="token operator">-=</span> step_size <span class="token operator">*</span> p<span class="token punctuation">.</span>grad
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>lossi<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model

g <span class="token operator">=</span> torch<span class="token punctuation">.</span>Generator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> train<span class="token punctuation">(</span>Xtr<span class="token punctuation">,</span> Ytr<span class="token punctuation">)</span>
    word_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            xi <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
            cur_word <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            y <span class="token operator">=</span> <span class="token string">'[INIT]'</span>
            <span class="token keyword">while</span> y <span class="token operator">!=</span> <span class="token string">&quot;.&quot;</span><span class="token punctuation">:</span>
                y_prob <span class="token operator">=</span> xi
                y_prob <span class="token operator">=</span> model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>y_prob<span class="token punctuation">)</span>
                y_prob <span class="token operator">=</span> y_prob<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
                iy <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>y_prob<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> generator<span class="token operator">=</span>g<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
                y <span class="token operator">=</span> itos<span class="token punctuation">[</span>iy<span class="token punctuation">]</span>
                xi <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>xi<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>iy<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
                cur_word<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
            word_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;&quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>cur_word<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>word_lst<span class="token punctuation">)</span>

<span class="token comment"># generate()</span>
<span class="token keyword">def</span> <span class="token function">calc_loss</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_logits <span class="token operator">=</span> model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    y_prob <span class="token operator">=</span> y_logits<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>y_prob<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> train<span class="token punctuation">(</span>Xtr<span class="token punctuation">,</span> Ytr<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Train Loss: &quot;</span><span class="token punctuation">,</span> calc_loss<span class="token punctuation">(</span>model<span class="token punctuation">,</span> Xtr<span class="token punctuation">,</span> Ytr<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Validation Loss: &quot;</span><span class="token punctuation">,</span> calc_loss<span class="token punctuation">(</span>model<span class="token punctuation">,</span> Xdev<span class="token punctuation">,</span> Ydev<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br><span class="line-number">106</span><br><span class="line-number">107</span><br><span class="line-number">108</span><br><span class="line-number">109</span><br><span class="line-number">110</span><br><span class="line-number">111</span><br><span class="line-number">112</span><br><span class="line-number">113</span><br><span class="line-number">114</span><br><span class="line-number">115</span><br><span class="line-number">116</span><br><span class="line-number">117</span><br><span class="line-number">118</span><br><span class="line-number">119</span><br><span class="line-number">120</span><br><span class="line-number">121</span><br><span class="line-number">122</span><br><span class="line-number">123</span><br><span class="line-number">124</span><br><span class="line-number">125</span><br><span class="line-number">126</span><br><span class="line-number">127</span><br><span class="line-number">128</span><br><span class="line-number">129</span><br><span class="line-number">130</span><br><span class="line-number">131</span><br><span class="line-number">132</span><br><span class="line-number">133</span><br><span class="line-number">134</span><br><span class="line-number">135</span><br><span class="line-number">136</span><br><span class="line-number">137</span><br><span class="line-number">138</span><br><span class="line-number">139</span><br><span class="line-number">140</span><br><span class="line-number">141</span><br><span class="line-number">142</span><br><span class="line-number">143</span><br><span class="line-number">144</span><br><span class="line-number">145</span><br><span class="line-number">146</span><br><span class="line-number">147</span><br><span class="line-number">148</span><br><span class="line-number">149</span><br><span class="line-number">150</span><br><span class="line-number">151</span><br><span class="line-number">152</span><br><span class="line-number">153</span><br><span class="line-number">154</span><br><span class="line-number">155</span><br><span class="line-number">156</span><br><span class="line-number">157</span><br><span class="line-number">158</span><br><span class="line-number">159</span><br><span class="line-number">160</span><br><span class="line-number">161</span><br><span class="line-number">162</span><br><span class="line-number">163</span><br><span class="line-number">164</span><br><span class="line-number">165</span><br><span class="line-number">166</span><br></div></div><p>Output:</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">:</span> <span class="token string">'e'</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">:</span> <span class="token string">'f'</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">:</span> <span class="token string">'g'</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">:</span> <span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">:</span> <span class="token string">'i'</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">:</span> <span class="token string">'j'</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">:</span> <span class="token string">'k'</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">:</span> <span class="token string">'l'</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">:</span> <span class="token string">'m'</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">:</span> <span class="token string">'n'</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">:</span> <span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">:</span> <span class="token string">'p'</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">:</span> <span class="token string">'q'</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">:</span> <span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">:</span> <span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">:</span> <span class="token string">'t'</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">:</span> <span class="token string">'u'</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">:</span> <span class="token string">'v'</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">:</span> <span class="token string">'w'</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">:</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">:</span> <span class="token string">'y'</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">:</span> <span class="token string">'z'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">'.'</span><span class="token punctuation">}</span>
<span class="token number">27</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">25626</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">25626</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3203</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3203</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3204</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3204</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Epoch   <span class="token number">0</span><span class="token operator">/</span>  <span class="token number">1</span><span class="token punctuation">,</span> Batch    <span class="token number">0</span><span class="token operator">/</span> <span class="token number">255</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">3.3114</span>
Epoch   <span class="token number">0</span><span class="token operator">/</span>  <span class="token number">1</span><span class="token punctuation">,</span> Batch  <span class="token number">255</span><span class="token operator">/</span> <span class="token number">255</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">2.0715</span>
Epoch   <span class="token number">1</span><span class="token operator">/</span>  <span class="token number">1</span><span class="token punctuation">,</span> Batch    <span class="token number">0</span><span class="token operator">/</span> <span class="token number">255</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">2.2137</span>
Epoch   <span class="token number">1</span><span class="token operator">/</span>  <span class="token number">1</span><span class="token punctuation">,</span> Batch  <span class="token number">255</span><span class="token operator">/</span> <span class="token number">255</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token number">1.9704</span>
Train Loss<span class="token punctuation">:</span>  <span class="token number">3.1263720989227295</span>
Validation Loss<span class="token punctuation">:</span>  <span class="token number">3.1217050552368164</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>Notice that we reduced train and validation loss even without any hyperparameter tuning.</p></div></div>  <div class="page-edit"><!----> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2025/07/04, 23:19:22</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/blog/pages/049b6e/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Makemore 4 - Backpropagation Ninja</div></a> <a href="/blog/pages/9a3c9d/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">ML资源</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/blog/pages/049b6e/" class="prev">Makemore 4 - Backpropagation Ninja</a></span> <span class="next"><a href="/blog/pages/9a3c9d/">ML资源</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/blog/archives" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/blog/pages/049b6e/"><div>
            Makemore 4 - Backpropagation Ninja
            <!----></div></a> <span class="date">07-04</span></dt></dl><dl><dd>02</dd> <dt><a href="/blog/pages/c0d04f/"><div>
            Makemore 3 - Activations &amp; Gradients, BatchNorm
            <!----></div></a> <span class="date">07-04</span></dt></dl><dl><dd>03</dd> <dt><a href="/blog/pages/fd8228/"><div>
            Makemore 2 - MLP
            <!----></div></a> <span class="date">07-03</span></dt></dl> <dl><dd></dd> <dt><a href="/blog/archives" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><!----> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2025
    <span>emmableu | <a href="https://github.com/emmableu/vuepress-theme-vdoing/blob/master/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/blog/assets/js/app.fa6bfa40.js" defer></script><script src="/blog/assets/js/2.7ce49225.js" defer></script><script src="/blog/assets/js/425.40010459.js" defer></script>
  </body>
</html>
