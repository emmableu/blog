(window.webpackJsonp=window.webpackJsonp||[]).push([[525],{897:function(e,t,a){"use strict";a.r(t);var s=a(9),r=Object(s.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[t("a",{attrs:{href:"https://docs.google.com/presentation/d/1s9J6vutpIuC0NtOzyJ6G-pnDzR612Dw9WdbVWEmFeAU/edit#slide=id.p9",target:"_blank",rel:"noopener noreferrer"}},[e._v("LAK 21 Presentation"),t("OutboundLink")],1)]),e._v(" "),t("h2",{attrs:{id:"motivation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#motivation"}},[e._v("#")]),e._v(" motivation:")]),e._v(" "),t("p",[e._v("in my area of research, learning analytics, there's also a big research space for applying ML -"),t("br"),e._v("\nlearning analytics means")]),e._v(" "),t("p",[e._v("understanding students, -"),t("br"),e._v("\nincluding understanding students' thoughts, ideas, and misconceptions, which sometimes resembles a lot with NLP tasks - deriving meanings from texts, in our case, codes")]),e._v(" "),t("p",[e._v("So the project I've worked on, I got the idea from the code2vec paper published in 2019, it is about learning code embeddings and use them to predict function names")]),e._v(" "),t("p",[e._v("I saw this paper in an sde/code representation/ml conference and I wanted to apply it in my work - in novice programming tasks.  Because:")]),e._v(" "),t("ul",[t("li",[e._v("it is at that time the state-of-the-art work in predicting method names based on functions.")]),e._v(" "),t("li",[e._v("It uses simple but interesting feature extraction - AST tree, leaf-to-leaf paths")]),e._v(" "),t("li",[e._v("It uses attention mechanism to find the part of the code that's most predictive of its function name. For example, in a sorting algorithm,...")]),e._v(" "),t("li",[e._v("It creates code-embeddings in the layer before the attention layer. While the paper did not dig deep into that I believe just like word embeddings, those code embeddings could be rather useful - like the misconception clustering task that I have mentioned.")])]),e._v(" "),t("p",[e._v("But different from code2vec,")]),e._v(" "),t("ul",[t("li",[e._v("we had much less data, code2vec has about 2 million pieces of code as training dataset, we have 207 from 4 semesters.")]),e._v(" "),t("li",[e._v("we don't predict method names - students write script-like functions that we only has labeled as right or wrong.")]),e._v(" "),t("li",[e._v("we want to do automatic misconception detection:\n"),t("ul",[t("li",[t("p",[e._v("misconception is an incorrect understanding of a concept or a set of concepts, which lead to making mistakes in writing or reading programs")])]),e._v(" "),t("li",[t("p",[e._v("example of an misconception:")])]),e._v(" "),t("li",[t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202210061705864.png",alt:""}})])]),e._v(" "),t("li",[t("ul",[t("li",[e._v("cannot detect by program execution - these are logic errors.")])])]),e._v(" "),t("li",[t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202210061705987.png",alt:""}})])])])])]),e._v(" "),t("p",[e._v("other misconceptions include:")]),e._v(" "),t("ul",[t("li",[t("ul",[t("li",[e._v("variable misuse - supposed to use x, but uses y")])])]),e._v(" "),t("li",[e._v("index off by 1 error, so when you iterative through indexes, it is easy to loop one index out of the loop, or return one index before or after the target index, for example, in a binary search problem")]),e._v(" "),t("li",[e._v("don't know how to write a loop - so unroll a loop by repeating code inside of the loop")])]),e._v(" "),t("h2",{attrs:{id:"two-fold-goal-of-the-work"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#two-fold-goal-of-the-work"}},[e._v("#")]),e._v(" two-fold goal of the work:")]),e._v(" "),t("ul",[t("li",[e._v("automatic assessment & misconception discovery:")]),e._v(" "),t("li",[e._v("the first work in the computing education area that does automatic misconception discovery.")])]),e._v(" "),t("h2",{attrs:{id:"method"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#method"}},[e._v("#")]),e._v(" method")]),e._v(" "),t("h3",{attrs:{id:"ast-code-representation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ast-code-representation"}},[e._v("#")]),e._v(" AST code representation:")]),e._v(" "),t("p",[e._v("input: 207 student programs, AST leaf-to-leaf paths")]),e._v(" "),t("p",[e._v("what is an AST Tree:\n"),t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202210070128775.png",alt:""}})]),e._v(" "),t("h3",{attrs:{id:"model-code2vec"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#model-code2vec"}},[e._v("#")]),e._v(" model: code2vec")]),e._v(" "),t("p",[e._v("output: right/wrong")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202209262256120.png",alt:""}})]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202209270023838.png",alt:""}})]),e._v(" "),t("h3",{attrs:{id:"dataset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataset"}},[e._v("#")]),e._v(" dataset:")]),e._v(" "),t("p",[e._v("CS0 course at NCSU from Spring 2016 to Fall 2017, in Snap (block based program). Totaling 207 submissions.")]),e._v(" "),t("h2",{attrs:{id:"results"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#results"}},[e._v("#")]),e._v(" Results")]),e._v(" "),t("h3",{attrs:{id:"rq1-automatic-assessment"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rq1-automatic-assessment"}},[e._v("#")]),e._v(" RQ1: Automatic Assessment")]),e._v(" "),t("p",[e._v("Research Question: How accurately can we use code2vec to assess students’ performance on a programming exercise?")]),e._v(" "),t("ul",[t("li",[e._v("Compared Naive majority, Support vector machine (SVM), 1-layer neural network (NN) for code assessment.")]),e._v(" "),t("li",[e._v("8:2 training and testing.")]),e._v(" "),t("li",[e._v("Resampled 50 times and reported average performance.")]),e._v(" "),t("li",[e._v("Hyperparameters on NN models (NN and code2vec):\n"),t("ul",[t("li",[e._v("Early stopping.")]),e._v(" "),t("li",[e._v("Grid search for better parameters (which didn’t produce much difference on performance).")])])])]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202210061835198.png",alt:""}})]),e._v(" "),t("h3",{attrs:{id:"rq2-misconception-discovery"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rq2-misconception-discovery"}},[e._v("#")]),e._v(" RQ2: Misconception Discovery")]),e._v(" "),t("p",[e._v("Research Question: How well does the code embedding from such a model capture meaningful similarities among students submissions, and do these reflect shared misconceptions?")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202210062357353.png",alt:""}})]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202210070109285.png",alt:""}})]),e._v(" "),t("h2",{attrs:{id:"are-the-clusters-similar-in-tree-edit-distance-no"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#are-the-clusters-similar-in-tree-edit-distance-no"}},[e._v("#")]),e._v(" Are the Clusters Similar in Tree Edit Distance? No")]),e._v(" "),t("p",[e._v("(meaning that their AST tree do not differ as much)\n"),t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202210070111291.png",alt:""}})]),e._v(" "),t("h2",{attrs:{id:"limitations"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#limitations"}},[e._v("#")]),e._v(" Limitations:")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202210070113855.png",alt:""}})])])}),[],!1,null,null,null);t.default=r.exports}}]);