(window.webpackJsonp=window.webpackJsonp||[]).push([[428],{798:function(a,e,t){"use strict";t.r(e);var i=t(9),r=Object(i.a)({},(function(){var a=this,e=a._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h2",{attrs:{id:"definition-of-generalization-error-bias-v-s-variance"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#definition-of-generalization-error-bias-v-s-variance"}},[a._v("#")]),a._v(" Definition of Generalization Error, Bias v.s. Variance")]),a._v(" "),e("h4",{attrs:{id:"bias"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#bias"}},[a._v("#")]),a._v(" bias")]),a._v(" "),e("ul",[e("li",[a._v("bias仅针对training set，描述的是根据training set拟合出的模型的输出预测结果的期望与training set本身的差距，简单讲，就是在样本上拟合的好不好。要想在bias上表现好，low bias，就得复杂化模型，增加模型的参数，但这样容易过拟合 (overfitting)，过拟合对应上图是high variance，点很分散。low bias对应就是点都打在靶心附近，所以瞄的是准的，但手不一定稳。")])]),a._v(" "),e("h4",{attrs:{id:"variance"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#variance"}},[a._v("#")]),a._v(" Variance")]),a._v(" "),e("ul",[e("li",[e("p",[a._v("variance描述的是training set上训练出来的模型在test set上的表现，要想在variance上表现好，low variance，就要简化模型，减少模型的参数，但这样容易欠拟合(under-fitting)，欠拟合对应上图是high bias，点偏离中心。low variance对应就是点都打的很集中，但不一定是靶心附近，手很稳，但是瞄的不准。")])]),a._v(" "),e("li",[e("p",[e("strong",[a._v("Low Variance")]),a._v(": Suggests small changes to the estimate of the target function with changes to the training dataset.")])]),a._v(" "),e("li",[e("p",[e("strong",[a._v("High Variance")]),a._v(": Suggests large changes to the estimate of the target function with changes to the training dataset.")])])]),a._v(" "),e("p",[a._v("Examples of "),e("strong",[a._v("low-variance")]),a._v(" machine learning algorithms include: "),e("em",[a._v("Linear Regression, Linear Discriminant Analysis and Logistic Regression")]),a._v(".")]),a._v(" "),e("p",[a._v("Examples of "),e("strong",[a._v("high-variance")]),a._v(" machine learning algorithms include: "),e("em",[a._v("Decision Trees, k-Nearest Neighbors and Support Vector Machines")]),a._v(".")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202209212220447.png",alt:""}})]),a._v(" "),e("p",[e("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202209122002625.png",alt:""}})]),a._v(" "),e("p",[a._v("generalization error: 模型在新样本集（测试集）上的误差称为“泛化误差”（generalization error）。")]),a._v(" "),e("p",[a._v("generalization error = bias^2 + variance + noise.")]),a._v(" "),e("p",[e("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/ensemble-learning-4.png",alt:""}})]),a._v(" "),e("h3",{attrs:{id:"bias-variance-decomposition-of-mean-squared-error"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#bias-variance-decomposition-of-mean-squared-error"}},[a._v("#")]),a._v(" Bias–variance decomposition of mean squared error")]),a._v(" "),e("p",[e("a",{attrs:{href:"https://towardsdatascience.com/mse-and-bias-variance-decomposition-77449dd2ff55",target:"_blank",rel:"noopener noreferrer"}},[a._v("resource"),e("OutboundLink")],1)]),a._v(" "),e("p",[e("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/ensemble-learning-6.png",alt:""}}),a._v("\nx")])])}),[],!1,null,null,null);e.default=r.exports}}]);