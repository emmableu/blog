(window.webpackJsonp=window.webpackJsonp||[]).push([[468],{840:function(s,t,n){"use strict";n.r(t);var a=n(9),e=Object(a.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h3",{attrs:{id:"resnet的提出背景和核心理论是什么-230-★★★☆☆"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#resnet的提出背景和核心理论是什么-230-★★★☆☆"}},[s._v("#")]),s._v(" ResNet的提出背景和核心理论是什么？ 230 ★★★☆☆")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202209220050403.png",alt:""}})]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202209220052733.png",alt:""}})]),s._v(" "),t("p",[s._v("让我们先思考一个问题：对神经网络模型添加新的层，充分训练后的模型是否只可能更有效地降低训练误差？理论上，原模型解的空间只是新模型解的空间的子空间。也就是说，如果我们能将新添加的层训练成恒等映射$f(x) = x$，新模型和原模型将同样有效。由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差。然而在实践中，添加过多的层后训练误差往往不降反升。即使利用批量归一化带来的数值稳定性使训练深层模型更加容易，该问题仍然存在。针对这一问题，何恺明等人提出了残差网络（ResNet） [1]。它在2015年的ImageNet图像识别挑战赛夺魁，并深刻影响了后来的深度神经网络的设计。")]),s._v(" "),t("h2",{attrs:{id:"残差块"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#残差块"}},[s._v("#")]),s._v(" 残差块")]),s._v(" "),t("p",[s._v("让我们聚焦于神经网络局部。如图5.9所示，设输入为$\\boldsymbol{x}$。假设我们希望学出的理想映射为$f(\\boldsymbol{x})$，从而作为图5.9上方激活函数的输入。左图虚线框中的部分需要直接拟合出该映射$f(\\boldsymbol{x})$，而右图虚线框中的部分则需要拟合出有关恒等映射的残差映射$f(\\boldsymbol{x})-\\boldsymbol{x}$。残差映射在实际中往往更容易优化。以本节开头提到的恒等映射作为我们希望学出的理想映射$f(\\boldsymbol{x})$。我们只需将图5.9中右图虚线框内上方的加权运算（如仿射）的权重和偏差参数学成0，那么$f(\\boldsymbol{x})$即为恒等映射。实际中，当理想映射$f(\\boldsymbol{x})$极接近于恒等映射时，残差映射也易于捕捉恒等映射的细微波动。图5.9右图也是ResNet的基础块，即残差块（residual block）。在残差块中，输入可通过跨层的数据线路更快地向前传播。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202209252325078.png",alt:""}})]),s._v(" "),t("p",[s._v("ResNet沿用了VGG全$3\\times 3$卷积层的设计。残差块里首先有2个有相同输出通道数的$3\\times 3$卷积层。每个卷积层后接一个批量归一化层和ReLU激活函数。然后我们将输入跳过这2个卷积运算后直接加在最后的ReLU激活函数前。这样的设计要求2个卷积层的输出与输入形状一样，从而可以相加。如果想改变通道数，就需要引入一个额外的$1\\times 1$卷积层来将输入变换成需要的形状后再做相加运算。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202209252330122.png",alt:""}})]),s._v(" "),t("p",[s._v("残差块的实现如下。它可以设定输出通道数、是否使用额外的$1\\times 1$卷积层来修改通道数以及卷积层的步幅。")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" torch "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" nn\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("nn "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" functional "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" F\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" d2l "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" d2l\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Residual")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Module"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("  \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_channels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_channels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" use_1x1conv"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                 strides"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("super")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__init__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("input_channels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_channels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" kernel_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                               padding"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" stride"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("strides"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_channels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_channels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" kernel_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                               padding"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" use_1x1conv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("input_channels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_channels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                                   kernel_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" stride"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("strides"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bn1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("BatchNorm2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_channels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bn2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("BatchNorm2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num_channels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ReLU"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inplace"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("forward")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" X"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        Y "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" F"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bn1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        Y "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("bn2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Y"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            X "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("X"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        Y "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" X\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" F"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Y"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br")])])])}),[],!1,null,null,null);t.default=e.exports}}]);