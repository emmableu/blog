(window.webpackJsonp=window.webpackJsonp||[]).push([[472],{844:function(t,s,a){"use strict";a.r(s);var n=a(9),r=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"✅-交叉熵损失-cross-entropy-loss-详解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#✅-交叉熵损失-cross-entropy-loss-详解"}},[t._v("#")]),t._v(" ✅ 交叉熵损失（Cross Entropy Loss）详解")]),t._v(" "),s("hr"),t._v(" "),s("p",[t._v("本文件通过示例和问答形式，详细解释交叉熵的定义、用途、以及为什么它在深度学习中如此重要。")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"📌-什么是交叉熵损失"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#📌-什么是交叉熵损失"}},[t._v("#")]),t._v(" 📌 什么是交叉熵损失？")]),t._v(" "),s("p",[t._v("交叉熵衡量的是两个概率分布之间的差异。对于分类任务来说，它衡量模型预测的概率分布（softmax 后）与真实标签分布之间的距离。")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"❓-q1-交叉熵损失的公式是什么"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#❓-q1-交叉熵损失的公式是什么"}},[t._v("#")]),t._v(" ❓ Q1：交叉熵损失的公式是什么？")]),t._v(" "),s("p",[t._v("对于一个样本，交叉熵损失为：")]),t._v(" "),s("p",[t._v("$$\n\\mathcal{L} = -\\log(p_y)\n$$")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://raw.githubusercontent.com/emmableu/image/master/202506141033506.png",alt:""}}),t._v("\n其中：")]),t._v(" "),s("ul",[s("li",[t._v("( p_y )：模型对真实类别 ( y ) 的预测概率（来自 softmax）")]),t._v(" "),s("li",[t._v("当 ( x ) 趋近于 1，损失趋近于 0（预测正确）")]),t._v(" "),s("li",[t._v("当 ( x ) 趋近于 0，损失趋近于 ∞（预测错误）")])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"📊-关键点表格"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#📊-关键点表格"}},[t._v("#")]),t._v(" 📊 关键点表格")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("x 值")]),t._v(" "),s("th",[t._v("-log(x)")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("1.0")]),t._v(" "),s("td",[t._v("0.000")])]),t._v(" "),s("tr",[s("td",[t._v("0.99")]),t._v(" "),s("td",[t._v("0.01005")])]),t._v(" "),s("tr",[s("td",[t._v("0.9")]),t._v(" "),s("td",[t._v("0.10536")])]),t._v(" "),s("tr",[s("td",[t._v("0.5")]),t._v(" "),s("td",[t._v("0.6931")])]),t._v(" "),s("tr",[s("td",[t._v("0.1")]),t._v(" "),s("td",[t._v("2.3026")])]),t._v(" "),s("tr",[s("td",[t._v("0.01")]),t._v(" "),s("td",[t._v("4.6052")])]),t._v(" "),s("tr",[s("td",[t._v("0.001")]),t._v(" "),s("td",[t._v("6.9078")])])])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"🧠-直观解释"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#🧠-直观解释"}},[t._v("#")]),t._v(" 🧠 直观解释")]),t._v(" "),s("ul",[s("li",[t._v("✅ 如果模型预测某一类别的概率为 "),s("strong",[t._v("0.99")]),t._v("，真实标签也正是该类别，那么损失为 "),s("code",[t._v("-log(0.99) ≈ 0.01")]),t._v("，非常小。")]),t._v(" "),s("li",[t._v("❌ 如果模型只给真实类别 "),s("strong",[t._v("0.01 的概率")]),t._v("，那么损失为 "),s("code",[t._v("-log(0.01) ≈ 4.6")]),t._v("，惩罚很大。")])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"❓-q2-举个例子"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#❓-q2-举个例子"}},[t._v("#")]),t._v(" ❓ Q2：举个例子？")]),t._v(" "),s("p",[t._v("假设你有三个类别，模型的预测概率如下：")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("类别 0: 0.1\n类别 1: 0.7 ✅（真实标签）\n类别 2: 0.2\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[t._v("则交叉熵损失为：")]),t._v(" "),s("p",[t._v("$$\n\\mathcal{L} = -\\log(0.7) \\approx 0.3567\n$$")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"❓-q3-为啥要取对数-log"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#❓-q3-为啥要取对数-log"}},[t._v("#")]),t._v(" ❓ Q3：为啥要取对数（log）？")]),t._v(" "),s("p",[t._v("原因有三个：")]),t._v(" "),s("ol",[s("li",[s("p",[s("strong",[t._v("放大错误")]),t._v("：如果模型对真实类别预测概率很小，比如 0.01，那 "),s("code",[t._v("-log(0.01) ≈ 4.6")]),t._v("，惩罚很大。这会鼓励模型提高正确预测的概率。")])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("更好的梯度表现")]),t._v("：")]),t._v(" "),s("ul",[s("li",[t._v("线性函数梯度恒定，优化效果差。")]),t._v(" "),s("li",[t._v("对数函数曲线陡峭 → 梯度较大 → 优化更快。")])])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("数学简洁性")]),t._v("：与 softmax 联合使用后，公式简化为：\n$$\n-z_y + \\log(\\sum_j e^{z_j})\n$$\n（其中 ( z_y ) 是真实类的 logit）")])])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"❓-q4-不用-log-可不可以-比如用平方误差"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#❓-q4-不用-log-可不可以-比如用平方误差"}},[t._v("#")]),t._v(" ❓ Q4：不用 log 可不可以？比如用平方误差？")]),t._v(" "),s("p",[t._v("可以，但效果差：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("平方误差（MSE）")]),t._v(" 在分类中不稳定，不能有效区分概率之间的微妙差异。")]),t._v(" "),s("li",[t._v("MSE 假设误差是对称的（e.g., 预测 0.1 vs 0.9 的差距一样），而分类问题不是对称的。")])]),t._v(" "),s("p",[t._v("结论：分类问题 → "),s("strong",[t._v("交叉熵更合适")]),t._v("。")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"❓-q5-交叉熵是怎么参与梯度下降的"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#❓-q5-交叉熵是怎么参与梯度下降的"}},[t._v("#")]),t._v(" ❓ Q5：交叉熵是怎么参与梯度下降的？")]),t._v(" "),s("p",[t._v("训练神经网络时，我们的目标是最小化损失函数。交叉熵的导数在 softmax 的基础上非常自然，计算如下：")]),t._v(" "),s("ul",[s("li",[t._v("假设 softmax 输出为 ( p_i )，目标为 ( y_i )")]),t._v(" "),s("li",[t._v("对损失函数求导得到：\n$$\n\\frac{\\partial L}{\\partial z_i} = p_i - y_i\n$$")])]),t._v(" "),s("p",[t._v("这个结果非常简单直接，计算效率高，而且梯度大小与预测误差成正比，非常适合用于反向传播（backpropagation）。")]),t._v(" "),s("hr"),t._v(" "),s("h1",{attrs:{id:"🧮-leetcode-风格题-手动计算交叉熵损失"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#🧮-leetcode-风格题-手动计算交叉熵损失"}},[t._v("#")]),t._v(" 🧮 Leetcode 风格题：手动计算交叉熵损失")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"📄-题目描述"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#📄-题目描述"}},[t._v("#")]),t._v(" 📄 题目描述")]),t._v(" "),s("p",[t._v("请你手动计算交叉熵损失函数的值，并和 "),s("code",[t._v("torch.nn.functional.cross_entropy")]),t._v(" 计算结果进行对比。")]),t._v(" "),s("h3",{attrs:{id:"✅-crossentropy-计算方式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#✅-crossentropy-计算方式"}},[t._v("#")]),t._v(" ✅ CrossEntropy 计算方式：")]),t._v(" "),s("ol",[s("li",[s("p",[s("strong",[t._v("先计算 softmax")]),t._v("：")]),t._v(" "),s("p",[t._v("$$p_i = e^{z_i} / sum(e^{z_j})$$")])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("再计算交叉熵损失（取真实标签的概率并取 -log）")]),t._v("：")]),t._v(" "),s("p",[t._v("$$L = -log(p_y)$$")])])]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"💡-函数签名"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#💡-函数签名"}},[t._v("#")]),t._v(" 💡 函数签名：")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("manual_cross_entropy")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 请你在这里手动计算 softmax , -log(p_y)")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("pass")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("hr"),t._v(" "),s("h2",{attrs:{id:"📥-示例输入"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#📥-示例输入"}},[t._v("#")]),t._v(" 📥 示例输入：")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("logits "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntarget "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br")])]),s("hr"),t._v(" "),s("h2",{attrs:{id:"📤-输出"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#📤-输出"}},[t._v("#")]),t._v(" 📤 输出：")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("0.356（左右）\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("hr"),t._v(" "),s("h2",{attrs:{id:"✅-测试用例"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#✅-测试用例"}},[t._v("#")]),t._v(" ✅ 测试用例：")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("functional "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" F\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("assert_close_batch")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" targets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 批量计算 PyTorch 自带的 cross_entropy")]),t._v("\n    expected "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cross_entropy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" targets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" reduction"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"none"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shape: [batch_size]")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 你需要自己实现 manual_cross_entropy 才能使用下行")]),t._v("\n    actual "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" manual_cross_entropy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" targets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shape: [batch_size]")]),t._v("\n    \n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("allclose"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("expected"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" actual"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" atol"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string-interpolation"}},[s("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"Mismatch:\\nExpected: ')]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("expected"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\\nGot: ")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("actual"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"✅ 所有测试通过！"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输入 logits 和 targets")]),t._v("\nlogits "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntargets "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 测试函数")]),t._v("\nassert_close_batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" targets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br")])]),s("h2",{attrs:{id:"implementation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation"}},[t._v("#")]),t._v(" Implementation")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("functional "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" F\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("manual_cross_entropy")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Tensor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    exponential "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("logits"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    probs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" exponential"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("exponential"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dim"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" keepdim"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    neg_log "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("probs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("torch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("arange"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("probs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" neg_log\n\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br")])]),s("hr"),t._v(" "),s("h2",{attrs:{id:"✅-总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#✅-总结"}},[t._v("#")]),t._v(" ✅ 总结")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("问题")]),t._v(" "),s("th",[t._v("回答")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("为什么用 log？")]),t._v(" "),s("td",[t._v("放大错误、梯度好、数学性质佳")])]),t._v(" "),s("tr",[s("td",[t._v("可以用平方误差代替吗？")]),t._v(" "),s("td",[t._v("不推荐，梯度不稳定，效果差")])]),t._v(" "),s("tr",[s("td",[t._v("为什么交叉熵适合用作损失函数？")]),t._v(" "),s("td",[t._v("梯度简洁、反映概率差距大、收敛快")])])])])])}),[],!1,null,null,null);s.default=r.exports}}]);