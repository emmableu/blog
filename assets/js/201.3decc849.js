(window.webpackJsonp=window.webpackJsonp||[]).push([[201],{571:function(s,t,n){"use strict";n.r(t);var a=n(9),e=Object(a.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("p",[t("a",{attrs:{href:"https://leetcode.com/problems/product-of-two-run-length-encoded-arrays",target:"_blank",rel:"noopener noreferrer"}},[s._v("LC link"),t("OutboundLink")],1),s._v(" "),t("a",{attrs:{href:"https://leetcode.com/problems/product-of-two-run-length-encoded-arrays/discuss/1228261/Python3-Clean-two-pointers-solution",target:"_blank",rel:"noopener noreferrer"}},[s._v("explanation"),t("OutboundLink")],1)]),s._v(" "),t("h2",{attrs:{id:"description"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#description"}},[s._v("#")]),s._v(" Description")]),s._v(" "),t("p",[s._v("行程编码（Run-length encoding）是一种压缩算法，能让一个含有许多段连续重复数字的整数类型数组 nums 以一个（通常更小的）二维数组 encoded 表示。每个 encoded[i] = [vali, freqi] 表示 nums 中第 i 段重复数字，其中 vali 是该段重复数字，重复了 freqi 次。")]),s._v(" "),t("blockquote",[t("p",[s._v("例如，"),t("code",[s._v("nums = [1,1,1,2,2,2,2,2]")]),s._v(" 可表示称行程编码数组 "),t("code",[s._v("encoded = [[1,3],[2,5]]")]),s._v(" 。对此数组的另一种读法是“三个 1 ，后面有五个 2 ”。\n两个行程编码数组 "),t("code",[s._v("encoded1")]),s._v(" 和 "),t("code",[s._v("encoded2")]),s._v(" 的积可以按下列步骤计算：")])]),s._v(" "),t("p",[s._v("将 "),t("code",[s._v("encoded1")]),s._v(" 和 "),t("code",[s._v("encoded2")]),s._v(" 分别扩展成完整数组 "),t("code",[s._v("nums1")]),s._v(" 和 "),t("code",[s._v("nums2")]),s._v(" 。")]),s._v(" "),t("ol",[t("li",[s._v("创建一个新的数组 "),t("code",[s._v("prodNums")]),s._v(" ，长度为 "),t("code",[s._v("nums1.length")]),s._v(" 并设 "),t("code",[s._v("prodNums[i] = nums1[i] * nums2[i]")]),s._v(" 。")]),s._v(" "),t("li",[s._v("将 "),t("code",[s._v("prodNums")]),s._v(" 压缩成一个行程编码数组并返回之。")]),s._v(" "),t("li",[s._v("给定两个行程编码数组 "),t("code",[s._v("encoded1")]),s._v(" 和 "),t("code",[s._v("encoded2")]),s._v(" ，分别表示完整数组 "),t("code",[s._v("nums1")]),s._v(" 和 "),t("code",[s._v("nums2")]),s._v(" 。nums1 和 nums2 的长度相同。 每一个 encoded1[i] = [vali, freqi] 表示 nums1 中的第 i 段，每一个 encoded2[j] = [valj, freqj] 表示 nums2 中的第 j 段。")])]),s._v(" "),t("p",[s._v("返回 encoded1 和 encoded2 的乘积。"),t("br"),s._v("\n注：行程编码数组需压缩成可能的最小长度。")]),s._v(" "),t("h2",{attrs:{id:"examples"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#examples"}},[s._v("#")]),s._v(" Examples")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("示例 1:\n输入: encoded1 = [[1,3],[2,3]], encoded2 = [[6,3],[3,3]]\n输出: [[6,6]]\n解释n: encoded1 扩展为 [1,1,1,2,2,2] ，encoded2 扩展为 [6,6,6,3,3,3]。\nprodNums = [6,6,6,6,6,6]，压缩成行程编码数组 [[6,6]]。\n\n示例 2:\n输入: encoded1 = [[1,3],[2,1],[3,2]], encoded2 = [[2,3],[3,3]]\n输出: [[2,3],[6,1],[9,2]]\n解释: encoded1 扩展为 [1,1,1,2,3,3] ，encoded2 扩展为 [2,2,2,3,3,3]。\nprodNums = [2,2,2,6,9,9]，压缩成行程编码数组 [[2,3],[6,1],[9,2]]。\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("h2",{attrs:{id:"solution"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#solution"}},[s._v("#")]),s._v(" Solution")]),s._v(" "),t("p",[s._v("在第一行的同一个分割段，而且也在第二个序列的同一个分割段中，那么这两个位置乘积之后，肯定值是相同的，而且一定在结果的同一个分割段中。"),t("br"),s._v("\n所以，每次循环：")]),s._v(" "),t("ul",[t("li",[s._v("双指针，找出当前在看的encoded1的元素，encoded2的元素中小的那个frequency，对于那个得到product")]),s._v(" "),t("li",[s._v("把encoded1， encoded2的元素的对应frequency减少，方便下一次比较，如果减到0了就增加指针的index")]),s._v(" "),t("li",[s._v("对于当前的"),t("code",[s._v("[prod_val, prod_freq]")]),s._v(", 检查是否可以和"),t("code",[s._v("res")]),s._v("的最后一项合并 （如果"),t("code",[s._v("prod_val")]),s._v(" 一样就可以合并）。")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Solution")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("findRLEArray")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" encoded1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" encoded2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        res "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# the encoded product ")]),s._v("\n        idx1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" idx2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" idx1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("encoded1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" \n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# the two idx get out of bounds together, so it's fine to use one of the two.")]),s._v("\n            val1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" freq1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" encoded1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("idx1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" \n            val2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" freq2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" encoded2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("idx2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n            prod_val "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" val1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" val2\n            prod_freq "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("min")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("freq1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" freq2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   \n            encoded1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("idx1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-=")]),s._v(" prod_freq\n            encoded2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("idx2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-=")]),s._v(" prod_freq\n\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" encoded1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("idx1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                idx1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n            \n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" encoded2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("idx2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                idx2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" res "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("or")]),s._v(" res"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" prod_val"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                res"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("prod_val"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" prod_freq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                res"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" prod_freq\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" res\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br")])])])}),[],!1,null,null,null);t.default=e.exports}}]);