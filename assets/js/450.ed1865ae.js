(window.webpackJsonp=window.webpackJsonp||[]).push([[450],{822:function(e,a,i){"use strict";i.r(a);var t=i(9),n=Object(t.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[a("a",{attrs:{href:"https://everdark.github.io/k9/notebooks/ml/learning_to_rank/learning_to_rank.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("source"),a("OutboundLink")],1)]),e._v(" "),a("p",[e._v("In this session, we introduce learning to rank (LTR), a machine learning sub-field applicable to a variety of real world problems that are related to ranking prediction or candidate recommendation.\nWe will walk through the evolution of LTR research in the past two decades, illustrate the very basic concept behind the theory.")]),e._v(" "),a("h2",{attrs:{id:"definition-of-lambdarank"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#definition-of-lambdarank"}},[e._v("#")]),e._v(" Definition of LambdaRank:")]),e._v(" "),a("p",[e._v("a pair-wise ranking model, which uses the lambda function, as an improvement to the NDCG loss function - to make it differentiable, to estimate the parameters inside the model.")]),e._v(" "),a("h2",{attrs:{id:"outline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#outline"}},[e._v("#")]),e._v(" Outline")]),e._v(" "),a("ul",[a("li",[e._v("Introduction to Learning-to-Rank (LTR)\n"),a("ul",[a("li",[e._v("What is LTR and what's the difference between it and other ML models?")]),e._v(" "),a("li",[e._v("The classical problem (And also the non-classical ones)")]),e._v(" "),a("li",[e._v("Different types of LTR modeling approach")])])]),e._v(" "),a("li",[e._v("How to Evaluate a Ranking Model?")]),e._v(" "),a("li",[e._v("The Evolution of mainstream LTR\n"),a("ul",[a("li",[e._v("RankNet -> LambdaNet -> LambdaMART -> LambdaLoss")])])]),e._v(" "),a("li",[e._v("Demo with the go-to open source libraries\n"),a("ul",[a("li",[e._v("LambdaMART with "),a("code",[e._v("lightgbm")]),e._v(" (Gradient Boosting Trees)")]),e._v(" "),a("li",[e._v("Listwise LTR with "),a("code",[e._v("tensorflow")]),e._v(" (Deep Neural Nets)")])])])]),e._v(" "),a("h2",{attrs:{id:"what-is-learning-to-rank-ltr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#what-is-learning-to-rank-ltr"}},[e._v("#")]),e._v(" What is Learning to Rank (LTR)?")]),e._v(" "),a("blockquote",[a("p",[e._v("Learning to rank refers to machine learning techniques for training a model to solve a ranking task. Usually it is a supervised task and sometimes semi-supervised.")])]),e._v(" "),a("p",[e._v("We try to learn a function $f(q, D)$,\ngiven a query $q$ and a relevant list of items $D$,\nto predict the order (ranking) of all items within list.")]),e._v(" "),a("h2",{attrs:{id:"a-classical-problem-in-ltr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#a-classical-problem-in-ltr"}},[e._v("#")]),e._v(" A Classical Problem in LTR")]),e._v(" "),a("h3",{attrs:{id:"web-search-ranking"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#web-search-ranking"}},[e._v("#")]),e._v(" Web Search Ranking")]),e._v(" "),a("p",[a("em",[e._v("Given a search query, rank the relevance of the resulting matched document URLs, such that more relevant document should be presented first to the user.")])]),e._v(" "),a("p",[e._v("More formally, we depict the above problem as the following task:")]),e._v(" "),a("p",[e._v("Given a query $q$,\nand the resulting $n$ documents $D = {d_1, d_2, ..., d_n}$,\nwe'd like to learn a function $f$ such that $f(q, D)$ will predict the relevance of any given document associated with a query.\nIdeally, $f(q, D)$ should return an ordered list of documents $D^*$, ranked from the most to least relevant to the given query $q$.")]),e._v(" "),a("h2",{attrs:{id:"non-classical-problems-in-ltr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#non-classical-problems-in-ltr"}},[e._v("#")]),e._v(" Non-Classical Problems in LTR")]),e._v(" "),a("p",[e._v("LTR is a general approach for solving ranking task.\nHere are some examples other than just web search ranking.\nNote that not all of them are obviously a ranking task in the first glance.")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("Recommender system")]),e._v(" (Solve personal product perference ranking)")]),e._v(" "),a("li",[a("strong",[e._v("Stock portfolio selection")]),e._v(" (Solving equity return ranking)")]),e._v(" "),a("li",[a("strong",[e._v("Message auto reply")]),e._v(" (Solving best-candidate ranking in email/message reply recommendation)")]),e._v(" "),a("li",[a("strong",[e._v("Image to text")]),e._v(" (Solving best-candidate contextual feature)")])]),e._v(" "),a("h2",{attrs:{id:"general-types-of-ltr-algorithm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#general-types-of-ltr-algorithm"}},[e._v("#")]),e._v(" General Types of LTR algorithm:")]),e._v(" "),a("ul",[a("li",[e._v("Pointwise")]),e._v(" "),a("li",[e._v("Pairwise")]),e._v(" "),a("li",[e._v("Listwise")])]),e._v(" "),a("p",[e._v("They are distinguished by how we formulate the "),a("strong",[e._v("loss function")]),e._v(" in the underlying machine learning task.")]),e._v(" "),a("p",[a("strong",[e._v("The Ranking Task")])]),e._v(" "),a("p",[e._v("Given a query $q$,\nand the resulting $n$ document $D = {d_1, d_2, ..., d_n}$,\nwe'd like to learn a function $f$ such that $f(q, D)$ will predict the relevance of any given document associated with a query.")]),e._v(" "),a("h2",{attrs:{id:"pointwise-ltr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pointwise-ltr"}},[e._v("#")]),e._v(" Pointwise LTR")]),e._v(" "),a("p",[e._v("In pointwise approach, the above ranking task is re-formulated as a regression (or classification) task.\nThe function to be learned $f(q, D)$ is simplied as $f(q, d_i)$.\nThat is, the relevance of each document given a query is scored independently.\nIn recent literature $f(q, d_i)$ is called pointwise scoring function,\nwhile $f(q, D)$ is refered to as groupwise scoring function.")]),e._v(" "),a("p",[e._v("If we have two queries associated with 2 and 3 resulting matching documents, respectively:")]),e._v(" "),a("p",[e._v("$$\n\\begin{align}\nq_1 & \\rightarrow d_1, d_2 \\\nq_2 & \\rightarrow d_3, d_4, d_5\n\\end{align}\n$$")]),e._v(" "),a("p",[e._v("Then the training examples $x_i$ in a pointwise framework will decouple them into every query-document pair:")]),e._v(" "),a("p",[e._v("$$\n\\begin{align}\nx_1: q_1, d_1 \\\nx_2: q_1, d_2 \\\nx_3: q_2, d_3 \\\nx_4: q_2, d_4 \\\nx_5: q_2, d_5\n\\end{align}\n$$")]),e._v(" "),a("p",[e._v("Since each document is indeed scored independently with the absolute relevance as the target label (could be real-valued in order or simply binary),\n"),a("strong",[e._v("the task is entirely no difference than a traditional regression or classification task.")]),e._v("\nAny such machine learning algorithm can be applied to pointwise solution.")]),e._v(" "),a("ul",[a("li",[e._v("Pros:\n"),a("ul",[a("li",[e._v("Simplicity. Existing ML models are ready to apply.")])])]),e._v(" "),a("li",[e._v("Cons:\n"),a("ul",[a("li",[e._v("The result is usually sub-optimal due to not utilizing the full information in the entire list of matching documents for each query.")]),e._v(" "),a("li",[e._v("Explicit pointwise labels are required to constitute the training dataset.")])])])]),e._v(" "),a("p",[a("strong",[e._v("The Ranking Task")])]),e._v(" "),a("p",[e._v("Given a query $q$,\nand the resulting $n$ document $D = {d_1, d_2, ..., d_n}$,\nwe'd like to learn a function $f$ such that $f(q, D)$ will predict the relevance of any given document associated with a query.")]),e._v(" "),a("h2",{attrs:{id:"pairwise-ltr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pairwise-ltr"}},[e._v("#")]),e._v(" Pairwise LTR")]),e._v(" "),a("p",[e._v("In pairwise approach, we are still trying to learn the "),a("em",[e._v("pointwise")]),e._v(" scoring function $f(q, d_i)$,\nhowever, our training examples are now consructed by pairs of documents within the same query:")]),e._v(" "),a("p",[e._v("$$\n\\begin{align}\nx_1: q_1, (d_1, d_2) \\")]),e._v(" "),a("p",[e._v("x_2: q_2, (d_3, d_4) \\")]),e._v(" "),a("p",[e._v("x_3: q_2, (d_3, d_5) \\")]),e._v(" "),a("p",[e._v("x_4: q_2, (d_4, d_5)\n\\end{align}\n$$")]),e._v(" "),a("p",[e._v("Given such setup, a new set of pairwise BINARY labels can be derived, by simply comapring the individual relevance score in each pair.\nFor example, given the first query $q_1$, if $y_1 = 0$ (totally irrelevant) for $d_1$ and $y_2 = 3$ (highly relevant) for $d_2$, then we have a new label $y_1 < y_2$ for the document pair $(d_1, d_2)$.\n"),a("strong",[e._v("Now the problem has become a binary classification learning task.")])]),e._v(" "),a("p",[e._v("In order to learn the still-pointwise function $f(q, d_i)$ in a pairwise manner, we model the score difference probablistically:")]),e._v(" "),a("p",[e._v("$$\nPr(i \\succ j) \\equiv \\frac{1}{1 + exp^{-(s_i - s_j)}}\n$$")]),e._v(" "),a("p",[e._v("In plain words, if document $i$ is better matched than document $j$ (which we denote as $i \\succ j$),\nthen the probability of the scoring function to have scored $f(q, d_i) = s_i$ higher than $f(q, d_j) = s_j$ should be close to 1.\nPut it differnetly, the model is trying to learn, given a query, how to score a pair of document such that a more relevant document should be scored higher.")]),e._v(" "),a("ul",[a("li",[e._v("Pros:\n"),a("ul",[a("li",[e._v("The model is learning how to rank directly, even though only in a pairwise manner, but in theory it can approximate the performance of a general ranking task given N document in a matched list.")]),e._v(" "),a("li",[e._v("We don't need explicit pointwise labels. Only pairwise preferences are required. This is an advantage because sometimes we are only able to infer the pairwise preference from collected user behavior.")])])]),e._v(" "),a("li",[e._v("Cons:\n"),a("ul",[a("li",[e._v("Scoring function itself is still pointwise, meaning that relative information in the feature space among different documents given the same query is still not fully exploited.")])])])]),e._v(" "),a("p",[e._v("examples of pairwise approach:  RankNet, LambdaRank and LambdaMART.")]),e._v(" "),a("p",[a("strong",[e._v("The Ranking Task")])]),e._v(" "),a("p",[e._v("Given a query $q$,\nand the resulting $n$ document $D = {d_1, d_2, ..., d_n}$,\nwe'd like to learn a function $f$ such that $f(q, D)$ will predict the relevance of any given document associated with a query.")]),e._v(" "),a("h2",{attrs:{id:"listwise-ltr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#listwise-ltr"}},[e._v("#")]),e._v(" Listwise LTR")]),e._v(" "),a("p",[e._v("The first ever proposed listwise approach is ListNet.\nHere we explain how it approach the ranking task.")]),e._v(" "),a("p",[e._v("ListNet is based on the concept of permutation probability given a ranking list.\nAgain we assume there is a "),a("em",[e._v("pointwise")]),e._v(" scoring function $f(q, d_i)$ used to score and hence rank a given list of items.\nBut instead of modeling the probability of a pairwise comparison using scoring difference,\nnow we'd like to model the probability of the entire ranking results.")]),e._v(" "),a("p",[e._v("$$\n\\begin{align}\nx_1: q_1, (d_1, d_2) \\\nx_2: q_2, (d_3, d_4, d_5)\n\\end{align}\n$$")]),e._v(" "),a("h3",{attrs:{id:"permutation-probability"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#permutation-probability"}},[e._v("#")]),e._v(" Permutation Probability")]),e._v(" "),a("p",[e._v("Let's denote $\\pi$ as a particular permutation of a given list of length $n$, $\\phi(s_i) = f(q, d_i)$ as any increasing function of scoring $s_i$ given query $q$ and document $i$.\nThe probability of having a permutation $\\pi$ can be written as:")]),e._v(" "),a("p",[e._v("$$\nPr(\\pi) = \\prod_{i=1}^n \\frac{\\phi(s_i)}{\\sum_{k=i}^n\\phi(s_k)}\n$$")]),e._v(" "),a("p",[e._v("To illustrate, given a list of 3 items, the probability of returning the permutation ${s_1, s_2, s_3}$ is calculated as: $Pr(\\pi = {s_1, s_2, s_3}) = \\frac{\\phi(s_1)}{\\phi(s_1) + \\phi(s_2) + \\phi(s_3)} \\cdot \\frac{\\phi(s_2)}{\\phi(s_2) + \\phi(s_3)} \\cdot \\frac{\\phi(s_3)}{\\phi(s_3)}$.")]),e._v(" "),a("h3",{attrs:{id:"top-one-probability"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#top-one-probability"}},[e._v("#")]),e._v(" Top-One Probability")]),e._v(" "),a("p",[e._v("Due to computational complexity, ListNet simplies the problem by looking at only the top-one probability of a given item.\nThe top-one probability of object $i$ equals the sum of the permutation probabilities of permutations in which object $i$ is ranked on the top.\nIndeed, the top-one probability of object $i$ can be written as:")]),e._v(" "),a("p",[e._v("$$\nPr(i) = \\frac{\\phi(s_i)}{\\sum_{k=1}^n \\phi(s_k)}\n$$")]),e._v(" "),a("p",[e._v("Now given any two ranking list represented by top-one probabilities,\nwe are able to measure their difference using cross entropy.\nThen we can build a machine learning algorithm that minimize that cross entropy.")]),e._v(" "),a("p",[e._v("For the choice of function $\\phi(\\cdot)$, it can be as simple as just an exponential function.\nIndeed, when $\\phi(\\cdot)$ is expotential and list length is two,\nthe solution will reduce to a pairwise model we just depicted in the previos section.")]),e._v(" "),a("ul",[a("li",[e._v("Pros:\n"),a("ul",[a("li",[e._v("Theoretically sound solution to approach a ranking task.")])])]),e._v(" "),a("li",[e._v("Cons:\n"),a("ul",[a("li",[e._v("Costly to compute in its theoretical form and hence several approximations are used in practice. (For example the use of top-one probability.)")]),e._v(" "),a("li",[e._v("Scoring function is still pointwise, which could be sub-optimal.")])])])]),e._v(" "),a("h2",{attrs:{id:"evaluation-of-ltr-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#evaluation-of-ltr-model"}},[e._v("#")]),e._v(" Evaluation of LTR Model")]),e._v(" "),a("p",[e._v("How to we evaluate a result of ranking prediction?")]),e._v(" "),a("p",[e._v("Several metrics have been proposed and commonly used in the evaluation of a ranking model:")]),e._v(" "),a("ul",[a("li",[e._v("Binary Relevance\n"),a("ul",[a("li",[e._v("Mean Average Precision (MAP)")]),e._v(" "),a("li",[e._v("Mean Reciprocal Rank (MRR)")])])]),e._v(" "),a("li",[e._v("Graded Relevance\n"),a("ul",[a("li",[e._v("Normalized Discounted Cumulative Gain (NDCG)")]),e._v(" "),a("li",[e._v("Expected Reciprocal Rank (ERR)")])])])]),e._v(" "),a("p",[e._v("In general, binary measures only consider relevant v.s. irrelevant,\nwhile graded measures will also consider the ranking among relevant items.\nThe degree of relevancy matters in this case when scoring a ranking list.")]),e._v(" "),a("h3",{attrs:{id:"mean-average-precision-map"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mean-average-precision-map"}},[e._v("#")]),e._v(" Mean Average Precision, MAP")]),e._v(" "),a("p",[e._v("MAP is a measure based on binary label of relevancy.\nThe calculation of MAP is indeed NOT that straightforward.\nFirst we need to define "),a("em",[e._v("precision at k given a query")]),e._v(" $P@k(q)$ as:")]),e._v(" "),a("p",[e._v("$$\nP@k(q) \\equiv \\frac{\\sum_{i=1}^k r_i}{k}\n$$")]),e._v(" "),a("p",[e._v("for an ordered list of prediction $r_i$ for all $k$ items. $r_i = 1$ if it is relevant and $0$ otherwise.")]),e._v(" "),a("p",[e._v("Then we define the "),a("em",[e._v("average precision given a query")]),e._v(" $AP(q)$ at $k$ items as:")]),e._v(" "),a("p",[e._v("$$\nAP(q)@k \\equiv \\frac{1}{\\sum_{i=1}^k r_i} \\sum_{i=1}^k P@i(q) \\times r_i\n$$")]),e._v(" "),a("p",[e._v("Mean Average Precision is just the mean of $AP(q)$ for all queries:")]),e._v(" "),a("p",[e._v("$$\nMAP \\equiv \\frac{\\sum_{q=1}^Q AP(q)}{Q}\n$$")]),e._v(" "),a("p",[e._v("Note that MAP is order-sensitive due to the introduction of the term $r_i$ in the calculation of AP.\nIntuitively, it is doing the average of precision at each ranking position, but penalizing the precision at positions with irrelevant item by strcitly setting them to zeroes.")]),e._v(" "),a("p",[a("strong",[e._v("Example:")])]),e._v(" "),a("p",[e._v("$$\n\\begin{align}\nq_1 & \\rightarrow d_1, d_2 \\\nq_2 & \\rightarrow d_3, d_4, d_5\n\\end{align}\n$$")]),e._v(" "),a("p",[e._v("Assuming only $d_2, d_3, d_5$ are relevant document given their corresponding query.")]),e._v(" "),a("p",[e._v("AP of query 1: $\\frac{1}{1} \\times (\\frac{0}{1} \\times 0 + \\frac{1}{2} \\times 1) = \\frac{1}{2}$")]),e._v(" "),a("p",[e._v("AP of query 2: $\\frac{1}{2} \\times (\\frac{1}{1} \\times 1 + \\frac{1}{2} \\times 0 + \\frac{2}{3} \\times 1) = \\frac{5}{6}$")]),e._v(" "),a("p",[e._v("MAP: $\\frac{1}{2} \\times (\\frac{1}{2} + \\frac{5}{6}) \\approx 67%$")]),e._v(" "),a("p",[a("strong",[e._v("Caveat:")])]),e._v(" "),a("p",[e._v("MAP is order-sensitive, but only in a binary context: relevant items should come first than irrelevant ones.\nIt does not take into account the optimal ranking among only relevant items.\nIn the above example, even if $d_5$ is prefered than $d_3$ (and both are relevant),\naverage precision of the query is the same for $d_3, d_4, d_5$ and $d_5, d_4, d_3$.\nBut ideally the latter should be scored higher.")]),e._v(" "),a("h3",{attrs:{id:"reciproal-rank-rr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reciproal-rank-rr"}},[e._v("#")]),e._v(" Reciproal Rank, RR")]),e._v(" "),a("p",[e._v("RR focuses on the first correctly predicted relevant item in a list.\nGiven a ranking list, assume $r_i$ is the rank of the highest ranking relevant item.\nSay, if the the 2nd item is the first relevant item in the list, RR is $\\frac{1}{2}$ for this query.")]),e._v(" "),a("h4",{attrs:{id:"mean-reciproal-rank-mrr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mean-reciproal-rank-mrr"}},[e._v("#")]),e._v(" Mean Reciproal Rank, MRR")]),e._v(" "),a("p",[e._v("By definition, each query will have a reciprocal rank.\nMRR is simply the average of RR for all queries:")]),e._v(" "),a("p",[e._v("$$\nMRR \\equiv \\frac{1}{Q} \\sum_{i=1}^Q\\frac{1}{r_i}\n$$")]),e._v(" "),a("h4",{attrs:{id:"expected-reciproal-rank-err"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#expected-reciproal-rank-err"}},[e._v("#")]),e._v(" Expected Reciproal Rank, ERR")]),e._v(" "),a("p",[e._v("The underlying rationale is the empirical finding in the web search problem that "),a("em",[e._v("the likelihood a user examines the document at rank i is dependent on how satisfied the user was with previously observed documents in the list")]),e._v(".\nERR hence tries to quantify the usefulness of a document at rank $i$ conditioned on the degree of relevance of documents at rank less than $i$.")]),e._v(" "),a("p",[e._v("Assume the probability of a user finding the result is satisfied at position $i$ in a given list is denoted as $R_i$.\nThe likelihood of a session for which the user is satisfied and stops at position $r$ is: $\\prod_{i=1}^{r-1}(1 - R_i)R_r$.")]),e._v(" "),a("p",[e._v("Now we model $R_i$ such that it is an increasing function of relevance:")]),e._v(" "),a("p",[e._v("$$\nR = R(g) \\equiv \\frac{2^g - 1}{2^{g_{max}}}\n$$")]),e._v(" "),a("p",[e._v("where $g$ is the labeled (graded) relevance such that $g \\in {0, 1, ..., g_{max}}$.\n$g = 0$ suggests irrelevant and $g = g_{max}$ perfectly relevant.")]),e._v(" "),a("p",[e._v("Finally, ERR is defined as:")]),e._v(" "),a("p",[e._v("$$\nERR \\equiv \\sum_{r=1}^n\\frac{1}{r}R_r\\prod_{i=1}^{r-1}(1-R_i)\n$$")]),e._v(" "),a("p",[e._v("Here $\\frac{1}{r}$ can be considered as a utility function $\\tau(r)$ that satisfies $\\tau(1) = 1$ and $\\tau(r) \\rightarrow 0$ as $r \\rightarrow \\infty$.")]),e._v(" "),a("p",[e._v("Note that ERR is a measure on a list with a single query,\nso the corresponding de-generated measure is RR instead of MRR.\nTo evaluate on results from multiple queries, we will need to further average ERRs among queries.")]),e._v(" "),a("p",[a("strong",[e._v("Example:")])]),e._v(" "),a("p",[e._v("$$\n\\begin{align}\nq_1 & \\rightarrow d_1, d_2 \\\nq_2 & \\rightarrow d_3, d_4, d_5\n\\end{align}\n$$")]),e._v(" "),a("p",[e._v("Assuming only $d_2, d_3, d_5$ are relevant document given their corresponding query.")]),e._v(" "),a("p",[e._v("MRR: $(\\frac{1}{2} + \\frac{1}{1}) \\times \\frac{1}{2} = \\frac{3}{4}$")]),e._v(" "),a("p",[e._v("ERR of $q_1$: $0 + \\frac{1}{2} \\times \\frac{2^1 - 1}{2^1} \\times (1 - \\frac{2^0 - 1}{2^1}) = \\frac{1}{4}$")]),e._v(" "),a("p",[e._v("ERR of $q_2$: $\\frac{1}{1} \\times \\frac{2^1 - 1}{2^1} + 0 + \\frac{1}{3} \\times \\frac{2^1 - 1}{2^1} \\times (1 - \\frac{2^0 - 1}{2^1}) \\times (1 - \\frac{2^1 - 1}{2^1}) = \\frac{7}{12}$")]),e._v(" "),a("p",[a("strong",[e._v("Caveat:")])]),e._v(" "),a("p",[e._v("MRR is a binary measure, while ERR is a graded measure.\nAlso MRR and ERR is NOT directly comparable between each other.\nBoth being graded measure, ERR is less popular than NDCG in empirical works due to its computational complexity.")]),e._v(" "),a("h3",{attrs:{id:"normalized-discounted-cumulative-gain-ndcg"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#normalized-discounted-cumulative-gain-ndcg"}},[e._v("#")]),e._v(" Normalized Discounted Cumulative Gain, NDCG")]),e._v(" "),a("p",[e._v("è§ "),a("RouterLink",{attrs:{to:"/pages/0fa9b5/#offline-metrics-ndcg"}},[e._v("/pages/0fa9b5/#offline-metrics-ndcg")])],1),e._v(" "),a("h2",{attrs:{id:"labeling-issues"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#labeling-issues"}},[e._v("#")]),e._v(" Labeling Issues")]),e._v(" "),a("p",[e._v("Broadly speaking there are two approaches to label a ranking dataset:")]),e._v(" "),a("ul",[a("li",[e._v("Human judgement")]),e._v(" "),a("li",[e._v("Derivation from user behavior log")])]),e._v(" "),a("p",[e._v("For the 1st approach, massive manpower is required to label the relevance of each item given a query.\nIn real world lots of dataset cannnot be labeled in such way, so we rely on the 2nd approach which indirectly infer user preference among different items.")]),e._v(" "),a("p",[e._v("Usually pairwise preference can be infered from user interaction with the query result.\nFor example, use click data to infer web search relevance.\nThis is also why pairwise approach in LTR can gain much more attention than the pointwise method: due to data availability.")]),e._v(" "),a("h2",{attrs:{id:"evolution-of-ltr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#evolution-of-ltr"}},[e._v("#")]),e._v(" Evolution of LTR")]),e._v(" "),a("h3",{attrs:{id:"from-pointwise-to-pairwise"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#from-pointwise-to-pairwise"}},[e._v("#")]),e._v(" From Pointwise to Pairwise")]),e._v(" "),a("p",[e._v("In the literature of LTR,\na set of very important theoretical and also empirical works were done by "),a("a",{attrs:{href:"http://chrisburges.net/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Chris Burges"),a("OutboundLink")],1),e._v(" from MicroSoft Research,\nwho have established the very foundation of the pairwise approach in LTR.")]),e._v(" "),a("p",[e._v("Those important pairwise LTR models include:")]),e._v(" "),a("ul",[a("li",[e._v("RankNet (2005)")]),e._v(" "),a("li",[e._v("LambdaNet (2006)")]),e._v(" "),a("li",[e._v("LambdaMART (2007); high quality implementation available in the library "),a("a",{attrs:{href:"https://github.com/Microsoft/LightGBM",target:"_blank",rel:"noopener noreferrer"}},[a("code",[e._v("lightgbm")]),a("OutboundLink")],1)])]),e._v(" "),a("h3",{attrs:{id:"from-pairwise-to-listwise-and-more"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#from-pairwise-to-listwise-and-more"}},[e._v("#")]),e._v(" From Pairwise to Listwise, and More")]),e._v(" "),a("p",[e._v("Recently, researchers from Google generalize the LambdaMART framework to provide a theoretical background of the ranking model of all 3 types of loss function (pointwise, pairwise, listwise) and the direct optimization of all the popular ranking metrics (NDCG, MAP, ...).\nThe framework is called LambdaLoss (2018).")]),e._v(" "),a("p",[e._v("A production-ready implementation of such framework is also open-sourced as a "),a("a",{attrs:{href:"https://github.com/tensorflow/ranking",target:"_blank",rel:"noopener noreferrer"}},[e._v("ranking module"),a("OutboundLink")],1),e._v(" under the popular library "),a("code",[e._v("TensorFlow")]),e._v(".\nA "),a("em",[e._v("groupwise")]),e._v(" scoring function is also proposed and can be implemented in the library.")]),e._v(" "),a("p",[e._v("The reason why we choose specifically to elaborate the above mentioned models is because they are the very foundation of LTR literature, cited more than a thousand times.")]),e._v(" "),a("p",[e._v("And the reason why the libraries are chosen is basically the same: they are the state-of-the-art popular open source go-to frameworks in this field.")]),e._v(" "),a("h2",{attrs:{id:"ranknet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ranknet"}},[e._v("#")]),e._v(" RankNet")]),e._v(" "),a("p",[e._v("Remember that we model the score difference between a given pair $(i, j)$ as a probability based on the sigmoid function:")]),e._v(" "),a("p",[e._v("$$\nPr(i \\succ j) = P_{ij} \\equiv \\frac{1}{1 + exp^{-(s_i - s_j)}}\n$$")]),e._v(" "),a("p",[e._v("where")]),e._v(" "),a("p",[e._v("$$\ns_i = f(q, d_i)\n$$")]),e._v(" "),a("p",[e._v("is the pointwise score output by our underlying learner $f(q, d)$, which in RankNet is formulated as a "),a("em",[e._v("2-layer neural network")]),e._v(" parameterized by a set of $w_k$.\n(Or even think simplier, let $f(q, d_i) = wx_i$ as a linear learner.)")]),e._v(" "),a("p",[e._v("Given a probability distribution $p$, the entropy is defined as: $p \\cdot log_2\\frac{1}{p}$.\nNow let $y_{ij} \\in {0, 1}$ be the actual label of the given pair $(i, j)$,\nThe loss function of the above setup will be the "),a("em",[e._v("cross entropy")]),e._v(":")]),e._v(" "),a("p",[e._v("$$\nloss = -\\sum_{i \\neq j}{y_{ij}log_2P_{ij} + (1-y_{ij})log_2(1-P_{ij})}\n$$")]),e._v(" "),a("p",[e._v("The cross entropy measures how close two probability distribution are to each other.\nSo naturally it is a good objective function for a machine learning model that models probability to optimize.\nUsing backprop techinque we can numerically find the model weights in $f(q, d)$ that minimize the cross entropy loss.")]),e._v(" "),a("p",[e._v("Note that the above loss is very general: it is just the expected log-loss, or the sum of cross entropy from each training record, used to measure how good the model distribution is approximating the empirical distribution of the traing data (which in turn serves as an approximation to the unknown true distribution generating the training data).\nWe can easily swap the neural network with other learners, resulting in a variety of different pairwise LTR models.")]),e._v(" "),a("h2",{attrs:{id:"lambdanet-probably-the-same-as-lambdarank"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lambdanet-probably-the-same-as-lambdarank"}},[e._v("#")]),e._v(" LambdaNet (Probably the same as LambdaRank)")]),e._v(" "),a("p",[e._v("Two important enhancements have been achieved from RankNet to LambdaNet.")]),e._v(" "),a("ol",[a("li",[e._v("Training speed-up thanks to factorization of gradient calculation")]),e._v(" "),a("li",[e._v("Optimization towards a ranking metric")])]),e._v(" "),a("h3",{attrs:{id:"gradient-factorization"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gradient-factorization"}},[e._v("#")]),e._v(" Gradient Factorization")]),e._v(" "),a("p",[e._v("For the first point, LambdaNet is a "),a("strong",[e._v("mathematically improved version of RankNet")]),e._v(".\nThe improvement is based on a factorization of the calculation of gradient of the cross entropy loss, under its pairwise update context.")]),e._v(" "),a("p",[e._v("Given the point cross entropy loss as $L$:")]),e._v(" "),a("p",[e._v("$$\nL = y_{ij}log_2P_{ij} + (1-y_{ij})log_2(1-P_{ij})\n$$")]),e._v(" "),a("p",[e._v("The gradient (the 1st-order derivative of the loss w.r.t. a model parameter $w_k$) can be written as:")]),e._v(" "),a("p",[e._v("$$\n\\frac{\\partial L}{\\partial w_k} = \\frac{\\partial L}{\\partial s_i} \\frac{\\partial s_i}{\\partial w_k} + \\frac{\\partial L}{\\partial s_j} \\frac{\\partial s_j}{\\partial w_k}\n$$")]),e._v(" "),a("p",[e._v("In plain words, the impact of a change in model parameter $w_k$ will go through the resulting changes in the model scores and then the changes in loss.\nNow rewrite the gradient in total losses for all training pairs ${i, j}$ that satisfied $i \\succ j$:")]),e._v(" "),a("p",[e._v("$$\n\\begin{align}\n\\frac{\\partial L_T}{\\partial w_k}\n&= \\sum_"+e._s(e.i,e.j)+" \\bigg[ \\frac{\\partial L}{\\partial s_i} \\frac{\\partial s_i}{\\partial w_k} + \\frac{\\partial L}{\\partial s_j} \\frac{\\partial s_j}{\\partial w_k} \\bigg] \\\n&= \\sum_i \\frac{\\partial s_i}{\\partial w_k} \\bigg( \\sum_{\\forall j \\prec i} \\frac{\\partial L(s_i, s_j)}{\\partial s_i} \\bigg) + \\sum_j \\frac{\\partial s_j}{\\partial w_k} \\bigg( \\sum_{\\forall i \\succ j} \\frac{\\partial L(s_i, s_j)}{\\partial s_j} \\bigg)\n\\end{align}\n$$")]),e._v(" "),a("p",[e._v("with the fact that:")]),e._v(" "),a("p",[e._v("$$\n\\frac{\\partial L(s_i, s_j)}{\\partial s_i} = - \\frac{\\partial L(s_i, s_j)}{\\partial s_j} = log_2e\\big[(1 - y_{ij}) - \\frac{1}{1 + e^{s_i - s_j}}\\big],\n$$")]),e._v(" "),a("p",[e._v("and a re-indexing of the second-term, we end up with:")]),e._v(" "),a("p",[e._v("$$\n\\begin{align}\n\\frac{\\partial L_T}{\\partial w_k}\n&= \\sum_i \\frac{\\partial s_i}{\\partial w_k} \\bigg[ \\sum_{\\forall j \\prec i} \\frac{\\partial L(s_i, s_j)}{\\partial s_i} + \\sum_{\\forall j \\prec i} \\frac{\\partial L(s_j, s_i)}{\\partial s_i} \\bigg] \\\n&= \\sum_i \\frac{\\partial s_i}{\\partial w_k} \\bigg[ \\sum_{\\forall j \\prec i} \\frac{\\partial L(s_i, s_j)}{\\partial s_i} - \\sum_{\\forall j \\succ i} \\frac{\\partial L(s_j, s_i)}{\\partial s_j} \\bigg] \\\n&= \\sum_i \\frac{\\partial s_i}{\\partial w_k} \\lambda_i\n\\end{align}\n$$")]),e._v(" "),a("p",[e._v("The intuition behind the above gradient:")]),e._v(" "),a("blockquote",[a("p",[e._v("For each document in a given query,\nthere is a gradient component we denoted as lambda,\nwhich is calculated by considering all the superior and inferior documents comparing to it.\nA relatively worse document will push the current document up, and a relatively better one will push it down.")])]),e._v(" "),a("p",[e._v("The implication of the above factorization is that during the learning process,\ninstead of doing update by each pair of documents,\nwe can update on a per-query basis.\nAnd since lambda is by far cheaper to calculate, the entire training process can speed up considerably.")]),e._v(" "),a("h3",{attrs:{id:"ranking-metric-optimization"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ranking-metric-optimization"}},[e._v("#")]),e._v(" Ranking Metric Optimization")]),e._v(" "),a("p",[e._v("Since we model the score difference of a pair of documents in a query as a probability measure,\nthe model is optimizing the pairwise correctness of ranking,\nwhich may not be the ultimately desirable objective.")]),e._v(" "),a("p",[e._v("Remember that the ranking objective is indeed measured by (ideally) a position-sensitive graded measure such as NDCG.\nBut in the above setup NDCG is not directly linked to the minimization of cross entropy.\nA straightforward and also simple solution is to use NDCG as an early stop criteria and determine by using a validation dataset.")]),e._v(" "),a("p",[e._v("LambdaRank proposes yet another solution.\nThe researcher found that during the gradient update using the lambda notion,\nfor each pair instead of calculating just the lambda,\nwe can adjusted lambda by the change in NDCG for that pair provided that the position of the two item swaped with each other.")]),e._v(" "),a("p",[e._v("The lambda of a given document is:")]),e._v(" "),a("p",[e._v("$$\n\\begin{align}\n\\lambda_i\n&= \\bigg[ \\sum_{\\forall j \\prec i} \\frac{\\partial L(s_i, s_j)}{\\partial s_i} - \\sum_{\\forall j \\succ i} \\frac{\\partial L(s_j, s_i)}{\\partial s_j} \\bigg] \\\n&= \\bigg[ \\sum_{\\forall j \\prec i} \\lambda_{ij} - \\sum_{\\forall j \\succ i} \\lambda_{ij} \\bigg]\n\\end{align}\n$$")]),e._v(" "),a("p",[e._v("The proposed method is to adjust the pairwise lambda $\\lambda_{ij}$ such that:")]),e._v(" "),a("p",[e._v("$$\n\\lambda_{ij} \\equiv \\frac{\\partial L(s_i, s_j)}{\\partial s_i} \\cdot |\\Delta NDCG_{ij}|\n$$")]),e._v(" "),a("p",[e._v("where $\\Delta NDCG_{ij}$ is the change in NDCG when the position of $i$ and $j$ are swapped.")]),e._v(" "),a("p",[e._v("The researcher found that by such adjustment,\nwithout theoretical proof,\nthe model is empirically optimizing NDCG, and hence yield better overall results.")]),e._v(" "),a("h2",{attrs:{id:"lambdamart"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lambdamart"}},[e._v("#")]),e._v(" LambdaMART")]),e._v(" "),a("p",[e._v("LambdaMART is simply a LambdaNet but replaces the underlying neural network model with "),a("strong",[e._v("gradient boosting regression trees")]),e._v(" (or more general, gradient boosting machines, GBM).\nGBM is proven to be very robust and performant in handling real world problem.")]),e._v(" "),a("p",[e._v("The model wins several real-world large-scale LTR contests.")]),e._v(" "),a("h2",{attrs:{id:"lambdaloss"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lambdaloss"}},[e._v("#")]),e._v(" LambdaLoss")]),e._v(" "),a("p",[e._v("In the original LambdaRank and LambdaMART framework,\nno theoretical work has been done to mathematically prove that ranking metric is being optimized after the adjustment of the lambda calculation.\nThe finding is purely based on empirical works, i.e., by observing the results from varying dataset and simulation with experiments.")]),e._v(" "),a("p",[e._v("Researchers from Google recently (2018) published a generalized framework called LambdaLoss,\nwhich serves as an extension of the original ranking model and comes with a thorough theoretical groundwork to justify that the model is indeed optimizing a ranking metric.")])])}),[],!1,null,null,null);a.default=n.exports}}]);